{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67ec8184",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import requests\n",
    "from yahooquery import Ticker  # Step 2 (Speed)\n",
    "import yfinance as yf          # Step 3 (Reliability)\n",
    "import io\n",
    "import json\n",
    "import os\n",
    "import time\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "831a506f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# CELL 2: CONFIGURATION AND SETUP\n",
    "# =============================================================================\n",
    "\n",
    "# 1. FOLDER SETUP\n",
    "# ---------------\n",
    "# We need a place to save our results. This creates a folder called \"YfinanceDataDump\"\n",
    "# \"Relative path\" means it creates the folder wherever this notebook is saved\n",
    "DATA_FOLDER = \"YfinanceDataDump\"\n",
    "\n",
    "# Check if the folder already exists. If not, create it.\n",
    "# os.path.exists() returns True if the folder exists, False if it doesn't\n",
    "if not os.path.exists(DATA_FOLDER):\n",
    "    try:\n",
    "        # os.makedirs() creates the folder\n",
    "        os.makedirs(DATA_FOLDER)\n",
    "        print(f\"Created data folder: {DATA_FOLDER}\")\n",
    "    except Exception as e:\n",
    "        # If something goes wrong (like no permission), save to current folder\n",
    "        print(f\"Warning: Could not create folder '{DATA_FOLDER}'. Saving to current directory. Error: {e}\")\n",
    "        DATA_FOLDER = \".\"  # The dot means \"current folder\"\n",
    "\n",
    "# 2. FILE PATHS\n",
    "# -------------\n",
    "# These are the names of the files where we'll save our results\n",
    "# os.path.join() combines the folder name with the file name properly\n",
    "# (handles / vs \\ on different operating systems automatically)\n",
    "CACHE_FILE = os.path.join(DATA_FOLDER, \"financial_cache.json\")    # Stores data we've already fetched\n",
    "FORTRESS_CSV = os.path.join(DATA_FOLDER, \"fortress_stocks.csv\")   # Best quality stocks\n",
    "STRONG_CSV = os.path.join(DATA_FOLDER, \"strong_stocks.csv\")       # Good quality stocks\n",
    "RISKY_CSV = os.path.join(DATA_FOLDER, \"risky_stocks.csv\")         # Lower quality stocks\n",
    "ANALYST_CSV = os.path.join(DATA_FOLDER, \"Analyst_Fortress_Picks.csv\")  # Analyst favorites\n",
    "BUFFETT_CSV = os.path.join(DATA_FOLDER, \"Buffett_Value_Picks.csv\") # Value picks\n",
    "DEEPVAL_CSV = os.path.join(DATA_FOLDER, \"Deep_Value_Gems.csv\")    # Intersection of Buffett + Burry\n",
    "# 3. UNIVERSE FILTERS - Minimum requirements for a stock to be considered\n",
    "# -----------------------------------------------------------------------\n",
    "# These are like \"minimum qualifications\" - stocks must pass ALL of these\n",
    "\n",
    "MIN_PRICE = 2.00              # Stock price must be at least $2 (avoid \"penny stocks\")\n",
    "MIN_VOLUME = 1_000_000          # At least 100,000 shares traded per day (so we can buy/sell easily)\n",
    "                              # The underscores are just for readability (100_000 = 100000)\n",
    "MIN_CAP = 300_000_000          # Market cap at least $50 million (company value)\n",
    "                              # Market Cap = Stock Price √ó Number of Shares\n",
    "MIN_CURRENT_RATIO = 1.2       # Current Ratio must be > 1.2\n",
    "                              # Current Ratio = Current Assets / Current Liabilities\n",
    "                              # If > 1, the company can pay its short-term bills\n",
    "MAX_PE_RATIO = 100.0          # P/E ratio must be less than 100\n",
    "                              # P/E = Price / Earnings Per Share\n",
    "                              # High P/E means investors are paying a lot for each dollar of profit\n",
    "\n",
    "# 4. SAFETY THRESHOLDS - Additional quality filters\n",
    "# -------------------------------------------------\n",
    "MIN_INTEREST_COVERAGE = 1.5   # Interest Coverage > 1.5 means company earns 1.5x what it owes in interest\n",
    "                              # Interest Coverage = EBIT / Interest Expense\n",
    "                              # If < 1, company can't pay its interest bills = bad!\n",
    "MIN_ROIC = 0.05               # ROIC (Return on Invested Capital) > 5%\n",
    "                              # ROIC = Operating Profit / Capital Invested\n",
    "                              # Shows how well management uses money to generate returns\n",
    "FORTRESS_MARGIN_THRESHOLD = 0.05  # Operating Margin > 5% for \"Fortress\" (best) tier\n",
    "                                   # Operating Margin = Operating Income / Revenue\n",
    "                                   # Shows what % of sales becomes actual profit\n",
    "\n",
    "# Sectors we want to EXCLUDE (skip)\n",
    "# Financial Services and Real Estate have very different financial structures\n",
    "# that don't work well with our filters\n",
    "EXCLUDED_SECTORS = ['Financial Services', 'Real Estate']\n",
    "\n",
    "CACHE_EXPIRY_DAYS = 30  # Re-fetch data if our saved data is older than 30 days\n",
    "\n",
    "\n",
    "# ==========================================\n",
    "# HELPER FUNCTIONS - Reusable code blocks\n",
    "# ==========================================\n",
    "# Functions are like recipes - we define them once, then use them whenever needed\n",
    "\n",
    "def load_cache():\n",
    "    \"\"\"\n",
    "    Load previously saved financial data from our cache file.\n",
    "    \n",
    "    Why cache? Getting data from Yahoo Finance is slow. If we already\n",
    "    fetched data recently, we can just load it from our saved file instead.\n",
    "    \n",
    "    Returns:\n",
    "        dict: A dictionary of saved data, or empty dict {} if no cache exists\n",
    "    \"\"\"\n",
    "    # Check if the cache file exists\n",
    "    if os.path.exists(CACHE_FILE):\n",
    "        try:\n",
    "            # 'r' means \"read mode\" - we're reading the file, not writing to it\n",
    "            with open(CACHE_FILE, 'r') as f:\n",
    "                # json.load() reads the JSON file and converts it to a Python dictionary\n",
    "                return json.load(f)\n",
    "        except:\n",
    "            # If something goes wrong reading the file, return empty dictionary\n",
    "            return {}\n",
    "    # If file doesn't exist, return empty dictionary\n",
    "    return {}\n",
    "\n",
    "def save_cache(cache_data):\n",
    "    \"\"\"\n",
    "    Save our financial data to a file so we can reuse it later.\n",
    "    \n",
    "    Args:\n",
    "        cache_data (dict): The data we want to save\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # 'w' means \"write mode\" - creates the file or overwrites existing\n",
    "        with open(CACHE_FILE, 'w') as f:\n",
    "            # json.dump() converts the Python dictionary to JSON format and saves it\n",
    "            json.dump(cache_data, f)\n",
    "    except Exception as e:\n",
    "        print(f\"Warning: Could not save cache: {e}\")\n",
    "\n",
    "def calculate_altman_z_yfinance(bs, fin, market_cap):\n",
    "    \"\"\"\n",
    "    Calculate the Altman Z-Score - a formula that predicts bankruptcy risk.\n",
    "    \n",
    "    Created by Professor Edward Altman in 1968.\n",
    "    - Z > 2.99: \"Safe Zone\" - company is financially healthy\n",
    "    - Z between 1.81 and 2.99: \"Grey Zone\" - uncertain\n",
    "    - Z < 1.81: \"Distress Zone\" - high risk of bankruptcy\n",
    "    \n",
    "    The Formula: Z = 1.2A + 1.4B + 3.3C + 0.6D + 1.0E\n",
    "    \n",
    "    Where:\n",
    "    A = Working Capital / Total Assets (liquidity)\n",
    "    B = Retained Earnings / Total Assets (profitability over time)\n",
    "    C = EBIT / Total Assets (operating efficiency)\n",
    "    D = Market Value of Equity / Total Liabilities (market confidence)\n",
    "    E = Sales / Total Assets (asset efficiency)\n",
    "    \n",
    "    Args:\n",
    "        bs: Balance Sheet data (DataFrame from yfinance)\n",
    "        fin: Financial data (DataFrame from yfinance)  \n",
    "        market_cap: Market capitalization in dollars\n",
    "        \n",
    "    Returns:\n",
    "        float: The Z-Score, or 0 if calculation fails\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Helper function to safely get values from DataFrames\n",
    "        # Sometimes the data has different names, so we try multiple\n",
    "        def get_val(df, keys):\n",
    "            for k in keys:\n",
    "                if k in df.index:\n",
    "                    # .iloc[0] gets the first value (most recent year)\n",
    "                    return df.loc[k].iloc[0]\n",
    "            return 0\n",
    "\n",
    "        # Get values from Balance Sheet (bs) and Financials (fin)\n",
    "        total_assets = get_val(bs, ['Total Assets'])\n",
    "        total_liab = get_val(bs, ['Total Liabilities Net Minority Interest', 'Total Liabilities'])\n",
    "        current_assets = get_val(bs, ['Current Assets', 'Total Current Assets'])\n",
    "        current_liab = get_val(bs, ['Current Liabilities', 'Total Current Liabilities'])\n",
    "        retained_earnings = get_val(bs, ['Retained Earnings'])\n",
    "        \n",
    "        ebit = get_val(fin, ['EBIT', 'Operating Income'])  # Earnings Before Interest & Taxes\n",
    "        total_revenue = get_val(fin, ['Total Revenue'])\n",
    "        \n",
    "        # Can't divide by zero, so return 0 if missing key data\n",
    "        if total_assets == 0 or total_liab == 0: \n",
    "            return 0\n",
    "\n",
    "        # Calculate each component of the Z-Score formula\n",
    "        # A: Working Capital (can company pay short-term bills?)\n",
    "        A = (current_assets - current_liab) / total_assets\n",
    "        \n",
    "        # B: Retained Earnings (accumulated profits over the years)\n",
    "        B = retained_earnings / total_assets\n",
    "        \n",
    "        # C: EBIT (operating profitability)\n",
    "        C = ebit / total_assets\n",
    "        \n",
    "        # D: Market Cap vs Debt (how much does market trust vs owe?)\n",
    "        D = market_cap / total_liab\n",
    "        \n",
    "        # E: Revenue (is the company using its assets efficiently?)\n",
    "        E = total_revenue / total_assets\n",
    "        \n",
    "        # The final formula with Altman's coefficients\n",
    "        return (1.2 * A) + (1.4 * B) + (3.3 * C) + (0.6 * D) + (1.0 * E)\n",
    "    \n",
    "    except Exception as e:\n",
    "        return 0  # Return 0 if any calculation fails"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efa4bf6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# CELL 3: STEP 1 - FETCH US STOCK UNIVERSE\n",
    "# =============================================================================\n",
    "# This version fetches US stocks instead of Canadian stocks\n",
    "\n",
    "def get_combined_universe():\n",
    "    \"\"\"\n",
    "    Get a list of all US stock tickers from NASDAQ.\n",
    "    \n",
    "    The NASDAQ provides a file with all traded stocks.\n",
    "    US tickers don't need a suffix (like .TO for Toronto).\n",
    "    \n",
    "    Returns:\n",
    "        list: List of US stock symbols like ['AAPL', 'MSFT', 'GOOGL', ...]\n",
    "    \"\"\"\n",
    "    print(\"--- STEP 1: Fetching North American Universe ---\")\n",
    "    tickers = []\n",
    "    \n",
    "    # Fetch from NASDAQ's official list\n",
    "    try:\n",
    "        url_us = \"https://www.nasdaqtrader.com/dynamic/symdir/nasdaqtraded.txt\"\n",
    "        \n",
    "        # Download the file\n",
    "        s = requests.get(url_us).content\n",
    "        \n",
    "        # Read it as a CSV with pipe (|) as the separator\n",
    "        # The file looks like: Symbol|Security Name|ETF|Test Issue|...\n",
    "        df_us = pd.read_csv(io.StringIO(s.decode('utf-8')), sep='|')\n",
    "        \n",
    "        # Filter out test issues and ETFs (we only want real stocks)\n",
    "        df_us = df_us[(df_us['Test Issue'] == 'N') & (df_us['ETF'] == 'N')]\n",
    "        \n",
    "        # Get symbols, clean them, and keep only short ones (< 5 characters)\n",
    "        # Long symbols are usually special securities we don't want\n",
    "        us_list = [x.replace('$', '-') for x in df_us['Symbol'].astype(str) if len(x) < 5]\n",
    "        \n",
    "        tickers.extend(us_list)  # Add to our list\n",
    "        print(f\"   -> Found {len(us_list)} US stocks.\")\n",
    "        \n",
    "    except:\n",
    "        print(\"   -> Error fetching USA list.\")\n",
    "\n",
    "    return tickers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65c3da19",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# CELL 4: STEP 2 - LIGHTWEIGHT FILTER (QUICK SCREENING)\n",
    "# =============================================================================\n",
    "# This is the first filter - it quickly eliminates stocks that don't meet\n",
    "# basic requirements. It's \"lightweight\" because it uses fast bulk data fetching.\n",
    "\n",
    "def get_initial_survivors(tickers):\n",
    "    \"\"\"\n",
    "    Filter stocks using basic criteria. This is FAST.\n",
    "    \n",
    "    Think of this like a job application - this is the resume screening phase.\n",
    "    We quickly eliminate candidates who don't meet minimum requirements\n",
    "    before doing detailed interviews.\n",
    "    \n",
    "    Args:\n",
    "        tickers (list): List of all stock symbols to check\n",
    "        \n",
    "    Returns:\n",
    "        DataFrame: Table of stocks that passed all filters with their metrics\n",
    "    \"\"\"\n",
    "    print(f\"\\n--- STEP 2: Running 'Lightweight' Filter on {len(tickers)} stocks ---\")\n",
    "    \n",
    "    chunk_size = 500  # Process stocks in batches of 500 at a time\n",
    "    survivors = []    # This list will hold stocks that pass all filters\n",
    "    \n",
    "    # Split our list into chunks (batches)\n",
    "    # This is like dividing a big task into smaller pieces\n",
    "    chunks = [tickers[i:i + chunk_size] for i in range(0, len(tickers), chunk_size)]\n",
    "    \n",
    "    # Process each chunk\n",
    "    for i, chunk in enumerate(chunks):\n",
    "        # Print progress every 2 batches\n",
    "        if i % 2 == 0: \n",
    "            print(f\" -> Processing Batch {i+1}/{len(chunks)}...\")\n",
    "        \n",
    "        try:\n",
    "            # Create a Ticker object for all stocks in this chunk\n",
    "            # asynchronous=True means it fetches data for multiple stocks simultaneously\n",
    "            yq = Ticker(chunk, asynchronous=True)\n",
    "            \n",
    "            # Get multiple types of data at once (this is the \"bulk fetch\")\n",
    "            # These are different Yahoo Finance data modules\n",
    "            df_modules = yq.get_modules(\n",
    "                'summaryProfile summaryDetail financialData price defaultKeyStatistics'\n",
    "            )\n",
    "            \n",
    "            # Loop through each stock's data\n",
    "            for symbol, data in df_modules.items():\n",
    "                # If data is just a string, it means there was an error\n",
    "                if isinstance(data, str): \n",
    "                    continue\n",
    "                \n",
    "                try:\n",
    "                    # Extract the stock price\n",
    "                    # The .get() method returns the value if it exists, or 0 if it doesn't\n",
    "                    price = data.get('price', {}).get('regularMarketPrice', 0)\n",
    "                    if price is None: \n",
    "                        price = 0\n",
    "                    \n",
    "                    # Extract average daily trading volume\n",
    "                    vol = data.get('summaryDetail', {}).get('averageVolume', 0)\n",
    "                    if vol is None or vol == 0:\n",
    "                        # Try alternative location for volume data\n",
    "                        vol = data.get('price', {}).get('averageDailyVolume10Day', 0)\n",
    "                    \n",
    "                    # Extract market capitalization (total company value)\n",
    "                    cap = data.get('price', {}).get('marketCap', 0)\n",
    "                    if cap is None: \n",
    "                        cap = 0\n",
    "                    \n",
    "                    # Extract sector (Technology, Healthcare, etc.)\n",
    "                    sector = data.get('summaryProfile', {}).get('sector', 'Unknown')\n",
    "                    \n",
    "                    # Get financial data\n",
    "                    fin_data = data.get('financialData', {})\n",
    "                    curr_ratio = fin_data.get('currentRatio', 0)      # Current Ratio\n",
    "                    op_margins = fin_data.get('operatingMargins', 0)  # Operating Margin (as decimal)\n",
    "                    if curr_ratio is None: \n",
    "                        curr_ratio = 0\n",
    "                    if op_margins is None: \n",
    "                        op_margins = 0\n",
    "\n",
    "                    # Get P/E ratio\n",
    "                    pe = data.get('summaryDetail', {}).get('trailingPE')\n",
    "\n",
    "                    # ====== APPLY FILTERS ======\n",
    "                    # Each 'continue' statement skips to the next stock\n",
    "                    \n",
    "                    # Skip if P/E is too high (overvalued)\n",
    "                    if pe is not None and pe > MAX_PE_RATIO: \n",
    "                        continue\n",
    "                    \n",
    "                    # Skip if price is too low (penny stock)\n",
    "                    if price < MIN_PRICE: \n",
    "                        continue\n",
    "                    \n",
    "                    # Skip if company is too small\n",
    "                    if cap < MIN_CAP: \n",
    "                        continue\n",
    "                    \n",
    "                    # Skip if not enough trading volume (hard to buy/sell)\n",
    "                    if vol < MIN_VOLUME: \n",
    "                        continue\n",
    "                    \n",
    "                    # Skip if in excluded sectors\n",
    "                    # any() returns True if ANY item in the list is True\n",
    "                    if any(x in sector for x in EXCLUDED_SECTORS): \n",
    "                        continue\n",
    "                    \n",
    "                    # Skip if current ratio is too low (can't pay bills)\n",
    "                    if curr_ratio < MIN_CURRENT_RATIO: \n",
    "                        continue\n",
    "                    \n",
    "                    # Skip if operating margin is zero or negative (not profitable)\n",
    "                    if op_margins <= 0: \n",
    "                        continue\n",
    "                    \n",
    "                    # If we get here, the stock passed ALL filters!\n",
    "                    # Add it to our survivors list\n",
    "                    survivors.append({\n",
    "                        'Ticker': symbol,\n",
    "                        'Sector': sector,\n",
    "                        'Price': price,\n",
    "                        'Op Margin %': round(op_margins * 100, 2),  # Convert to percentage\n",
    "                        'P/E': round(pe, 2) if pe else 0,\n",
    "                        'Curr Ratio': curr_ratio,\n",
    "                        'Mkt Cap (B)': round(cap / 1_000_000_000, 2)  # Convert to billions\n",
    "                    })\n",
    "                    \n",
    "                except:\n",
    "                    continue  # Skip this stock if any error occurs\n",
    "                    \n",
    "        except:\n",
    "            continue  # Skip this batch if any error occurs\n",
    "    \n",
    "    # Convert our list of dictionaries to a pandas DataFrame (table)\n",
    "    return pd.DataFrame(survivors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b09f64f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# CELL 5: STEP 3 - DEEP FINANCIAL ANALYSIS\n",
    "# =============================================================================\n",
    "# This is the detailed analysis phase. For each stock that passed Step 2,\n",
    "# we download detailed financial statements and calculate advanced metrics.\n",
    "\n",
    "def get_advanced_metrics(survivor_df):\n",
    "    \"\"\"\n",
    "    Perform deep financial analysis on stocks that passed initial screening.\n",
    "    \n",
    "    This is like the interview phase after resume screening.\n",
    "    We look at detailed financials to assess:\n",
    "    - Safety (interest coverage, debt levels)\n",
    "    - Quality (ROIC, consistent margins)\n",
    "    - Value (Z-Score)\n",
    "    \n",
    "    Args:\n",
    "        survivor_df: DataFrame of stocks from Step 2\n",
    "        \n",
    "    Returns:\n",
    "        DataFrame: Stocks with full analysis and tier classification\n",
    "    \"\"\"\n",
    "    tickers = survivor_df['Ticker'].tolist()\n",
    "    print(f\"\\n--- STEP 3: Fetching Deep Financials for {len(tickers)} Survivors ---\")\n",
    "    \n",
    "    # Load our cached data (data we've already fetched before)\n",
    "    cache = load_cache()\n",
    "    current_time = time.time()  # Current time in seconds since 1970 (Unix timestamp)\n",
    "    expiry_seconds = CACHE_EXPIRY_DAYS * 86400  # Convert days to seconds (86400 sec/day)\n",
    "    \n",
    "    final_data = []  # Will store our results\n",
    "    \n",
    "    # Loop through each stock\n",
    "    for i, ticker in enumerate(tickers):\n",
    "        # Print progress every 20 stocks\n",
    "        if i % 20 == 0: \n",
    "            print(f\" -> Analyzing {i+1}/{len(tickers)}: {ticker}...\")\n",
    "        \n",
    "        # Uncomment the line below if you're getting throttled (too many requests)\n",
    "        #time.sleep(0.5)  # Wait 0.75 seconds between requests\n",
    "        \n",
    "        def determine_tier_history(metrics, is_fortress_margin, is_pos_margin):\n",
    "            \"\"\"\n",
    "            Determine which tier (Fortress/Strong/Risky) a stock belongs to.\n",
    "            \n",
    "            Fortress = Best quality (strong margins, safe finances)\n",
    "            Strong = Good quality (positive margins, safe finances)\n",
    "            Risky = Questionable (poor margins or unsafe finances)\n",
    "            \"\"\"\n",
    "            # Safety checks first - must pass these regardless of margins\n",
    "            if metrics['int_cov'] < MIN_INTEREST_COVERAGE: \n",
    "                return \"Risky\"\n",
    "            if metrics['roic'] < MIN_ROIC: \n",
    "                return \"Risky\"\n",
    "            \n",
    "            # Then check historical margin performance\n",
    "            if is_fortress_margin:  # Average margin > 5%\n",
    "                return \"Fortress\"\n",
    "            elif is_pos_margin:     # Average margin > 0%\n",
    "                return \"Strong\"\n",
    "            \n",
    "            return \"Risky\"\n",
    "\n",
    "        # Check if we have cached data for this stock that's not expired\n",
    "        cached_data = cache.get(ticker)\n",
    "        if cached_data and (current_time - cached_data['timestamp'] < expiry_seconds):\n",
    "            if cached_data.get('roic') == -999: \n",
    "                continue  # Skip if previous fetch failed\n",
    "\n",
    "        # FETCH NEW DATA using yfinance\n",
    "        try:\n",
    "            stock = yf.Ticker(ticker)\n",
    "            fin = stock.financials      # Income statement data\n",
    "            bs = stock.balance_sheet    # Balance sheet data\n",
    "            \n",
    "            # Check if Yahoo actually gave us data\n",
    "            if fin.empty or bs.empty:\n",
    "                print(f\"   ‚ö†Ô∏è No data for {ticker} (skipping)\")\n",
    "                continue\n",
    "            \n",
    "            # --- CALCULATE 4-YEAR AVERAGE OPERATING MARGIN ---\n",
    "            # We look at multiple years to see if profitability is consistent\n",
    "            try:\n",
    "                # Try to get Operating Income (might be called different things)\n",
    "                if 'Operating Income' in fin.index:\n",
    "                    op_income_history = fin.loc['Operating Income']\n",
    "                elif 'EBIT' in fin.index:\n",
    "                    op_income_history = fin.loc['EBIT']\n",
    "                else:\n",
    "                    op_income_history = pd.Series([0])\n",
    "\n",
    "                # Get Revenue for same periods\n",
    "                revenue_history = fin.loc['Total Revenue']\n",
    "                \n",
    "                # Calculate margin for each year: Operating Income / Revenue\n",
    "                yearly_margins = (op_income_history / revenue_history).dropna()\n",
    "                \n",
    "                if len(yearly_margins) > 0:\n",
    "                    avg_margin = yearly_margins.mean()  # Average of all years\n",
    "                    \n",
    "                    # Check if average meets our thresholds\n",
    "                    is_fortress_margin = avg_margin > FORTRESS_MARGIN_THRESHOLD\n",
    "                    is_positive_margin = avg_margin > 0\n",
    "                else:\n",
    "                    is_fortress_margin = False\n",
    "                    is_positive_margin = False\n",
    "\n",
    "            except Exception as e:\n",
    "                is_fortress_margin = False\n",
    "                is_positive_margin = False\n",
    "\n",
    "            # --- STANDARD CALCULATIONS ---\n",
    "            def get_item(df, keys):\n",
    "                \"\"\"Helper to get values that might have different names.\"\"\"\n",
    "                for k in keys:\n",
    "                    if k in df.index: \n",
    "                        return df.loc[k].iloc[0]\n",
    "                return 0\n",
    "\n",
    "            # Get needed values\n",
    "            ebit = get_item(fin, ['EBIT', 'Operating Income', 'Pretax Income'])\n",
    "            int_exp = get_item(fin, ['Interest Expense', 'Interest Expense Non Operating'])\n",
    "            total_assets = get_item(bs, ['Total Assets'])\n",
    "            curr_liab = get_item(bs, ['Current Liabilities', 'Total Current Liabilities'])\n",
    "            \n",
    "            # Calculate Interest Coverage Ratio\n",
    "            # This tells us if the company can pay its interest bills\n",
    "            int_exp = abs(int_exp)  # Make positive (expenses are often negative)\n",
    "            if int_exp == 0: \n",
    "                int_cov = 100  # No debt = infinite coverage, use 100 as placeholder\n",
    "            else: \n",
    "                int_cov = ebit / int_exp\n",
    "            \n",
    "            # Calculate ROIC (Return on Invested Capital)\n",
    "            # Shows how efficiently management uses capital\n",
    "            invested_cap = total_assets - curr_liab  # Simplified invested capital\n",
    "            if invested_cap <= 0: \n",
    "                roic = 0\n",
    "            else: \n",
    "                roic = ebit / invested_cap\n",
    "            \n",
    "            # Calculate Altman Z-Score\n",
    "            base_row = survivor_df[survivor_df['Ticker'] == ticker].iloc[0]\n",
    "            mkt_cap_raw = base_row['Mkt Cap (B)'] * 1_000_000_000  # Convert back to dollars\n",
    "            z = calculate_altman_z_yfinance(bs, fin, mkt_cap_raw)\n",
    "            \n",
    "            # Store metrics in cache for future use\n",
    "            metrics = {\n",
    "                'timestamp': current_time,\n",
    "                'z_score': round(z, 2),\n",
    "                'roic': roic,\n",
    "                'int_cov': round(int_cov, 2)\n",
    "            }\n",
    "            cache[ticker] = metrics\n",
    "            \n",
    "            # Determine final tier based on all metrics\n",
    "            tier = determine_tier_history(metrics, is_fortress_margin, is_positive_margin)\n",
    "\n",
    "            # Add all data to our final results\n",
    "            final_data.append({\n",
    "                'Ticker': ticker,\n",
    "                'Tier': tier,\n",
    "                'Price': base_row['Price'],\n",
    "                'P/E': base_row['P/E'],\n",
    "                'Sector': base_row['Sector'],\n",
    "                'Z-Score': round(z, 2),\n",
    "                'ROIC %': round(roic * 100, 2),\n",
    "                'Op Margin %': base_row['Op Margin %'],\n",
    "                'Avg Margin (4Y)': round(avg_margin * 100, 2) if 'avg_margin' in locals() else 0,\n",
    "                'Curr Ratio': base_row['Curr Ratio'],\n",
    "                'Int Cov': round(int_cov, 2),\n",
    "                'Mkt Cap (B)': base_row['Mkt Cap (B)']\n",
    "            })\n",
    "            \n",
    "        except Exception as e:\n",
    "            continue  # Skip if any error\n",
    "\n",
    "    # Save updated cache to file\n",
    "    save_cache(cache)\n",
    "    \n",
    "    return pd.DataFrame(final_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "a5361c2f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception ignored from cffi callback <function buffer_callback at 0x000001CD29038900>:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\James\\anaconda3\\Lib\\site-packages\\curl_cffi\\curl.py\", line 101, in buffer_callback\n",
      "    @ffi.def_extern()\n",
      "KeyboardInterrupt: \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   ‚ö†Ô∏è No data for QCOM (skipping)\n",
      "\n",
      "============================================================\n",
      "RESULTS GENERATED\n",
      "============================================================\n",
      "1. FORTRESS (190): Saved to 'YfinanceDataDump\\fortress_stocks.csv'\n",
      "2. STRONG   (19): Saved to 'YfinanceDataDump\\strong_stocks.csv'\n",
      "3. RISKY    (119): Saved to 'YfinanceDataDump\\risky_stocks.csv'\n",
      "\n",
      "--- FORTRESS PREVIEW ---\n",
      "    Ticker      Tier   Price    P/E                  Sector  Z-Score  ROIC %  Op Margin %  Avg Margin (4Y)  Curr Ratio  Int Cov  Mkt Cap (B)\n",
      "276   ISRG  Fortress  566.36  75.21              Healthcare    56.74   13.82        30.33            27.54       4.728   100.00       203.03\n",
      "35     APP  Fortress  673.82  79.37  Communication Services    30.88   39.37        76.80            15.80       3.250     5.95       227.92\n",
      "185   FAST  Fortress   40.13  37.86             Industrials    29.95   37.78        20.70            20.47       4.259   207.59        46.07\n",
      "154   DOCS  Fortress   44.28  35.42              Healthcare    29.69   20.77        38.55            34.85       7.786   100.00         8.34\n",
      "120   CPRT  Fortress   39.15  24.02             Industrials    28.48   18.04        37.29            37.83       7.939      NaN        37.90\n",
      "31    ANET  Fortress  131.03  49.82              Technology    27.18   26.03        42.38            36.70       3.254   100.00       165.00\n",
      "46     ASM  Fortress    6.21  44.36         Basic Materials    25.54   11.12        32.56             6.68       2.754    38.26         0.97\n",
      "229   GOOG  Fortress  313.80  30.95  Communication Services    20.78   33.25        30.51            29.14       1.747   448.07      3788.14\n",
      "121   CPRX  Fortress   23.34  13.65              Healthcare    16.42   26.70        44.66            36.56       6.622   100.00         2.87\n",
      "118   CORT  Fortress   34.80  40.00              Healthcare    16.40   19.57         4.92            26.14       3.141   100.00         3.67\n",
      "98    CDNS  Fortress  312.58  80.56              Technology    14.23   19.35        35.09            29.17       3.048    19.37        85.17\n",
      "227   GNTX  Fortress   23.27  13.77       Consumer Cyclical    13.09   18.68        18.75            21.19       2.962   100.00         5.11\n",
      "145   DECK  Fortress  103.67  15.40       Consumer Cyclical    12.88   44.52        22.82            20.30       3.067   354.51        15.38\n",
      "181     EW  Fortress   85.25  37.39              Healthcare    12.70   13.57        27.37            30.42       4.004    79.19        50.05\n",
      "128   CTAS  Fortress  188.07  40.62             Industrials    12.59   28.91        23.42            21.26       1.705    23.39        75.78\n"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# CELL 6: MAIN EXECUTION\n",
    "# =============================================================================\n",
    "# This is where we actually RUN all the functions we defined above.\n",
    "# The 'if __name__ == \"__main__\":' is a Python convention - it means\n",
    "# \"only run this code if this file is being run directly, not imported\"\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # STEP 1: Get list of all Canadian stocks\n",
    "    tickers = get_combined_universe()\n",
    "    \n",
    "    if len(tickers) > 0:\n",
    "        # STEP 2: Apply quick filters\n",
    "        survivors_df = get_initial_survivors(tickers)\n",
    "        \n",
    "        if not survivors_df.empty:\n",
    "            print(f\"\\n‚úÖ Step 2 Complete. {len(survivors_df)} stocks passed basic filters.\")\n",
    "            \n",
    "            # STEP 3: Deep financial analysis\n",
    "            final_results = get_advanced_metrics(survivors_df)\n",
    "            \n",
    "            if not final_results.empty:\n",
    "                # Sort results: First by Tier (alphabetically), then by Z-Score (highest first)\n",
    "                final_results = final_results.sort_values(\n",
    "                    by=['Tier', 'Z-Score'], \n",
    "                    ascending=[True, False]  # True = A-Z, False = highest first\n",
    "                )\n",
    "                \n",
    "                # Split into three categories based on tier\n",
    "                fortress_df = final_results[final_results['Tier'] == 'Fortress'].copy()\n",
    "                strong_df = final_results[final_results['Tier'] == 'Strong'].copy()\n",
    "                risky_df = final_results[final_results['Tier'] == 'Risky'].copy()\n",
    "                \n",
    "                # Save to CSV files (spreadsheet format)\n",
    "                try:\n",
    "                    fortress_df.to_csv(FORTRESS_CSV, index=False)  # index=False means don't save row numbers\n",
    "                    strong_df.to_csv(STRONG_CSV, index=False)\n",
    "                    risky_df.to_csv(RISKY_CSV, index=False)\n",
    "                    \n",
    "                    print(\"\\n\" + \"=\"*60)\n",
    "                    print(\"RESULTS GENERATED\")\n",
    "                    print(\"=\"*60)\n",
    "                    print(f\"1. FORTRESS ({len(fortress_df)}): Saved to '{FORTRESS_CSV}'\")\n",
    "                    print(f\"2. STRONG   ({len(strong_df)}): Saved to '{STRONG_CSV}'\")\n",
    "                    print(f\"3. RISKY    ({len(risky_df)}): Saved to '{RISKY_CSV}'\")\n",
    "                    \n",
    "                except Exception as e:\n",
    "                    print(f\"\\n‚ö†Ô∏è Error Saving Files: {e}\")\n",
    "                \n",
    "                # Set display options for pandas (so we can see more data)\n",
    "                pd.set_option('display.max_rows', 500)\n",
    "                pd.set_option('display.max_columns', 20)\n",
    "                pd.set_option('display.width', 1000)\n",
    "                \n",
    "                # Show preview of fortress stocks\n",
    "                print(\"\\n--- FORTRESS PREVIEW ---\")\n",
    "                print(fortress_df.head(15))  # .head(15) shows first 15 rows\n",
    "            else:\n",
    "                print(\"No stocks passed the deep financial analysis.\")\n",
    "        else:\n",
    "            print(\"No stocks passed the initial lightweight filter.\")\n",
    "    else:\n",
    "        print(\"Could not fetch ticker universe.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36ee3ec0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# CELL 7: STEP 4 - ANALYST RATINGS FILTER\n",
    "# =============================================================================\n",
    "# This adds another layer of analysis: what do professional analysts think?\n",
    "# Analyst Rating Scale (typically):\n",
    "#   1.0 = Strong Buy\n",
    "#   2.0 = Buy  \n",
    "#   3.0 = Hold\n",
    "#   4.0 = Sell\n",
    "#   5.0 = Strong Sell\n",
    "\n",
    "def get_analyst_fortress_from_var(df_input):\n",
    "    \"\"\"\n",
    "    Fetch analyst ratings for stocks and filter for those rated \"Buy\" or better.\n",
    "    \n",
    "    Args:\n",
    "        df_input: DataFrame of stocks to analyze (usually fortress_df)\n",
    "        \n",
    "    Returns:\n",
    "        DataFrame: Stocks with analyst ratings and upside potential\n",
    "    \"\"\"\n",
    "    working_df = df_input.copy()\n",
    "    tickers = working_df['Ticker'].tolist()\n",
    "    \n",
    "    print(f\"\\n--- STEP 4: Fetching Analyst Ratings for {len(tickers)} Stocks ---\")\n",
    "    print(\"    (Fetching serially to avoid throttling...)\")\n",
    "    \n",
    "    analyst_data = []\n",
    "    \n",
    "    for i, ticker in enumerate(tickers):\n",
    "        # Print progress every 10 stocks\n",
    "        if i % 10 == 0: \n",
    "            print(f\" -> Analyst Scan {i+1}/{len(tickers)}: {ticker}...\")\n",
    "        \n",
    "        try:\n",
    "            stock = yf.Ticker(ticker)\n",
    "            info = stock.info  # Get all available info for the stock\n",
    "            \n",
    "            # Extract analyst recommendation (1.0 to 5.0 scale)\n",
    "            rec_mean = info.get('recommendationMean')\n",
    "            target_price = info.get('targetMeanPrice')  # Average price target\n",
    "            current_price = info.get('currentPrice')\n",
    "            \n",
    "            # Filter: Only keep stocks rated 2.0 or better (Buy or Strong Buy)\n",
    "            if rec_mean is None or rec_mean > 2.0: \n",
    "                continue\n",
    "            \n",
    "            # Calculate upside potential\n",
    "            # Upside = (Target - Current) / Current * 100\n",
    "            upside = 0\n",
    "            if target_price and current_price:\n",
    "                upside = round(((target_price - current_price) / current_price) * 100, 2)\n",
    "            \n",
    "            # Get the original data and add new columns\n",
    "            base_row = working_df[working_df['Ticker'] == ticker].iloc[0].to_dict()\n",
    "            base_row['Analyst_Rating'] = rec_mean\n",
    "            base_row['Target_Price'] = target_price\n",
    "            base_row['Upside_%'] = upside\n",
    "            \n",
    "            analyst_data.append(base_row)\n",
    "            time.sleep(0.2)  # Small delay to be nice to Yahoo's servers\n",
    "            \n",
    "        except Exception:\n",
    "            continue\n",
    "            \n",
    "    return pd.DataFrame(analyst_data)\n",
    "\n",
    "# ==========================================\n",
    "# EXECUTE THE ANALYST FILTER\n",
    "# ==========================================\n",
    "\n",
    "# Check if fortress_df exists from the previous step\n",
    "if 'fortress_df' in locals() and not fortress_df.empty:\n",
    "    \n",
    "    # Run the function\n",
    "    Analyst_Fortress_DF = get_analyst_fortress_from_var(fortress_df)\n",
    "    \n",
    "    if not Analyst_Fortress_DF.empty:\n",
    "        # Sort by highest upside potential\n",
    "        Analyst_Fortress_DF = Analyst_Fortress_DF.sort_values(by='Upside_%', ascending=False)\n",
    "        \n",
    "        print(\"\\n‚úÖ Analyst Scan Complete!\")\n",
    "        print(f\"Found {len(Analyst_Fortress_DF)} stocks with Buy Ratings (Score < 2.0)\")\n",
    "        \n",
    "        # Save to CSV\n",
    "        Analyst_Fortress_DF.to_csv(ANALYST_CSV, index=False)\n",
    "        print(f\"Saved to '{ANALYST_CSV}'\")\n",
    "        \n",
    "        # Show top picks\n",
    "        cols = ['Ticker', 'Price', 'Analyst_Rating', 'Upside_%', 'Target_Price', 'Tier']\n",
    "        print(Analyst_Fortress_DF[cols].head(20))\n",
    "    else:\n",
    "        print(\"No stocks passed the Analyst filter.\")\n",
    "else:\n",
    "    print(\"‚ùå 'fortress_df' not found. Please run Steps 1-3 first.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca466fcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# CELL 8: BUFFETT VALUE SCAN\n",
    "# =============================================================================\n",
    "# This filter looks for stocks Warren Buffett might like:\n",
    "# - Trading BELOW book value (P/B < 1.0) means you're buying $1 of assets for less than $1\n",
    "# - Positive Return on Equity (ROE) shows the company is profitable\n",
    "# - Reasonable debt levels (Debt/Equity < 100%)\n",
    "\n",
    "def get_buffett_value_picks(df_input):\n",
    "    \"\"\"\n",
    "    Find deep value stocks trading below their book value.\n",
    "    \n",
    "    Book Value = Total Assets - Total Liabilities\n",
    "    P/B Ratio = Stock Price / Book Value per Share\n",
    "    \n",
    "    If P/B < 1.0, you're theoretically buying the company for less than\n",
    "    what it would be worth if you sold all its assets and paid all debts.\n",
    "    \n",
    "    Args:\n",
    "        df_input: DataFrame of stocks to analyze\n",
    "        \n",
    "    Returns:\n",
    "        DataFrame: Deep value stocks sorted by P/B ratio\n",
    "    \"\"\"\n",
    "    print(f\"\\n--- STEP 5: Warren Buffett 'Below NAV' Scan ---\")\n",
    "    print(f\"    Scanning {len(df_input)} candidates for Deep Value...\")\n",
    "    print(\"    Criteria: P/B < 1.0 (Below Book) | ROE > 0% (Profitable) | Debt/Eq < 100%\")\n",
    "\n",
    "    tickers = df_input['Ticker'].tolist()\n",
    "    buffett_candidates = []\n",
    "\n",
    "    # Process in chunks for speed\n",
    "    chunk_size = 250\n",
    "    chunks = [tickers[i:i + chunk_size] for i in range(0, len(tickers), chunk_size)]\n",
    "\n",
    "    for chunk in chunks:\n",
    "        try:\n",
    "            yq = Ticker(chunk, asynchronous=True)\n",
    "            # Get key statistics and financial data\n",
    "            data = yq.get_modules(\"defaultKeyStatistics financialData\")\n",
    "\n",
    "            for symbol in chunk:\n",
    "                if isinstance(data, dict) and symbol in data:\n",
    "                    try:\n",
    "                        stats = data[symbol].get('defaultKeyStatistics', {})\n",
    "                        fin = data[symbol].get('financialData', {})\n",
    "\n",
    "                        # 1. Price to Book < 1.0 (The Core \"Value\" Rule)\n",
    "                        pb = stats.get('priceToBook')\n",
    "                        if pb is None or pb >= 1.0 or pb <= 0: \n",
    "                            continue\n",
    "\n",
    "                        # 2. Positive ROE (Return on Equity - company makes money)\n",
    "                        roe = fin.get('returnOnEquity', 0)\n",
    "                        if roe is None or roe <= 0: \n",
    "                            continue\n",
    "\n",
    "                        # 3. Reasonable Debt (not overleveraged)\n",
    "                        de = fin.get('debtToEquity', 0)\n",
    "                        if de is None or de > 100: \n",
    "                            continue\n",
    "\n",
    "                        # Get base data and add value metrics\n",
    "                        base_row = df_input[df_input['Ticker'] == symbol].iloc[0].to_dict()\n",
    "                        base_row['P/B Ratio'] = round(pb, 2)\n",
    "                        base_row['ROE %'] = round(roe * 100, 2)\n",
    "                        base_row['Debt/Eq %'] = round(de, 2)\n",
    "\n",
    "                        buffett_candidates.append(base_row)\n",
    "\n",
    "                    except: \n",
    "                        continue\n",
    "        except: \n",
    "            continue\n",
    "\n",
    "    return pd.DataFrame(buffett_candidates)\n",
    "\n",
    "# Run the Buffett scan\n",
    "if 'final_results' in locals() and not final_results.empty:\n",
    "    Buffett_Value_DF = get_buffett_value_picks(final_results)\n",
    "    \n",
    "    if not Buffett_Value_DF.empty:\n",
    "        Buffett_Value_DF = Buffett_Value_DF.sort_values(by='P/B Ratio', ascending=True)\n",
    "        Buffett_Value_DF.to_csv(BUFFETT_CSV, index=False)\n",
    "        \n",
    "        print(\"\\n\" + \"=\"*60)\n",
    "        print(\"BUFFETT SCAN COMPLETE\")\n",
    "        print(\"=\"*60)\n",
    "        print(f\"Found {len(Buffett_Value_DF)} Deep Value Stocks\")\n",
    "        \n",
    "        cols = ['Ticker', 'Price', 'P/B Ratio', 'ROE %', 'Debt/Eq %', 'Sector', 'Tier']\n",
    "        print(\"\\n--- DEEP VALUE PICKS ---\")\n",
    "        print(Buffett_Value_DF[cols].head(20))\n",
    "    else:\n",
    "        print(\"\\n‚ùå No stocks passed the Buffett filter.\")\n",
    "else:\n",
    "    print(\"‚ùå 'final_results' not found. Please run Steps 1-3 first.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c744c9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# CELL 9: INSIDER TRADING FILTER\n",
    "# =============================================================================\n",
    "# Insiders (executives, directors, major shareholders) sometimes have better\n",
    "# information about their company. When they BUY their own stock, it can be\n",
    "# a positive sign. When they SELL, it might be neutral (paying taxes) or negative.\n",
    "\n",
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "\n",
    "def filter_for_insider_buying(tickers):\n",
    "    \"\"\"\n",
    "    Find stocks where company insiders are NET BUYERS.\n",
    "    \n",
    "    Net Buying = Total shares bought - Total shares sold\n",
    "    If positive, insiders are accumulating shares (bullish signal).\n",
    "    \n",
    "    Args:\n",
    "        tickers: List of stock symbols to check\n",
    "        \n",
    "    Returns:\n",
    "        DataFrame: Stocks with positive insider buying\n",
    "    \"\"\"\n",
    "    print(f\"üïµÔ∏è Scanning {len(tickers)} stocks for Insider Buying...\")\n",
    "    insider_picks = []\n",
    "    \n",
    "    # Process in smaller chunks to avoid timeout\n",
    "    chunk_size = 20\n",
    "    chunks = [tickers[i:i + chunk_size] for i in range(0, len(tickers), chunk_size)]\n",
    "    \n",
    "    for chunk in chunks:\n",
    "        try:\n",
    "            yq = Ticker(chunk, asynchronous=True)\n",
    "            \n",
    "            # Fetch insider transaction data\n",
    "            df_insiders = yq.insider_transactions\n",
    "            \n",
    "            # Fetch current prices\n",
    "            price_data = yq.price\n",
    "            \n",
    "            # Skip if no data\n",
    "            if isinstance(df_insiders, dict) or not hasattr(df_insiders, 'reset_index'):\n",
    "                continue\n",
    "            \n",
    "            df_insiders = df_insiders.reset_index()\n",
    "\n",
    "            for symbol in chunk:\n",
    "                if symbol not in df_insiders['symbol'].values:\n",
    "                    continue\n",
    "                \n",
    "                # Get transactions for this stock\n",
    "                stock_tx = df_insiders[df_insiders['symbol'] == symbol].copy()\n",
    "                \n",
    "                # Separate purchases and sales\n",
    "                # The text typically says \"Purchase\" or \"Sale\"\n",
    "                buys = stock_tx[stock_tx['transactionText'].astype(str).str.contains(\n",
    "                    \"Purchase\", case=False, na=False)]\n",
    "                sells = stock_tx[stock_tx['transactionText'].astype(str).str.contains(\n",
    "                    \"Sale\", case=False, na=False)]\n",
    "                \n",
    "                # Calculate total buy/sell volume\n",
    "                buy_vol = buys['shares'].sum() if not buys.empty else 0\n",
    "                sell_vol = sells['shares'].sum() if not sells.empty else 0\n",
    "                \n",
    "                # Get current price\n",
    "                current_price = None\n",
    "                try:\n",
    "                    if isinstance(price_data, dict) and symbol in price_data:\n",
    "                        current_price = price_data[symbol].get('regularMarketPrice', None)\n",
    "                except:\n",
    "                    current_price = None\n",
    "\n",
    "                # Only keep if net buying is positive\n",
    "                if buy_vol > sell_vol:\n",
    "                    insider_picks.append({\n",
    "                        'Ticker': symbol,\n",
    "                        'Current_Price': current_price,\n",
    "                        'Insider_Buys_Count': len(buys),\n",
    "                        'Net_Shares_Bought': buy_vol - sell_vol\n",
    "                    })\n",
    "                        \n",
    "        except Exception as e:\n",
    "            continue\n",
    "\n",
    "    return pd.DataFrame(insider_picks)\n",
    "\n",
    "# Run the insider filter\n",
    "if 'fortress_df' in locals() and not fortress_df.empty:\n",
    "    target_tickers = fortress_df['Ticker'].tolist()\n",
    "else:\n",
    "    print(\"‚ö†Ô∏è 'fortress_df' not found.\")\n",
    "\n",
    "Fortress_insiders = filter_for_insider_buying(target_tickers)\n",
    "print(f\"‚úÖ Created 'Fortress_insiders' with {len(Fortress_insiders)} rows.\")\n",
    "display(Fortress_insiders)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb164c43",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# ==========================================\n",
    "# 10. ANALYST FILTER FUNCTION FOR INSIDER PICKS (NEW)\n",
    "# ==========================================\n",
    "def filter_for_analyst_ratings(df_insiders, max_score=2.5):\n",
    "    \"\"\"\n",
    "    Fetches analyst data for the insider winners and filters for 'Buy' or better.\n",
    "    Scale: 1.0 = Strong Buy, 5.0 = Sell.\n",
    "    Cutoff: 2.5 ensures we get 'Buy' and 'Strong Buy'.\n",
    "    \"\"\"\n",
    "    if df_insiders.empty:\n",
    "        return df_insiders\n",
    "        \n",
    "    tickers = df_insiders['Ticker'].tolist()\n",
    "    \n",
    "    \n",
    "    try:\n",
    "        yq = Ticker(tickers, asynchronous=True)\n",
    "        # 'financial_data' contains the specific recommendation scores\n",
    "        fin_data = yq.financial_data\n",
    "        \n",
    "        analyst_data = []\n",
    "        for t in tickers:\n",
    "            # Check if we got valid data for this ticker\n",
    "            if isinstance(fin_data, dict) and t in fin_data:\n",
    "                data = fin_data[t]\n",
    "                # Ensure it's a dictionary and has the key we need\n",
    "                if isinstance(data, dict) and 'recommendationMean' in data:\n",
    "                    score = data.get('recommendationMean')\n",
    "                    \n",
    "                    # Only keep valid scores (sometimes they are None)\n",
    "                    if score is not None:\n",
    "                        analyst_data.append({\n",
    "                            'Ticker': t,\n",
    "                            'Analyst_Score': score,\n",
    "                            'Analyst_Verdict': data.get('recommendationKey', 'N/A')\n",
    "                        })\n",
    "        \n",
    "        df_analyst = pd.DataFrame(analyst_data)\n",
    "        \n",
    "        if df_analyst.empty:\n",
    "            print(\"‚ö†Ô∏è No Analyst ratings found for these tickers.\")\n",
    "            return df_insiders # Return original if no data found\n",
    "            \n",
    "        # Merge with the Insider DataFrame\n",
    "        merged = pd.merge(df_insiders, df_analyst, on='Ticker', how='inner')\n",
    "        \n",
    "        # FILTER: Keep only scores <= max_score (Lower is better)\n",
    "        final_df = merged[merged['Analyst_Score'] <= max_score].copy()\n",
    "        \n",
    "        print(f\"‚úÖ Analyst Filter: {len(merged)} -> {len(final_df)} stocks (Min Rating: Buy).\")\n",
    "        return final_df.sort_values(by='Analyst_Score', ascending=True)\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Error in Analyst Filter: {e}\")\n",
    "        return df_insiders\n",
    "\n",
    "# ==========================================\n",
    "# 3. EXECUTION PIPELINE\n",
    "# ==========================================\n",
    "\n",
    "# A. Setup Tickers\n",
    "if 'fortress_df' in locals() and not fortress_df.empty:\n",
    "    target_tickers = fortress_df['Ticker'].tolist()\n",
    "else:\n",
    "    # Backup list just in case\n",
    "    target_tickers = [\n",
    "        'PET.TO', 'MFI.TO', 'TXG.TO', 'SAP.TO', 'PAAS.TO', 'NEO.TO', 'WPM.TO', \n",
    "        'FNV.TO', 'LUG.TO', 'DPM.TO', 'ASM.TO', 'PNG.V', 'DSG.TO', 'KNT.TO', \n",
    "        'GGD.TO', 'GRGD.TO', 'WDO.TO', 'OGC.TO', 'DNG.TO', 'CLS.TO'\n",
    "    ]\n",
    "\n",
    "# B. Run Insider Filter\n",
    "insider_winners = filter_for_insider_buying(target_tickers)\n",
    "\n",
    "# C. Run Analyst Filter (NEW STEP)\n",
    "# We overwrite 'Fortress_insiders' so it works with your Data Wrangler flow\n",
    "if not insider_winners.empty:\n",
    "    Fortress_insiders_Analyst_buy = filter_for_analyst_ratings(insider_winners, max_score=2.5)\n",
    "else:\n",
    "    Fortress_insiders_Analyst_buy = pd.DataFrame()\n",
    "\n",
    "# D. Display Result\n",
    "if not Fortress_insiders_Analyst_buy.empty:\n",
    "    print(f\"\\nüöÄ Final List: {len(Fortress_insiders_Analyst_buy)} stocks (Fortress + Insider Buying + Analyst Buy Rating)\")\n",
    "    display(Fortress_insiders_Analyst_buy)\n",
    "else:\n",
    "    print(\"No stocks passed all filters.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d999738",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# CELL 11: BURRY EV/EBITDA FILTER\n",
    "# =============================================================================\n",
    "# EV/EBITDA is a valuation metric popular with hedge fund manager Michael Burry.\n",
    "# \n",
    "# EV = Enterprise Value = Market Cap + Debt - Cash\n",
    "#      (What it would cost to buy the whole company)\n",
    "# \n",
    "# EBITDA = Earnings Before Interest, Taxes, Depreciation, and Amortization\n",
    "#          (Proxy for operating cash flow)\n",
    "# \n",
    "# EV/EBITDA tells you how many years of cash flow it would take to buy the company.\n",
    "# Lower is better (cheaper stock).\n",
    "# We compare each stock to its SECTOR AVERAGE to find relative value.\n",
    "\n",
    "def filter_burry_ev_ebitda(df_input):\n",
    "    \"\"\"\n",
    "    Find stocks trading at a discount to their sector average.\n",
    "    \n",
    "    Logic: A stock with EV/EBITDA of 8x is \"cheap\" in a sector \n",
    "           where the average is 15x.\n",
    "    \n",
    "    Args:\n",
    "        df_input: DataFrame of stocks to analyze (usually fortress_df)\n",
    "        \n",
    "    Returns:\n",
    "        DataFrame: Stocks cheaper than their sector average\n",
    "    \"\"\"\n",
    "    if df_input is None or df_input.empty:\n",
    "        print(\"‚ùå Input DataFrame is empty.\")\n",
    "        return pd.DataFrame()\n",
    "\n",
    "    print(f\"üìâ Analyzing EV/EBITDA for {len(df_input)} Fortress stocks...\")\n",
    "    \n",
    "    tickers = df_input['Ticker'].tolist()\n",
    "    \n",
    "    # Fetch data in bulk\n",
    "    try:\n",
    "        yq = Ticker(tickers, asynchronous=True)\n",
    "        data = yq.get_modules('defaultKeyStatistics financialData summaryDetail')\n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Error fetching data: {e}\")\n",
    "        return pd.DataFrame()\n",
    "\n",
    "    ev_data = []\n",
    "    \n",
    "    for ticker in tickers:\n",
    "        try:\n",
    "            ticker_data = data.get(ticker, {})\n",
    "            if isinstance(ticker_data, str): \n",
    "                continue\n",
    "            \n",
    "            stats = ticker_data.get('defaultKeyStatistics', {})\n",
    "            fin_data = ticker_data.get('financialData', {})\n",
    "            summary = ticker_data.get('summaryDetail', {})\n",
    "\n",
    "            # Try to get pre-calculated EV/EBITDA\n",
    "            ev_ebitda = stats.get('enterpriseToEbitda')\n",
    "            \n",
    "            # If not available, calculate manually\n",
    "            if ev_ebitda is None:\n",
    "                try:\n",
    "                    market_cap = summary.get('marketCap')\n",
    "                    total_debt = fin_data.get('totalDebt')\n",
    "                    total_cash = fin_data.get('totalCash')\n",
    "                    ebitda = fin_data.get('ebitda')\n",
    "                    \n",
    "                    if all(v is not None for v in [market_cap, total_debt, total_cash, ebitda]):\n",
    "                        if ebitda != 0:\n",
    "                            # EV = Market Cap + Debt - Cash\n",
    "                            enterprise_value = market_cap + total_debt - total_cash\n",
    "                            ev_ebitda = enterprise_value / ebitda\n",
    "                except:\n",
    "                    pass\n",
    "\n",
    "            # Only include positive values (profitable companies)\n",
    "            if ev_ebitda is not None and ev_ebitda > 0:\n",
    "                ev_data.append({\n",
    "                    'Ticker': ticker,\n",
    "                    'EV/EBITDA': round(ev_ebitda, 2)\n",
    "                })\n",
    "        except:\n",
    "            continue\n",
    "            \n",
    "    df_vals = pd.DataFrame(ev_data)\n",
    "    \n",
    "    if df_vals.empty:\n",
    "        print(\"‚ö†Ô∏è Could not retrieve EV/EBITDA data.\")\n",
    "        return pd.DataFrame()\n",
    "\n",
    "    # Merge with sector data\n",
    "    merged_df = pd.merge(df_input, df_vals, on='Ticker', how='inner')\n",
    "    \n",
    "    # Calculate sector averages\n",
    "    print(\"\\n--- üìä SECTOR AVERAGES (EV/EBITDA) ---\")\n",
    "    sector_stats = merged_df.groupby('Sector')['EV/EBITDA'].mean().reset_index()\n",
    "    sector_stats.rename(columns={'EV/EBITDA': 'Sector_Avg_EV_EBITDA'}, inplace=True)\n",
    "    sector_stats['Sector_Avg_EV_EBITDA'] = sector_stats['Sector_Avg_EV_EBITDA'].round(2)\n",
    "    \n",
    "    print(sector_stats.to_string(index=False))\n",
    "    \n",
    "    # Merge with sector averages\n",
    "    final_df = pd.merge(merged_df, sector_stats, on='Sector', how='left')\n",
    "    \n",
    "    # Filter: Keep only stocks CHEAPER than sector average\n",
    "    burry_picks = final_df[final_df['EV/EBITDA'] < final_df['Sector_Avg_EV_EBITDA']].copy()\n",
    "    \n",
    "    # Calculate discount percentage\n",
    "    # Discount = 1 - (Stock EV/EBITDA / Sector Average)\n",
    "    burry_picks['Discount_%'] = round(\n",
    "        (1 - (burry_picks['EV/EBITDA'] / burry_picks['Sector_Avg_EV_EBITDA'])) * 100, 2\n",
    "    )\n",
    "    \n",
    "    # Sort by biggest discount\n",
    "    burry_picks = burry_picks.sort_values(by='Discount_%', ascending=False)\n",
    "    \n",
    "    return burry_picks\n",
    "\n",
    "# Run the Burry filter\n",
    "if 'fortress_df' in locals() and not fortress_df.empty:\n",
    "    Fortress_Burry_EV_EBITDA = filter_burry_ev_ebitda(fortress_df)\n",
    "    \n",
    "    if not Fortress_Burry_EV_EBITDA.empty:\n",
    "        print(f\"\\n‚úÖ Found {len(Fortress_Burry_EV_EBITDA)} Undervalued Stocks\")\n",
    "        display(Fortress_Burry_EV_EBITDA[['Ticker', 'Sector', 'Price', 'EV/EBITDA', \n",
    "                                          'Sector_Avg_EV_EBITDA', 'Discount_%', 'Tier']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efa7b10c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# ==========================================\n",
    "# 12. ANALYST FILTER FUNCTION FOR INSIDER PICKS (NEW)\n",
    "# ==========================================\n",
    "def filter_for_analyst_ratings(Fortress_Burry_EV_EBITDA, max_score=2.5):\n",
    "    \"\"\"\n",
    "    Fetches analyst data for the insider winners and filters for 'Buy' or better.\n",
    "    Scale: 1.0 = Strong Buy, 5.0 = Sell.\n",
    "    Cutoff: 2.5 ensures we get 'Buy' and 'Strong Buy'.\n",
    "    \"\"\"\n",
    "    if Fortress_Burry_EV_EBITDA.empty:\n",
    "        return Fortress_Burry_EV_EBITDA\n",
    "        \n",
    "    tickers = Fortress_Burry_EV_EBITDA['Ticker'].tolist()\n",
    "    \n",
    "    \n",
    "    try:\n",
    "        yq = Ticker(tickers, asynchronous=True)\n",
    "        # 'financial_data' contains the specific recommendation scores\n",
    "        fin_data = yq.financial_data\n",
    "        \n",
    "        analyst_data = []\n",
    "        for t in tickers:\n",
    "            # Check if we got valid data for this ticker\n",
    "            if isinstance(fin_data, dict) and t in fin_data:\n",
    "                data = fin_data[t]\n",
    "                # Ensure it's a dictionary and has the key we need\n",
    "                if isinstance(data, dict) and 'recommendationMean' in data:\n",
    "                    score = data.get('recommendationMean')\n",
    "                    \n",
    "                    # Only keep valid scores (sometimes they are None)\n",
    "                    if score is not None:\n",
    "                        analyst_data.append({\n",
    "                            'Ticker': t,\n",
    "                            'Analyst_Score': score,\n",
    "                            'Analyst_Verdict': data.get('recommendationKey', 'N/A')\n",
    "                        })\n",
    "        \n",
    "        df_analyst = pd.DataFrame(analyst_data)\n",
    "        \n",
    "        if df_analyst.empty:\n",
    "            print(\"‚ö†Ô∏è No Analyst ratings found for these tickers.\")\n",
    "            return Fortress_Burry_EV_EBITDA # Return original if no data found\n",
    "            \n",
    "        # Merge with the Fortress DataFrame\n",
    "        merged = pd.merge(Fortress_Burry_EV_EBITDA, df_analyst, on='Ticker', how='inner')\n",
    "        \n",
    "        # FILTER: Keep only scores <= max_score (Lower is better)\n",
    "        final_df = merged[merged['Analyst_Score'] <= max_score].copy()\n",
    "        \n",
    "        print(f\"‚úÖ Analyst Filter: {len(merged)} -> {len(final_df)} stocks (Min Rating: Buy).\")\n",
    "        return final_df.sort_values(by='Analyst_Score', ascending=True)\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Error in Analyst Filter: {e}\")\n",
    "        return Fortress_Burry_EV_EBITDA\n",
    "\n",
    "# ==========================================\n",
    "# 3. EXECUTION PIPELINE\n",
    "# ==========================================\n",
    "\n",
    "# A. Setup Tickers\n",
    "if 'Fortress_Burry_EV_EBITDA' in locals() and not Fortress_Burry_EV_EBITDA.empty:\n",
    "    target_tickers = Fortress_Burry_EV_EBITDA['Ticker'].tolist()\n",
    "\n",
    "\n",
    "# B. Run Insider Filter\n",
    "Fortress_Burry_EV_EBITDA = filter_burry_ev_ebitda(fortress_df)\n",
    "\n",
    "# C. Run Analyst Filter (NEW STEP)\n",
    "# We overwrite 'Fortress_insiders' so it works with your Data Wrangler flow\n",
    "if not Fortress_Burry_EV_EBITDA.empty:\n",
    "    Fortress_Burry_Analyst_buy = filter_for_analyst_ratings(Fortress_Burry_EV_EBITDA, max_score=2.5)\n",
    "else:\n",
    "    Fortress_Burry_Analyst_buy = pd.DataFrame()\n",
    "\n",
    "# D. Display Result\n",
    "if not Fortress_Burry_Analyst_buy.empty:\n",
    "    print(f\"\\nüöÄ Final List: {len(Fortress_Burry_Analyst_buy)} stocks (Fortress + Burry + Analyst Buy Rating)\")\n",
    "    display(Fortress_Burry_Analyst_buy)\n",
    "else:\n",
    "    print(\"No stocks passed all filters.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcc57c53",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==========================================\n",
    "# 13. THE \"DEEP VALUE\" INTERSECTION (Buffett + Burry)\n",
    "# ==========================================\n",
    "\n",
    "# 1. Ensure we have the Buffett Data\n",
    "# (If you haven't run the Buffett scanner in this notebook yet, this runs it now)\n",
    "if 'Buffett_Value_DF' not in locals():\n",
    "    print(\"üîÑ Buffett Data not found. Running scan now...\")\n",
    "    if 'get_buffett_value_picks' in globals() and 'final_results' in locals():\n",
    "        Buffett_Value_DF = get_buffett_value_picks(final_results)\n",
    "    else:\n",
    "        print(\"‚ö†Ô∏è Missing 'final_results' or 'get_buffett_value_picks' function.\")\n",
    "        Buffett_Value_DF = pd.DataFrame()\n",
    "\n",
    "# 2. Ensure we have the Burry Data\n",
    "if 'Fortress_Burry_EV_EBITDA' not in locals():\n",
    "    print(\"‚ö†Ô∏è Please run the Burry EV/EBITDA filter cell first.\")\n",
    "    Fortress_Burry_EV_EBITDA = pd.DataFrame()\n",
    "\n",
    "# 3. THE MERGE (Finding the Overlap)\n",
    "if not Buffett_Value_DF.empty and not Fortress_Burry_EV_EBITDA.empty:\n",
    "    \n",
    "    # Merge on Ticker to find stocks that appear in BOTH lists\n",
    "    # We use an 'inner' join, which means \"keep only if in both\"\n",
    "    Deep_Value_Intersection = pd.merge(\n",
    "        Buffett_Value_DF[['Ticker', 'P/B Ratio', 'ROE %', 'Debt/Eq %']], \n",
    "        Fortress_Burry_EV_EBITDA[['Ticker', 'Price', 'Sector', 'EV/EBITDA', 'Sector_Avg_EV_EBITDA', 'Discount_%', 'Tier']],\n",
    "        on='Ticker', \n",
    "        how='inner'\n",
    "    )\n",
    "    \n",
    "    if not Deep_Value_Intersection.empty:\n",
    "        print(\"\\n\" + \"=\"*60)\n",
    "        print(f\"üíé DEEP VALUE GEMS FOUND: {len(Deep_Value_Intersection)}\")\n",
    "        print(\"=\"*60)\n",
    "        print(\"Criteria: Trading < Book Value (Buffett) AND Cheaper than Sector (Burry)\")\n",
    "        \n",
    "        # Sort by the \"Discount\" (how cheap they are vs sector)\n",
    "        Deep_Value_Intersection = Deep_Value_Intersection.sort_values(by='Discount_%', ascending=False)\n",
    "        \n",
    "        cols = ['Ticker', 'Price', 'Tier', 'P/B Ratio', 'EV/EBITDA', 'Sector_Avg_EV_EBITDA', 'Discount_%', 'Sector']\n",
    "        display(Deep_Value_Intersection[cols])\n",
    "        \n",
    "    else:\n",
    "        print(\"\\n‚ùå No stocks passed BOTH filters.\")\n",
    "        print(\"This means no stock is both 'Below Book Value' AND 'Cheaper than Sector Average' at the same time.\")\n",
    "        print(f\"Buffett Count: {len(Buffett_Value_DF)} | Burry Count: {len(Fortress_Burry_EV_EBITDA)}\")\n",
    "\n",
    "else:\n",
    "    print(\"‚ùå Cannot combine. One of the filters returned 0 results.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ceaa9fcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==========================================\n",
    "# Watchlist Combiner (Finviz + YFinance)\n",
    "# ==========================================\n",
    "\n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "import yfinance as yf\n",
    "from finvizfinance.quote import finvizfinance\n",
    "import time\n",
    "import numpy as np\n",
    "\n",
    "# --- 1. INPUT YOUR MANUAL LIST HERE ---\n",
    "MY_TICKERS = ['GRND','ARCC','BANC','ONB','UBER','ADMA','MIR','APG','SEI','FLEX','DD','SVM'] \n",
    "\n",
    "def get_combined_watchlist(ticker_list):\n",
    "    print(f\"--- Processing {len(ticker_list)} stocks ---\")\n",
    "    \n",
    "    # --- PART A: Get Analyst Ratings from Finviz ---\n",
    "    print(\"1. Fetching Analyst Ratings from Finviz...\")\n",
    "    finviz_data = []\n",
    "    \n",
    "    for ticker in ticker_list:\n",
    "        try:\n",
    "            stock = finvizfinance(ticker)\n",
    "            info = stock.ticker_fundament()\n",
    "            \n",
    "            finviz_data.append({\n",
    "                'Ticker': ticker,\n",
    "                'Recom': info.get('Recom', np.nan),\n",
    "                'Target_Price': info.get('Target Price', np.nan)\n",
    "            })\n",
    "            time.sleep(0.5) \n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"   Skipping Finviz for {ticker}: {e}\")\n",
    "            finviz_data.append({'Ticker': ticker, 'Recom': np.nan, 'Target_Price': np.nan})\n",
    "\n",
    "    df_finviz = pd.DataFrame(finviz_data)\n",
    "    \n",
    "    # --- PART B: Get Real-Time Stats from yfinance ---\n",
    "    print(\"2. Fetching Price & Volatility from yfinance...\")\n",
    "    \n",
    "    try:\n",
    "        # Download data (1 Year is perfect for 52-Week MA)\n",
    "        data = yf.download(ticker_list, period=\"1y\", interval=\"1d\", group_by='ticker', progress=False, threads=True)\n",
    "        yf_stats = []\n",
    "        \n",
    "        for ticker in ticker_list:\n",
    "            try:\n",
    "                # --- FIXED: Robust Data Extraction ---\n",
    "                if isinstance(data.columns, pd.MultiIndex):\n",
    "                    if ticker in data.columns.levels[0]:\n",
    "                        df = data[ticker].copy()\n",
    "                    else:\n",
    "                        print(f\"   Warning: {ticker} not found in yfinance download.\")\n",
    "                        continue\n",
    "                else:\n",
    "                    df = data.copy()\n",
    "\n",
    "                # Cleanup\n",
    "                df = df.dropna(subset=['Close'])\n",
    "                if len(df) < 20: \n",
    "                    print(f\"   Warning: Not enough data for {ticker}\")\n",
    "                    continue\n",
    "\n",
    "                # --- MATH CALCULATIONS ---\n",
    "                current_price = df['Close'].iloc[-1]\n",
    "                prev_close = df['Close'].iloc[-2]\n",
    "                \n",
    "                high_52 = df['High'].max()\n",
    "                drop_from_high = ((current_price - high_52) / high_52) * 100\n",
    "                \n",
    "                change_pct = ((current_price - prev_close) / prev_close) * 100\n",
    "                \n",
    "                # Volatility (30-day Std Dev)\n",
    "                volatility = df['Close'].pct_change().std() * 100\n",
    "                \n",
    "                # Relative Volume\n",
    "                curr_vol = df['Volume'].iloc[-1]\n",
    "                avg_vol = df['Volume'].tail(30).mean()\n",
    "                rel_vol = curr_vol / avg_vol if avg_vol > 0 else 0\n",
    "\n",
    "                # --- NEW: 52-Week Moving Average ---\n",
    "                # Since we fetched exactly 1 year ('1y'), the mean of the whole column is the 52W MA\n",
    "                ma_52w = df['Close'].mean()\n",
    "\n",
    "                # Distance from MA (Optional but helpful metric)\n",
    "                # dist_ma = ((current_price - ma_52w) / ma_52w) * 100 \n",
    "\n",
    "                yf_stats.append({\n",
    "                    'Ticker': ticker,\n",
    "                    'Price': round(current_price, 2),\n",
    "                    'Change_%': round(change_pct, 2),\n",
    "                    '52W_MA': round(ma_52w, 2),          # <--- Added Here\n",
    "                    'Drop_from_High_%': round(drop_from_high, 2),\n",
    "                    'Volatility_%': round(volatility, 2),\n",
    "                    'Rel_Volume': round(rel_vol, 2)\n",
    "                })\n",
    "                \n",
    "            except Exception as e:\n",
    "                print(f\"   Error calculating stats for {ticker}: {e}\")\n",
    "                continue\n",
    "                \n",
    "        df_yf = pd.DataFrame(yf_stats)\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"yfinance Critical Error: {e}\")\n",
    "        return pd.DataFrame()\n",
    "\n",
    "    # --- PART C: Merge ---\n",
    "    if not df_finviz.empty:\n",
    "        if not df_yf.empty:\n",
    "            master_df = pd.merge(df_finviz, df_yf, on='Ticker', how='outer')\n",
    "        else:\n",
    "            master_df = df_finviz\n",
    "            \n",
    "        # Added '52W_MA' to this list so it displays in the final table\n",
    "        cols = ['Ticker', 'Price', 'Change_%', '52W_MA', 'Drop_from_High_%', 'Recom', 'Target_Price', 'Rel_Volume', 'Volatility_%']\n",
    "        \n",
    "        final_cols = [c for c in cols if c in master_df.columns]\n",
    "        return master_df[final_cols]\n",
    "    else:\n",
    "        return pd.DataFrame()\n",
    "\n",
    "# --- RUN IT ---\n",
    "watchlist_df = get_combined_watchlist(MY_TICKERS)\n",
    "\n",
    "if not watchlist_df.empty:\n",
    "    if 'Drop_from_High_%' in watchlist_df.columns:\n",
    "        watchlist_df['Drop_from_High_%'] = pd.to_numeric(watchlist_df['Drop_from_High_%'], errors='coerce')\n",
    "        print(\"\\n--- Final Watchlist ---\")\n",
    "        display(watchlist_df.sort_values(by='Drop_from_High_%', ascending=True))\n",
    "    else:\n",
    "        display(watchlist_df)\n",
    "else:\n",
    "    print(\"No data found.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "333020a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# CELL: GEMINI AI SENTIMENT ANALYSIS\n",
    "# =============================================================================\n",
    "# This uses Google's Gemini AI to analyze news and sentiment for a stock.\n",
    "# You need a Gemini API key to use this feature.\n",
    "\n",
    "import os\n",
    "from google import genai\n",
    "from google.genai import types\n",
    "from IPython.display import display, Markdown\n",
    "\n",
    "# ==========================================\n",
    "# CONFIGURATION\n",
    "# ==========================================\n",
    "\n",
    "# Path to a text file containing your Gemini API key\n",
    "# (We store it in a file instead of the code for security)\n",
    "KEY_FILE_PATH = \"C:\\\\Users\\\\James\\\\OneDrive - McMaster University\\\\Gemini API Key\\\\gemini_key.txt\"\n",
    "\n",
    "def load_api_key(filepath):\n",
    "    \"\"\"\n",
    "    Read the API key from a file.\n",
    "    \n",
    "    Why a file? Because API keys are like passwords - you don't want to\n",
    "    accidentally share them by uploading code to GitHub.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        with open(filepath, \"r\") as f:\n",
    "            return f.read().strip()  # .strip() removes whitespace\n",
    "    except FileNotFoundError:\n",
    "        print(f\"‚ùå Error: Could not find the file '{filepath}'\")\n",
    "        return None\n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Error reading key file: {e}\")\n",
    "        return None\n",
    "\n",
    "# Load the key\n",
    "api_key = load_api_key(KEY_FILE_PATH)\n",
    "\n",
    "if api_key:\n",
    "    # Environment variables are a way to store settings that programs can access\n",
    "    os.environ[\"GEMINI_API_KEY\"] = api_key\n",
    "    print(\"‚úÖ API Key loaded securely.\")\n",
    "else:\n",
    "    print(\"‚ö†Ô∏è CRITICAL: API Key not loaded. AI analysis will not work.\")\n",
    "\n",
    "# ==========================================\n",
    "# SENTIMENT ANALYSIS FUNCTION\n",
    "# ==========================================\n",
    "\n",
    "def analyze_sentiment_gemini_3(ticker_symbol, company_name=None):\n",
    "    \"\"\"\n",
    "    Use Gemini AI to analyze market sentiment for a stock.\n",
    "    \n",
    "    The AI will:\n",
    "    1. Search Google for recent news\n",
    "    2. Analyze the sentiment (positive/negative)\n",
    "    3. Generate a professional report\n",
    "    \n",
    "    Args:\n",
    "        ticker_symbol: Stock ticker (e.g., 'AAPL', 'RY.TO')\n",
    "        company_name: Optional company name for better search results\n",
    "    \"\"\"\n",
    "    if not os.environ.get(\"GEMINI_API_KEY\"):\n",
    "        print(\"‚ùå Stop: No API Key found.\")\n",
    "        return\n",
    "\n",
    "    print(f\"\\nüß† Gemini 3 is thinking... analyzing ${ticker_symbol}...\")\n",
    "\n",
    "    # Initialize the Gemini API client\n",
    "    client = genai.Client(api_key=os.environ[\"GEMINI_API_KEY\"])\n",
    "\n",
    "    # Configure the AI's settings\n",
    "    config = types.GenerateContentConfig(\n",
    "        thinking_config=types.ThinkingConfig(\n",
    "            include_thoughts=False,  # Don't show internal reasoning\n",
    "            thinking_level=\"HIGH\"    # Use maximum reasoning depth\n",
    "        ),\n",
    "        tools=[types.Tool(\n",
    "            google_search=types.GoogleSearch()  # Allow AI to search Google\n",
    "        )],\n",
    "        response_modalities=[\"TEXT\"]\n",
    "    )\n",
    "\n",
    "    # The prompt tells the AI what to do\n",
    "    # We ask it to investigate 4 key areas (pillars)\n",
    "    prompt = f\"\"\"\n",
    "    You are a Senior Equity Research Analyst.\n",
    "    Perform a deep \"Market Sentiment Analysis\" on {ticker_symbol} ({company_name or 'the company'}).\n",
    "    \n",
    "    Step 1: SEARCH. Find the latest (last 30 days) news, analyst notes, and SEC filings.\n",
    "    Step 2: REASON. Analyze to determine market psychology.\n",
    "    \n",
    "    Investigate these 4 Pillars:\n",
    "    1. **News Virality**: Are headlines fear-mongering or euphoric?\n",
    "    2. **Analyst Shifts**: Are price targets moving UP or DOWN?\n",
    "    3. **Institutional Flows**: Are hedge funds or insiders buying/selling?\n",
    "    4. **The \"Whisper\" Number**: What are traders saying vs. official guidance?\n",
    "\n",
    "    **OUTPUT FORMAT (Markdown):**\n",
    "    \n",
    "    ## üß† Gemini 3 Sentiment Report: {ticker_symbol}\n",
    "    **Sentiment Score:** [1-10]\n",
    "    **Verdict:** [Buy / Hold / Sell / Speculative]\n",
    "    \n",
    "    ### 1. The Bull Thesis (Why it goes up)\n",
    "    ### 2. The Bear Thesis (Why it goes down)\n",
    "    ### 3. Deep Dive Analysis\n",
    "    ### 4. Conclusion\n",
    "    \"\"\"\n",
    "\n",
    "    try:\n",
    "        # Send the prompt to Gemini and get a response\n",
    "        response = client.models.generate_content(\n",
    "            model='gemini-3-flash-preview',\n",
    "            contents=prompt,\n",
    "            config=config\n",
    "        )\n",
    "        # Display the response as formatted Markdown\n",
    "        display(Markdown(response.text))\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Error: {e}\")\n",
    "\n",
    "# ==========================================\n",
    "# EXECUTION\n",
    "# ==========================================\n",
    "\n",
    "# Set the ticker you want to analyze\n",
    "tickers_gemini = ['TCL-A.TO']\n",
    "\n",
    "# Run the analysis if API key is available\n",
    "if os.environ.get(\"GEMINI_API_KEY\"):\n",
    "    analyze_sentiment_gemini_3(tickers_gemini[0], tickers_gemini[0])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
