{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "67ec8184",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import requests\n",
    "from yahooquery import Ticker  # Step 2 (Speed)\n",
    "import yfinance as yf          # Step 3 (Reliability)\n",
    "import io\n",
    "import json\n",
    "import os\n",
    "import time\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "831a506f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "\n",
    "# ==========================================\n",
    "# CONFIGURATION\n",
    "# ==========================================\n",
    "# 1. FOLDER SETUP (The Fix for GitHub Portability)\n",
    "DATA_FOLDER = \"YfinanceDataDump\"  # Relative path (creates folder in project root)\n",
    "\n",
    "# Create the folder if it doesn't exist\n",
    "if not os.path.exists(DATA_FOLDER):\n",
    "    try:\n",
    "        os.makedirs(DATA_FOLDER)\n",
    "        print(f\"Created data folder: {DATA_FOLDER}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Warning: Could not create folder '{DATA_FOLDER}'. Saving to current directory. Error: {e}\")\n",
    "        DATA_FOLDER = \".\"\n",
    "\n",
    "# 2. FILE PATHS (Everything saves inside the folder now)\n",
    "CACHE_FILE = os.path.join(DATA_FOLDER, \"financial_cache.json\")\n",
    "FORTRESS_CSV = os.path.join(DATA_FOLDER, \"fortress_stocks.csv\")\n",
    "STRONG_CSV = os.path.join(DATA_FOLDER, \"strong_stocks.csv\")\n",
    "RISKY_CSV = os.path.join(DATA_FOLDER, \"risky_stocks.csv\")\n",
    "ANALYST_CSV = os.path.join(DATA_FOLDER, \"Analyst_Fortress_Picks.csv\")\n",
    "BUFFETT_CSV = os.path.join(DATA_FOLDER, \"Buffett_Value_Picks.csv\")\n",
    "\n",
    "# 3. UNIVERSE FILTERS\n",
    "MIN_PRICE = 2.00               \n",
    "MIN_VOLUME = 1_000_000       \n",
    "MIN_CAP = 300_000_000        # $300M\n",
    "MIN_CURRENT_RATIO = 1.2\n",
    "MAX_PE_RATIO = 100.0         \n",
    "\n",
    "# 4. SAFETY THRESHOLDS \n",
    "MIN_INTEREST_COVERAGE = 1.5\n",
    "MIN_ROIC = 0.05              # 5%\n",
    "FORTRESS_MARGIN_THRESHOLD = 0.05  # 5%\n",
    "\n",
    "EXCLUDED_SECTORS = ['Financial Services', 'Real Estate']\n",
    "CACHE_EXPIRY_DAYS = 30 \n",
    "\n",
    "# ==========================================\n",
    "# HELPER FUNCTIONS\n",
    "# ==========================================\n",
    "def load_cache():\n",
    "    if os.path.exists(CACHE_FILE):\n",
    "        try:\n",
    "            with open(CACHE_FILE, 'r') as f:\n",
    "                return json.load(f)\n",
    "        except:\n",
    "            return {}\n",
    "    return {}\n",
    "\n",
    "def save_cache(cache_data):\n",
    "    try:\n",
    "        with open(CACHE_FILE, 'w') as f:\n",
    "            json.dump(cache_data, f)\n",
    "    except Exception as e:\n",
    "        print(f\"Warning: Could not save cache: {e}\")\n",
    "\n",
    "def calculate_altman_z_yfinance(bs, fin, market_cap):\n",
    "    \"\"\"\n",
    "    Calculates Z-Score using yfinance DataFrames.\n",
    "    Formula: 1.2A + 1.4B + 3.3C + 0.6D + 1.0E\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Helper to safely get value from Series\n",
    "        def get_val(df, keys):\n",
    "            for k in keys:\n",
    "                if k in df.index:\n",
    "                    return df.loc[k].iloc[0]\n",
    "            return 0\n",
    "\n",
    "        # Map yfinance row names\n",
    "        total_assets = get_val(bs, ['Total Assets'])\n",
    "        total_liab = get_val(bs, ['Total Liabilities Net Minority Interest', 'Total Liabilities'])\n",
    "        current_assets = get_val(bs, ['Current Assets', 'Total Current Assets'])\n",
    "        current_liab = get_val(bs, ['Current Liabilities', 'Total Current Liabilities'])\n",
    "        retained_earnings = get_val(bs, ['Retained Earnings'])\n",
    "        \n",
    "        ebit = get_val(fin, ['EBIT', 'Operating Income'])\n",
    "        total_revenue = get_val(fin, ['Total Revenue'])\n",
    "        \n",
    "        if total_assets == 0 or total_liab == 0: return 0\n",
    "\n",
    "        # A: Working Capital / Total Assets\n",
    "        A = (current_assets - current_liab) / total_assets\n",
    "        \n",
    "        # B: Retained Earnings / Total Assets\n",
    "        B = retained_earnings / total_assets\n",
    "        \n",
    "        # C: EBIT / Total Assets\n",
    "        C = ebit / total_assets\n",
    "        \n",
    "        # D: Market Value of Equity / Total Liabilities\n",
    "        D = market_cap / total_liab\n",
    "        \n",
    "        # E: Sales / Total Assets\n",
    "        E = total_revenue / total_assets\n",
    "        \n",
    "        return (1.2 * A) + (1.4 * B) + (3.3 * C) + (0.6 * D) + (1.0 * E)\n",
    "    except Exception as e:\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "efa4bf6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==========================================\n",
    "# STEP 1: FETCH COMBINED UNIVERSE (USA + CAD)\n",
    "# ==========================================\n",
    "def get_combined_universe():\n",
    "    print(\"--- STEP 1: Fetching North American Universe ---\")\n",
    "    tickers = []\n",
    "    \n",
    "    # 1. USA\n",
    "    try:\n",
    "        url_us = \"https://www.nasdaqtrader.com/dynamic/symdir/nasdaqtraded.txt\"\n",
    "        s = requests.get(url_us).content\n",
    "        df_us = pd.read_csv(io.StringIO(s.decode('utf-8')), sep='|')\n",
    "        df_us = df_us[(df_us['Test Issue'] == 'N') & (df_us['ETF'] == 'N')]\n",
    "        us_list = [x.replace('$', '-') for x in df_us['Symbol'].astype(str) if len(x) < 5]\n",
    "        tickers.extend(us_list)\n",
    "        print(f\"   -> Found {len(us_list)} US stocks.\")\n",
    "    except:\n",
    "        print(\"   -> Error fetching USA list.\")\n",
    "\n",
    "    return tickers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "65c3da19",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==========================================\n",
    "# STEP 2: LIGHTWEIGHT SIEVE (YahooQuery)\n",
    "# ==========================================\n",
    "def get_initial_survivors(tickers):\n",
    "    print(f\"\\n--- STEP 2: Running 'Lightweight' Filter on {len(tickers)} stocks ---\")\n",
    "    chunk_size = 500 \n",
    "    survivors = []\n",
    "    chunks = [tickers[i:i + chunk_size] for i in range(0, len(tickers), chunk_size)]\n",
    "    \n",
    "    for i, chunk in enumerate(chunks):\n",
    "        if i % 2 == 0: print(f\" -> Processing Batch {i+1}/{len(chunks)}...\")\n",
    "        try:\n",
    "            yq = Ticker(chunk, asynchronous=True)\n",
    "            df_modules = yq.get_modules('summaryProfile summaryDetail financialData price defaultKeyStatistics')\n",
    "            \n",
    "            for symbol, data in df_modules.items():\n",
    "                if isinstance(data, str): continue \n",
    "                try:\n",
    "                    price = data.get('price', {}).get('regularMarketPrice', 0)\n",
    "                    if price is None: price = 0\n",
    "                    \n",
    "                    vol = data.get('summaryDetail', {}).get('averageVolume', 0)\n",
    "                    if vol is None or vol == 0:\n",
    "                         vol = data.get('price', {}).get('averageDailyVolume10Day', 0)\n",
    "                    \n",
    "                    cap = data.get('price', {}).get('marketCap', 0)\n",
    "                    if cap is None: cap = 0\n",
    "                    \n",
    "                    sector = data.get('summaryProfile', {}).get('sector', 'Unknown')\n",
    "                    fin_data = data.get('financialData', {})\n",
    "                    curr_ratio = fin_data.get('currentRatio', 0)\n",
    "                    op_margins = fin_data.get('operatingMargins', 0)\n",
    "                    if curr_ratio is None: curr_ratio = 0\n",
    "                    if op_margins is None: op_margins = 0\n",
    "\n",
    "                    # --- P/E RATIO CHECK ---\n",
    "                    pe = data.get('summaryDetail', {}).get('trailingPE')\n",
    "                    if pe is not None and pe > MAX_PE_RATIO: continue\n",
    "\n",
    "                    # FILTERS\n",
    "                    if price < MIN_PRICE: continue\n",
    "                    if cap < MIN_CAP: continue\n",
    "                    if vol < MIN_VOLUME: continue \n",
    "                    if any(x in sector for x in EXCLUDED_SECTORS): continue\n",
    "                    if curr_ratio < MIN_CURRENT_RATIO: continue\n",
    "                    if op_margins <= 0: continue \n",
    "                    \n",
    "                    survivors.append({\n",
    "                        'Ticker': symbol,\n",
    "                        'Sector': sector,\n",
    "                        'Price': price,\n",
    "                        'Op Margin %': round(op_margins * 100, 2),\n",
    "                        'P/E': round(pe, 2) if pe else 0,\n",
    "                        'Curr Ratio': curr_ratio,\n",
    "                        'Mkt Cap (B)': round(cap / 1_000_000_000, 2)\n",
    "                    })\n",
    "                except: continue\n",
    "        except: continue\n",
    "    return pd.DataFrame(survivors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b09f64f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# ==========================================\n",
    "# STEP 3: DEEP DIVE (yfinance + Cache)\n",
    "# ==========================================\n",
    "def get_advanced_metrics(survivor_df):\n",
    "    tickers = survivor_df['Ticker'].tolist()\n",
    "    print(f\"\\n--- STEP 3: Fetching Deep Financials for {len(tickers)} Survivors ---\")\n",
    "    \n",
    "    cache = load_cache()\n",
    "    current_time = time.time()\n",
    "    expiry_seconds = CACHE_EXPIRY_DAYS * 86400\n",
    "    \n",
    "    final_data = []\n",
    "    \n",
    "    for i, ticker in enumerate(tickers):\n",
    "        if i % 20 == 0: print(f\" -> Analyzing {i+1}/{len(tickers)}: {ticker}...\")\n",
    "        \n",
    "        def determine_tier(metrics, base_row):\n",
    "            if metrics['int_cov'] < MIN_INTEREST_COVERAGE: return \"Risky\"\n",
    "            if metrics['roic'] < MIN_ROIC: return \"Risky\"\n",
    "            \n",
    "            op_margin_pct = base_row['Op Margin %'] / 100\n",
    "            if op_margin_pct >= FORTRESS_MARGIN_THRESHOLD: return \"Fortress\"\n",
    "            return \"Strong\"\n",
    "\n",
    "        # 1. CHECK CACHE\n",
    "        cached_data = cache.get(ticker)\n",
    "        if cached_data and (current_time - cached_data['timestamp'] < expiry_seconds):\n",
    "            if cached_data.get('roic') == -999: continue \n",
    "            \n",
    "            base_row = survivor_df[survivor_df['Ticker'] == ticker].iloc[0]\n",
    "            tier = determine_tier(cached_data, base_row)\n",
    "            \n",
    "            final_data.append({\n",
    "                'Ticker': ticker,\n",
    "                'Tier': tier,\n",
    "                'Price': base_row['Price'],\n",
    "                'P/E': base_row['P/E'],\n",
    "                'Sector': base_row['Sector'],\n",
    "                'Z-Score': cached_data['z_score'],\n",
    "                'ROIC %': round(cached_data['roic'] * 100, 2),\n",
    "                'Op Margin %': base_row['Op Margin %'],\n",
    "                'Curr Ratio': base_row['Curr Ratio'],\n",
    "                'Int Cov': cached_data['int_cov'],\n",
    "                'Mkt Cap (B)': base_row['Mkt Cap (B)']\n",
    "            })\n",
    "            continue\n",
    "\n",
    "        # 2. FETCH NEW DATA\n",
    "        try:\n",
    "            stock = yf.Ticker(ticker)\n",
    "            fin = stock.financials\n",
    "            bs = stock.balance_sheet\n",
    "            \n",
    "            if fin.empty or bs.empty:\n",
    "                cache[ticker] = {'timestamp': current_time, 'z_score': 0, 'roic': -999, 'int_cov': -999}\n",
    "                continue\n",
    "            \n",
    "            def get_item(df, keys):\n",
    "                for k in keys:\n",
    "                    if k in df.index: return df.loc[k].iloc[0]\n",
    "                return 0\n",
    "\n",
    "            ebit = get_item(fin, ['EBIT', 'Operating Income', 'Pretax Income'])\n",
    "            int_exp = get_item(fin, ['Interest Expense', 'Interest Expense Non Operating'])\n",
    "            total_assets = get_item(bs, ['Total Assets'])\n",
    "            curr_liab = get_item(bs, ['Current Liabilities', 'Total Current Liabilities'])\n",
    "            \n",
    "            int_exp = abs(int_exp)\n",
    "            if int_exp == 0: int_cov = 100\n",
    "            else: int_cov = ebit / int_exp\n",
    "            \n",
    "            invested_cap = total_assets - curr_liab\n",
    "            if invested_cap <= 0: roic = 0\n",
    "            else: roic = ebit / invested_cap\n",
    "            \n",
    "            base_row = survivor_df[survivor_df['Ticker'] == ticker].iloc[0]\n",
    "            mkt_cap_raw = base_row['Mkt Cap (B)'] * 1_000_000_000\n",
    "            z = calculate_altman_z_yfinance(bs, fin, mkt_cap_raw)\n",
    "            \n",
    "            metrics = {\n",
    "                'timestamp': current_time,\n",
    "                'z_score': round(z, 2),\n",
    "                'roic': roic,\n",
    "                'int_cov': round(int_cov, 2)\n",
    "            }\n",
    "            cache[ticker] = metrics\n",
    "            \n",
    "            tier = determine_tier(metrics, base_row)\n",
    "\n",
    "            final_data.append({\n",
    "                'Ticker': ticker,\n",
    "                'Tier': tier,\n",
    "                'Price': base_row['Price'],\n",
    "                'P/E': base_row['P/E'],\n",
    "                'Sector': base_row['Sector'],\n",
    "                'Z-Score': round(z, 2),\n",
    "                'ROIC %': round(roic * 100, 2),\n",
    "                'Op Margin %': base_row['Op Margin %'],\n",
    "                'Curr Ratio': base_row['Curr Ratio'],\n",
    "                'Int Cov': round(int_cov, 2),\n",
    "                'Mkt Cap (B)': base_row['Mkt Cap (B)']\n",
    "            })\n",
    "            \n",
    "        except Exception as e:\n",
    "            continue\n",
    "\n",
    "    save_cache(cache)\n",
    "    return pd.DataFrame(final_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a5361c2f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- STEP 1: Fetching North American Universe ---\n",
      "   -> Found 6014 US stocks.\n",
      "\n",
      "--- STEP 2: Running 'Lightweight' Filter on 6014 stocks ---\n",
      " -> Processing Batch 1/13...\n",
      " -> Processing Batch 3/13...\n",
      " -> Processing Batch 5/13...\n",
      " -> Processing Batch 7/13...\n",
      " -> Processing Batch 9/13...\n",
      " -> Processing Batch 11/13...\n",
      " -> Processing Batch 13/13...\n",
      "\n",
      "‚úÖ Step 2 Complete. 554 stocks passed basic filters.\n",
      "\n",
      "--- STEP 3: Fetching Deep Financials for 554 Survivors ---\n",
      " -> Analyzing 1/554: A...\n",
      " -> Analyzing 21/554: ALGM...\n",
      " -> Analyzing 41/554: AQN...\n",
      " -> Analyzing 61/554: AXTA...\n",
      " -> Analyzing 81/554: BMBL...\n",
      " -> Analyzing 101/554: CDE...\n",
      " -> Analyzing 121/554: COP...\n",
      " -> Analyzing 141/554: CXW...\n",
      " -> Analyzing 161/554: DT...\n",
      " -> Analyzing 181/554: ETN...\n",
      " -> Analyzing 201/554: FOLD...\n",
      " -> Analyzing 221/554: GILD...\n",
      " -> Analyzing 241/554: HAFN...\n",
      " -> Analyzing 261/554: HUM...\n",
      " -> Analyzing 281/554: ISRG...\n",
      " -> Analyzing 301/554: LEN...\n",
      " -> Analyzing 321/554: MDT...\n",
      " -> Analyzing 341/554: NAGE...\n",
      " -> Analyzing 361/554: OGN...\n",
      " -> Analyzing 381/554: PFE...\n",
      " -> Analyzing 401/554: QDEL...\n",
      " -> Analyzing 421/554: RUN...\n",
      " -> Analyzing 441/554: SLGN...\n",
      " -> Analyzing 461/554: STM...\n",
      " -> Analyzing 481/554: TMHC...\n",
      " -> Analyzing 501/554: UAA...\n",
      " -> Analyzing 521/554: VRTX...\n",
      " -> Analyzing 541/554: XRAY...\n",
      "\n",
      "============================================================\n",
      "RESULTS GENERATED\n",
      "============================================================\n",
      "1. FORTRESS (348): Saved to 'YfinanceDataDump\\fortress_stocks.csv'\n",
      "2. STRONG   (27): Saved to 'YfinanceDataDump\\strong_stocks.csv'\n",
      "3. RISKY    (178): Saved to 'YfinanceDataDump\\risky_stocks.csv'\n",
      "\n",
      "--- FORTRESS PREVIEW ---\n",
      "    Ticker      Tier   Price    P/E                  Sector  Z-Score  ROIC %  Op Margin %  Curr Ratio  Int Cov  Mkt Cap (B)\n",
      "533    WPM  Fortress  117.38  56.43         Basic Materials   196.14    8.72        66.54       8.089  2269.82        53.36\n",
      "350   NVDA  Fortress  188.22  47.17              Technology    90.25   90.08        63.17       4.468   341.19      4582.59\n",
      "279   ISRG  Fortress  575.40  76.31              Healthcare    57.67   13.82        30.33       4.728   100.00       206.27\n",
      "410   RGLD  Fortress  225.32  32.05         Basic Materials    44.83   13.18        50.53       3.516    44.71        19.02\n",
      "37     APP  Fortress  698.82  83.99  Communication Services    31.81   39.37        76.80       3.250     5.95       236.38\n",
      "186   FAST  Fortress   41.29  38.95             Industrials    30.74   37.78        20.70       4.259   207.59        47.40\n",
      "155   DOCS  Fortress   44.23  35.38              Healthcare    29.59   20.77        38.55       7.786   100.00         8.33\n",
      "325   MNST  Fortress   77.63  43.86      Consumer Defensive    29.48   29.15        30.74       3.185   100.00        75.85\n",
      "122   CPRT  Fortress   39.49  24.08             Industrials    28.72   18.04        37.29       7.939      NaN        38.23\n",
      "414   RMBS  Fortress   93.57  44.77              Technology    28.32   15.97        35.43      11.609   142.27        10.07\n",
      "31    ANET  Fortress  134.15  50.24              Technology    27.81   26.03        42.38       3.254      NaN       168.93\n",
      "48     ASM  Fortress    6.58  50.62         Basic Materials    27.34   11.12        32.56       2.754    38.26         1.03\n",
      "472    TER  Fortress  197.36  72.56              Technology    23.21   19.87        18.89       1.759   170.80        31.39\n",
      "274   INOD  Fortress   52.08  52.08              Technology    22.78   32.91        18.80       2.690      NaN         1.66\n",
      "11    ADMA  Fortress   19.11  22.48              Healthcare    21.16   32.24        38.01       7.128    10.02         4.56\n"
     ]
    }
   ],
   "source": [
    "# ==========================================\n",
    "# MAIN EXECUTION\n",
    "# ==========================================\n",
    "if __name__ == \"__main__\":\n",
    "    tickers = get_combined_universe()\n",
    "    \n",
    "    if len(tickers) > 0:\n",
    "        survivors_df = get_initial_survivors(tickers)\n",
    "        \n",
    "        if not survivors_df.empty:\n",
    "            print(f\"\\n‚úÖ Step 2 Complete. {len(survivors_df)} stocks passed basic filters.\")\n",
    "            \n",
    "            final_results = get_advanced_metrics(survivors_df)\n",
    "            \n",
    "            if not final_results.empty:\n",
    "                final_results = final_results.sort_values(by=['Tier', 'Z-Score'], ascending=[True, False])\n",
    "                \n",
    "                # 1. Standard Split\n",
    "                fortress_df = final_results[final_results['Tier'] == 'Fortress'].copy()\n",
    "                strong_df = final_results[final_results['Tier'] == 'Strong'].copy()\n",
    "                risky_df = final_results[final_results['Tier'] == 'Risky'].copy()\n",
    "                \n",
    "                # 3. Save Files (Updated to use Relative Paths from Cell 2)\n",
    "                try:\n",
    "                    fortress_df.to_csv(FORTRESS_CSV, index=False)\n",
    "                    strong_df.to_csv(STRONG_CSV, index=False)\n",
    "                    risky_df.to_csv(RISKY_CSV, index=False)\n",
    "                    \n",
    "                    print(\"\\n\" + \"=\"*60)\n",
    "                    print(\"RESULTS GENERATED\")\n",
    "                    print(\"=\"*60)\n",
    "                    print(f\"1. FORTRESS ({len(fortress_df)}): Saved to '{FORTRESS_CSV}'\")\n",
    "                    print(f\"2. STRONG   ({len(strong_df)}): Saved to '{STRONG_CSV}'\")\n",
    "                    print(f\"3. RISKY    ({len(risky_df)}): Saved to '{RISKY_CSV}'\")\n",
    "                except Exception as e:\n",
    "                    print(f\"\\n‚ö†Ô∏è Error Saving Files: {e}\")\n",
    "                    print(\"Check if the file is open in Excel or if the folder exists.\")\n",
    "                \n",
    "                pd.set_option('display.max_rows', 500)\n",
    "                pd.set_option('display.max_columns', 20)\n",
    "                pd.set_option('display.width', 1000)\n",
    "                \n",
    "                print(\"\\n--- FORTRESS PREVIEW ---\")\n",
    "                print(fortress_df.head(15))\n",
    "            else:\n",
    "                print(\"No stocks passed the deep financial analysis.\")\n",
    "        else:\n",
    "            print(\"No stocks passed the initial lightweight filter.\")\n",
    "    else:\n",
    "        print(\"Could not fetch ticker universe.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "36ee3ec0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- STEP 4: Fetching Analyst Ratings for 348 Stocks (From Memory) ---\n",
      "    (Fetching serially to avoid throttling...)\n",
      " -> Analyst Scan 1/348: WPM...\n",
      " -> Analyst Scan 11/348: ANET...\n",
      " -> Analyst Scan 21/348: GRMN...\n",
      " -> Analyst Scan 31/348: CTAS...\n",
      " -> Analyst Scan 41/348: NFLX...\n",
      " -> Analyst Scan 51/348: MSFT...\n",
      " -> Analyst Scan 61/348: INTU...\n",
      " -> Analyst Scan 71/348: DV...\n",
      " -> Analyst Scan 81/348: INCY...\n",
      " -> Analyst Scan 91/348: TGTX...\n",
      " -> Analyst Scan 101/348: KEYS...\n",
      " -> Analyst Scan 111/348: WDC...\n",
      " -> Analyst Scan 121/348: PNR...\n",
      " -> Analyst Scan 131/348: HALO...\n",
      " -> Analyst Scan 141/348: CAT...\n",
      " -> Analyst Scan 151/348: AS...\n",
      " -> Analyst Scan 161/348: GLW...\n",
      " -> Analyst Scan 171/348: AMKR...\n",
      " -> Analyst Scan 181/348: EOG...\n",
      " -> Analyst Scan 191/348: PPC...\n",
      " -> Analyst Scan 201/348: IR...\n",
      " -> Analyst Scan 211/348: TTI...\n",
      " -> Analyst Scan 221/348: PAYX...\n",
      " -> Analyst Scan 231/348: VIPS...\n",
      " -> Analyst Scan 241/348: COP...\n",
      " -> Analyst Scan 251/348: EQNR...\n",
      " -> Analyst Scan 261/348: ZBH...\n",
      " -> Analyst Scan 271/348: APTV...\n",
      " -> Analyst Scan 281/348: AXTA...\n",
      " -> Analyst Scan 291/348: HMY...\n",
      " -> Analyst Scan 301/348: SU...\n",
      " -> Analyst Scan 311/348: SEE...\n",
      " -> Analyst Scan 321/348: SHC...\n",
      " -> Analyst Scan 331/348: WYNN...\n",
      " -> Analyst Scan 341/348: IRDM...\n",
      "\n",
      "‚úÖ Analyst Scan Complete!\n",
      "Found 168 stocks with Buy Ratings (Score < 2.0)\n",
      "Saved to 'Analyst_Fortress_Picks.csv'\n",
      "    Ticker   Price  Analyst_Rating  Upside_%  Target_Price      Tier\n",
      "13    NAGE    6.59         1.00000    139.76     15.800000  Fortress\n",
      "167   MNKD    5.77         1.11111     66.57      9.611110  Fortress\n",
      "157    HLX    6.28         2.00000     59.24     10.000000  Fortress\n",
      "80     LRN   66.59         2.00000     57.68    105.000000  Fortress\n",
      "155    CXW   19.35         1.00000     54.39     29.875000  Fortress\n",
      "15    VITL   32.51         1.16667     52.12     49.454550  Fortress\n",
      "148    TME   17.67         1.40625     51.99     26.855772  Fortress\n",
      "114   BIRK   41.20         1.50000     49.62     61.642950  Fortress\n",
      "97    GNRC  138.48         1.80952     49.14    206.529400  Fortress\n",
      "153   GPRK    7.32         1.85714     48.91     10.900000  Fortress\n",
      "111   SMPL   19.99         2.00000     48.07     29.600000  Fortress\n",
      "31    SGHC   11.98         1.25000     47.12     17.625000  Fortress\n",
      "99      SE  130.89         1.36364     45.90    190.973560  Fortress\n",
      "56    BRBR   27.33         1.81250     39.04     38.000000  Fortress\n",
      "54      DT   44.22         1.58333     37.45     60.781250  Fortress\n",
      "105    DRS   34.13         1.50000     37.42     46.900000  Fortress\n",
      "130    JBS   14.54         1.33333     35.90     19.760534  Fortress\n",
      "159   NTNX   52.35         1.94118     35.06     70.704290  Fortress\n",
      "134    LKQ   30.55         1.77778     34.82     41.187500  Fortress\n",
      "1     NVDA  188.22         1.32812     34.43    253.018250  Fortress\n"
     ]
    }
   ],
   "source": [
    "# 1. Define the function (if you haven't already in a previous cell)\n",
    "def get_analyst_fortress_from_var(df_input):\n",
    "    working_df = df_input.copy()\n",
    "    tickers = working_df['Ticker'].tolist()\n",
    "    \n",
    "    print(f\"\\n--- STEP 4: Fetching Analyst Ratings for {len(tickers)} Stocks (From Memory) ---\")\n",
    "    print(\"    (Fetching serially to avoid throttling...)\")\n",
    "    \n",
    "    analyst_data = []\n",
    "    \n",
    "    for i, ticker in enumerate(tickers):\n",
    "        if i % 10 == 0: print(f\" -> Analyst Scan {i+1}/{len(tickers)}: {ticker}...\")\n",
    "        \n",
    "        try:\n",
    "            stock = yf.Ticker(ticker)\n",
    "            info = stock.info\n",
    "            \n",
    "            rec_mean = info.get('recommendationMean')\n",
    "            target_price = info.get('targetMeanPrice')\n",
    "            current_price = info.get('currentPrice')\n",
    "            \n",
    "            # Filter: Must be better than 2.0 (Lower is better)\n",
    "            if rec_mean is None or rec_mean > 2.0: continue\n",
    "            \n",
    "            upside = 0\n",
    "            if target_price and current_price:\n",
    "                upside = round(((target_price - current_price) / current_price) * 100, 2)\n",
    "            \n",
    "            # Merge with existing data\n",
    "            base_row = working_df[working_df['Ticker'] == ticker].iloc[0].to_dict()\n",
    "            base_row['Analyst_Rating'] = rec_mean\n",
    "            base_row['Target_Price'] = target_price\n",
    "            base_row['Upside_%'] = upside\n",
    "            \n",
    "            analyst_data.append(base_row)\n",
    "            time.sleep(0.2) # Polite delay\n",
    "            \n",
    "        except Exception:\n",
    "            continue\n",
    "            \n",
    "    return pd.DataFrame(analyst_data)\n",
    "\n",
    "# ==========================================\n",
    "# 2. EXECUTE IT (Run this part!)\n",
    "# ==========================================\n",
    "\n",
    "# Check if fortress_df exists from the previous step\n",
    "if 'fortress_df' in locals() and not fortress_df.empty:\n",
    "    \n",
    "    # Run the function\n",
    "    Analyst_Fortress_DF = get_analyst_fortress_from_var(fortress_df)\n",
    "    \n",
    "    if not Analyst_Fortress_DF.empty:\n",
    "        # Sort by best Analyst Rating (Lower is better) or Upside\n",
    "        Analyst_Fortress_DF = Analyst_Fortress_DF.sort_values(by='Upside_%', ascending=False)\n",
    "        \n",
    "        # Display Results\n",
    "        print(\"\\n‚úÖ Analyst Scan Complete!\")\n",
    "        print(f\"Found {len(Analyst_Fortress_DF)} stocks with Buy Ratings (Score < 2.0)\")\n",
    "        \n",
    "        # Save to CSV\n",
    "        Analyst_Fortress_DF.to_csv(ANALYST_CSV, index=False)\n",
    "        print(\"Saved to 'Analyst_Fortress_Picks.csv'\")\n",
    "        \n",
    "        # Show top picks\n",
    "        cols = ['Ticker', 'Price', 'Analyst_Rating', 'Upside_%', 'Target_Price', 'Tier']\n",
    "        print(Analyst_Fortress_DF[cols].head(20))\n",
    "    else:\n",
    "        print(\"No stocks passed the Analyst filter.\")\n",
    "else:\n",
    "    print(\"‚ùå 'fortress_df' not found or empty. Please run the Main Filter (Step 1-3) first.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ca466fcd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- STEP 5: Warren Buffett 'Below NAV' Scan ---\n",
      "    Scanning 553 candidates for Deep Value...\n",
      "    Criteria: P/B < 1.0 (Below Book) | ROE > 0% (Profitable) | Debt/Eq < 100%\n",
      "\n",
      "============================================================\n",
      "BUFFETT SCAN COMPLETE\n",
      "============================================================\n",
      "Found 19 Deep Value Stocks (Trading < Book Value)\n",
      "Saved to: 'Buffett_Value_Picks.csv'\n",
      "\n",
      "--- DEEP VALUE PICKS ---\n",
      "   Ticker   Price  P/B Ratio  ROE %  Debt/Eq %                  Sector      Tier\n",
      "0    GMAB   32.52       0.35  29.41       2.47              Healthcare  Fortress\n",
      "14     KT   19.06       0.38   5.08      60.17  Communication Services     Risky\n",
      "10   ACHC   14.50       0.42   3.69      74.49              Healthcare  Fortress\n",
      "8     SSL    6.44       0.45   5.07      76.56         Basic Materials  Fortress\n",
      "13   ANGI   12.77       0.56   3.42      54.03  Communication Services     Risky\n",
      "7     HLX    6.28       0.59   2.71      39.52                  Energy  Fortress\n",
      "4      WB   10.15       0.63  12.37      47.28  Communication Services  Fortress\n",
      "16     MT   45.54       0.63   4.72      26.23         Basic Materials    Strong\n",
      "5     GGB    3.66       0.74   5.51      36.52         Basic Materials  Fortress\n",
      "15     DD   40.89       0.75   3.22      39.67         Basic Materials     Risky\n",
      "3     MHK  109.48       0.81   5.20      28.03       Consumer Cyclical  Fortress\n",
      "17    SXC    7.15       0.87  10.23      97.59         Basic Materials    Strong\n",
      "18    NOV   15.68       0.89   6.03      36.16                  Energy    Strong\n",
      "12   DINO   45.98       0.90   4.18      35.77                  Energy     Risky\n",
      "11    KBH   56.94       0.92  10.77      43.40       Consumer Cyclical  Fortress\n",
      "1    TMHC   59.12       0.93  14.40      36.53       Consumer Cyclical  Fortress\n",
      "9    SBLK   19.71       0.93   2.50      50.95             Industrials  Fortress\n",
      "6      NE   28.32       0.99   4.92      43.60                  Energy  Fortress\n",
      "2    TGNA   19.33       1.00  11.45      83.12  Communication Services  Fortress\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from yahooquery import Ticker\n",
    "\n",
    "# ==========================================\n",
    "# BUFFETT \"BELOW NAV\" SCAN\n",
    "# ==========================================\n",
    "def get_buffett_value_picks(df_input):\n",
    "    print(f\"\\n--- STEP 5: Warren Buffett 'Below NAV' Scan ---\")\n",
    "    print(f\"    Scanning {len(df_input)} candidates for Deep Value...\")\n",
    "    print(\"    Criteria: P/B < 1.0 (Below Book) | ROE > 0% (Profitable) | Debt/Eq < 100%\")\n",
    "\n",
    "    tickers = df_input['Ticker'].tolist()\n",
    "    buffett_candidates = []\n",
    "\n",
    "    # Use YahooQuery for speed (Key Stats are summary data, no throttling risk here)\n",
    "    chunk_size = 250\n",
    "    chunks = [tickers[i:i + chunk_size] for i in range(0, len(tickers), chunk_size)]\n",
    "\n",
    "    for chunk in chunks:\n",
    "        try:\n",
    "            yq = Ticker(chunk, asynchronous=True)\n",
    "            # We need defaultKeyStatistics (P/B) and financialData (ROE, Debt)\n",
    "            data = yq.get_modules(\"defaultKeyStatistics financialData\")\n",
    "\n",
    "            for symbol in chunk:\n",
    "                if isinstance(data, dict) and symbol in data:\n",
    "                    try:\n",
    "                        stats = data[symbol].get('defaultKeyStatistics', {})\n",
    "                        fin = data[symbol].get('financialData', {})\n",
    "\n",
    "                        # 1. Price to Book < 1.0 (The Core Rule)\n",
    "                        pb = stats.get('priceToBook')\n",
    "                        # Skip if None, > 1.0, or negative (insolvent)\n",
    "                        if pb is None or pb >= 1.0 or pb <= 0: continue\n",
    "\n",
    "                        # 2. Positive ROE (No Zombies)\n",
    "                        roe = fin.get('returnOnEquity', 0)\n",
    "                        if roe is None or roe <= 0: continue\n",
    "\n",
    "                        # 3. Reasonable Debt (Safety)\n",
    "                        # Buffett hates high leverage on weak companies\n",
    "                        de = fin.get('debtToEquity', 0)\n",
    "                        if de is None or de > 100: continue \n",
    "\n",
    "                        # Get base data from input_df\n",
    "                        base_row = df_input[df_input['Ticker'] == symbol].iloc[0].to_dict()\n",
    "\n",
    "                        # Add new Value Metrics\n",
    "                        base_row['P/B Ratio'] = round(pb, 2)\n",
    "                        base_row['ROE %'] = round(roe * 100, 2)\n",
    "                        base_row['Debt/Eq %'] = round(de, 2)\n",
    "\n",
    "                        buffett_candidates.append(base_row)\n",
    "\n",
    "                    except: continue\n",
    "        except: continue\n",
    "\n",
    "    return pd.DataFrame(buffett_candidates)\n",
    "\n",
    "# ==========================================\n",
    "# EXECUTION BLOCK\n",
    "# ==========================================\n",
    "# Ensure we have the 'final_results' from the Main Filter\n",
    "if 'final_results' in locals() and not final_results.empty:\n",
    "    \n",
    "    Buffett_Value_DF = get_buffett_value_picks(final_results)\n",
    "    \n",
    "    if not Buffett_Value_DF.empty:\n",
    "        # Sort by P/B Ratio (Cheapest first)\n",
    "        Buffett_Value_DF = Buffett_Value_DF.sort_values(by='P/B Ratio', ascending=True)\n",
    "        \n",
    "        # Save results\n",
    "        Buffett_Value_DF.to_csv(BUFFETT_CSV, index=False)\n",
    "        \n",
    "        print(\"\\n\" + \"=\"*60)\n",
    "        print(\"BUFFETT SCAN COMPLETE\")\n",
    "        print(\"=\"*60)\n",
    "        print(f\"Found {len(Buffett_Value_DF)} Deep Value Stocks (Trading < Book Value)\")\n",
    "        print(\"Saved to: 'Buffett_Value_Picks.csv'\")\n",
    "        \n",
    "        # Display\n",
    "        pd.set_option('display.max_rows', 500)\n",
    "        cols = ['Ticker', 'Price', 'P/B Ratio', 'ROE %', 'Debt/Eq %', 'Sector', 'Tier']\n",
    "        print(\"\\n--- DEEP VALUE PICKS ---\")\n",
    "        print(Buffett_Value_DF[cols].head(20))\n",
    "        \n",
    "    else:\n",
    "        print(\"\\n‚ùå No stocks passed the Buffett Value filter (All stocks are trading > Book Value).\")\n",
    "else:\n",
    "    print(\"‚ùå 'final_results' variable not found. Please run the Main Filter first.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0a156e6f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üïµÔ∏è Scanning 348 stocks for Insider Buying...\n",
      "‚úÖ Created 'Fortress_insiders' with 31 rows.\n"
     ]
    },
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "Ticker",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "Insider_Buys_Count",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "Net_Shares_Bought",
         "rawType": "float64",
         "type": "float"
        }
       ],
       "ref": "ce663cdf-a4fa-4155-8de9-3cb6c0d93a1b",
       "rows": [
        [
         "0",
         "PGNY",
         "3",
         "68670.0"
        ],
        [
         "1",
         "PAAS",
         "15",
         "1368070.0"
        ],
        [
         "2",
         "VLTO",
         "6",
         "14327.0"
        ],
        [
         "3",
         "HXL",
         "110",
         "1575676.0"
        ],
        [
         "4",
         "SVM",
         "3",
         "8335.0"
        ],
        [
         "5",
         "NUE",
         "92",
         "5442652.0"
        ],
        [
         "6",
         "MGY",
         "1",
         "2000.0"
        ],
        [
         "7",
         "MAS",
         "10",
         "3517712.0"
        ],
        [
         "8",
         "SOLS",
         "4",
         "916900.0"
        ],
        [
         "9",
         "OPCH",
         "8",
         "18954.0"
        ],
        [
         "10",
         "ALC",
         "3",
         "147507.0"
        ],
        [
         "11",
         "HON",
         "3",
         "413316.0"
        ],
        [
         "12",
         "PDD",
         "5",
         "16257.0"
        ],
        [
         "13",
         "GLOB",
         "1",
         "8064.0"
        ],
        [
         "14",
         "DE",
         "1",
         "28994.0"
        ],
        [
         "15",
         "TXT",
         "17",
         "1259880.0"
        ],
        [
         "16",
         "BRKR",
         "4",
         "41837.0"
        ],
        [
         "17",
         "NTAP",
         "7",
         "7366.0"
        ],
        [
         "18",
         "TEX",
         "3",
         "24183.0"
        ],
        [
         "19",
         "RDY",
         "5",
         "22600.0"
        ],
        [
         "20",
         "AKAM",
         "93",
         "5086503.0"
        ],
        [
         "21",
         "CVE",
         "73",
         "53965480.0"
        ],
        [
         "22",
         "SU",
         "63",
         "12017751.0"
        ],
        [
         "23",
         "DEO",
         "2",
         "12803.0"
        ],
        [
         "24",
         "DAR",
         "11",
         "703246.0"
        ],
        [
         "25",
         "SLGN",
         "1",
         "1120.0"
        ],
        [
         "26",
         "UMC",
         "11",
         "72178.0"
        ],
        [
         "27",
         "NTNX",
         "4",
         "361161.0"
        ],
        [
         "28",
         "SSL",
         "5",
         "7038631.0"
        ],
        [
         "29",
         "ET",
         "8",
         "143034.0"
        ],
        [
         "30",
         "SSP",
         "3",
         "14900.0"
        ]
       ],
       "shape": {
        "columns": 3,
        "rows": 31
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Ticker</th>\n",
       "      <th>Insider_Buys_Count</th>\n",
       "      <th>Net_Shares_Bought</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>PGNY</td>\n",
       "      <td>3</td>\n",
       "      <td>68670.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>PAAS</td>\n",
       "      <td>15</td>\n",
       "      <td>1368070.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>VLTO</td>\n",
       "      <td>6</td>\n",
       "      <td>14327.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>HXL</td>\n",
       "      <td>110</td>\n",
       "      <td>1575676.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>SVM</td>\n",
       "      <td>3</td>\n",
       "      <td>8335.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>NUE</td>\n",
       "      <td>92</td>\n",
       "      <td>5442652.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>MGY</td>\n",
       "      <td>1</td>\n",
       "      <td>2000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>MAS</td>\n",
       "      <td>10</td>\n",
       "      <td>3517712.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>SOLS</td>\n",
       "      <td>4</td>\n",
       "      <td>916900.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>OPCH</td>\n",
       "      <td>8</td>\n",
       "      <td>18954.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>ALC</td>\n",
       "      <td>3</td>\n",
       "      <td>147507.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>HON</td>\n",
       "      <td>3</td>\n",
       "      <td>413316.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>PDD</td>\n",
       "      <td>5</td>\n",
       "      <td>16257.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>GLOB</td>\n",
       "      <td>1</td>\n",
       "      <td>8064.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>DE</td>\n",
       "      <td>1</td>\n",
       "      <td>28994.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>TXT</td>\n",
       "      <td>17</td>\n",
       "      <td>1259880.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>BRKR</td>\n",
       "      <td>4</td>\n",
       "      <td>41837.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>NTAP</td>\n",
       "      <td>7</td>\n",
       "      <td>7366.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>TEX</td>\n",
       "      <td>3</td>\n",
       "      <td>24183.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>RDY</td>\n",
       "      <td>5</td>\n",
       "      <td>22600.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>AKAM</td>\n",
       "      <td>93</td>\n",
       "      <td>5086503.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>CVE</td>\n",
       "      <td>73</td>\n",
       "      <td>53965480.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>SU</td>\n",
       "      <td>63</td>\n",
       "      <td>12017751.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>DEO</td>\n",
       "      <td>2</td>\n",
       "      <td>12803.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>DAR</td>\n",
       "      <td>11</td>\n",
       "      <td>703246.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>SLGN</td>\n",
       "      <td>1</td>\n",
       "      <td>1120.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>UMC</td>\n",
       "      <td>11</td>\n",
       "      <td>72178.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>NTNX</td>\n",
       "      <td>4</td>\n",
       "      <td>361161.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>SSL</td>\n",
       "      <td>5</td>\n",
       "      <td>7038631.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>ET</td>\n",
       "      <td>8</td>\n",
       "      <td>143034.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>SSP</td>\n",
       "      <td>3</td>\n",
       "      <td>14900.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Ticker  Insider_Buys_Count  Net_Shares_Bought\n",
       "0    PGNY                   3            68670.0\n",
       "1    PAAS                  15          1368070.0\n",
       "2    VLTO                   6            14327.0\n",
       "3     HXL                 110          1575676.0\n",
       "4     SVM                   3             8335.0\n",
       "5     NUE                  92          5442652.0\n",
       "6     MGY                   1             2000.0\n",
       "7     MAS                  10          3517712.0\n",
       "8    SOLS                   4           916900.0\n",
       "9    OPCH                   8            18954.0\n",
       "10    ALC                   3           147507.0\n",
       "11    HON                   3           413316.0\n",
       "12    PDD                   5            16257.0\n",
       "13   GLOB                   1             8064.0\n",
       "14     DE                   1            28994.0\n",
       "15    TXT                  17          1259880.0\n",
       "16   BRKR                   4            41837.0\n",
       "17   NTAP                   7             7366.0\n",
       "18    TEX                   3            24183.0\n",
       "19    RDY                   5            22600.0\n",
       "20   AKAM                  93          5086503.0\n",
       "21    CVE                  73         53965480.0\n",
       "22     SU                  63         12017751.0\n",
       "23    DEO                   2            12803.0\n",
       "24    DAR                  11           703246.0\n",
       "25   SLGN                   1             1120.0\n",
       "26    UMC                  11            72178.0\n",
       "27   NTNX                   4           361161.0\n",
       "28    SSL                   5          7038631.0\n",
       "29     ET                   8           143034.0\n",
       "30    SSP                   3            14900.0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from yahooquery import Ticker\n",
    "from IPython.display import display, Markdown\n",
    "import warnings\n",
    "# Ignore these specific FutureWarning messages\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "# ==========================================\n",
    "# INSIDER FILTER FUNCTION\n",
    "# ==========================================\n",
    "def filter_for_insider_buying(tickers):\n",
    "    print(f\"üïµÔ∏è Scanning {len(tickers)} stocks for Insider Buying...\")\n",
    "    insider_picks = []\n",
    "    \n",
    "    # Chunk to prevent timeouts\n",
    "    chunk_size = 20\n",
    "    chunks = [tickers[i:i + chunk_size] for i in range(0, len(tickers), chunk_size)]\n",
    "    \n",
    "    for chunk in chunks:\n",
    "        try:\n",
    "            yq = Ticker(chunk, asynchronous=True)\n",
    "            df_insiders = yq.insider_transactions\n",
    "            \n",
    "            if isinstance(df_insiders, dict) or not hasattr(df_insiders, 'reset_index'): \n",
    "                continue\n",
    "            \n",
    "            df_insiders = df_insiders.reset_index()\n",
    "\n",
    "            for symbol in chunk:\n",
    "                if symbol not in df_insiders['symbol'].values:\n",
    "                    continue\n",
    "                \n",
    "                stock_tx = df_insiders[df_insiders['symbol'] == symbol].copy()\n",
    "                \n",
    "                # Filter for Purchases\n",
    "                buys = stock_tx[stock_tx['transactionText'].astype(str).str.contains(\"Purchase\", case=False, na=False)]\n",
    "                sells = stock_tx[stock_tx['transactionText'].astype(str).str.contains(\"Sale\", case=False, na=False)]\n",
    "                \n",
    "                # Logic: Net Positive Buying\n",
    "                buy_vol = buys['shares'].sum() if not buys.empty else 0\n",
    "                sell_vol = sells['shares'].sum() if not sells.empty else 0\n",
    "                \n",
    "                if buy_vol > sell_vol:\n",
    "                    insider_picks.append({\n",
    "                        'Ticker': symbol,\n",
    "                        'Insider_Buys_Count': len(buys),\n",
    "                        'Net_Shares_Bought': buy_vol - sell_vol\n",
    "                    })\n",
    "                        \n",
    "        except Exception:\n",
    "            continue\n",
    "\n",
    "    return pd.DataFrame(insider_picks)\n",
    "\n",
    "# ==========================================\n",
    "# 2. CREATE 'Fortress_insiders' DATAFRAME\n",
    "# ==========================================\n",
    "\n",
    "# Use fortress_df if it exists, otherwise use the top 20 backup list\n",
    "if 'fortress_df' in locals() and not fortress_df.empty:\n",
    "    target_tickers = fortress_df['Ticker'].tolist()\n",
    "else:\n",
    "    # Backup list from your logs so this runs even if you restarted the kernel\n",
    "    target_tickers = [\n",
    "        'PET.TO', 'MFI.TO', 'TXG.TO', 'SAP.TO', 'PAAS.TO', 'NEO.TO', 'WPM.TO', \n",
    "        'FNV.TO', 'LUG.TO', 'DPM.TO', 'ASM.TO', 'PNG.V', 'DSG.TO', 'KNT.TO', \n",
    "        'GGD.TO', 'GRGD.TO', 'WDO.TO', 'OGC.TO', 'DNG.TO', 'CLS.TO'\n",
    "    ]\n",
    "\n",
    "# Run the filter and assign to the variable you requested\n",
    "Fortress_insiders = filter_for_insider_buying(target_tickers)\n",
    "\n",
    "# Display so Data Wrangler picks it up\n",
    "print(f\"‚úÖ Created 'Fortress_insiders' with {len(Fortress_insiders)} rows.\")\n",
    "display(Fortress_insiders)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "eb164c43",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üïµÔ∏è Scanning 348 stocks for Insider Buying...\n",
      "‚úÖ Analyst Filter: 24 -> 22 stocks (Min Rating: Buy).\n",
      "\n",
      "üöÄ Final List: 22 stocks (Fortress + Insider Buying + Analyst Buy Rating)\n"
     ]
    },
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "Ticker",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "Insider_Buys_Count",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "Net_Shares_Bought",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "Analyst_Score",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "Analyst_Verdict",
         "rawType": "object",
         "type": "string"
        }
       ],
       "ref": "193b08d8-8375-4a68-982e-ba34bad9a8e3",
       "rows": [
        [
         "4",
         "SVM",
         "3",
         "8335.0",
         "1.33333",
         "strong_buy"
        ],
        [
         "22",
         "DAR",
         "11",
         "703246.0",
         "1.38462",
         "strong_buy"
        ],
        [
         "5",
         "NUE",
         "92",
         "5442652.0",
         "1.46667",
         "strong_buy"
        ],
        [
         "9",
         "OPCH",
         "8",
         "18954.0",
         "1.5",
         "strong_buy"
        ],
        [
         "19",
         "CVE",
         "73",
         "53965480.0",
         "1.52941",
         "buy"
        ],
        [
         "12",
         "PDD",
         "5",
         "16257.0",
         "1.7561",
         "buy"
        ],
        [
         "10",
         "ALC",
         "3",
         "147507.0",
         "1.78571",
         "buy"
        ],
        [
         "0",
         "PGNY",
         "3",
         "68670.0",
         "1.81818",
         "buy"
        ],
        [
         "1",
         "PAAS",
         "15",
         "1368070.0",
         "2.0",
         "buy"
        ],
        [
         "2",
         "VLTO",
         "6",
         "14327.0",
         "2.05263",
         "buy"
        ],
        [
         "16",
         "BRKR",
         "4",
         "41837.0",
         "2.06667",
         "buy"
        ],
        [
         "11",
         "HON",
         "3",
         "413316.0",
         "2.07407",
         "buy"
        ],
        [
         "20",
         "SU",
         "63",
         "12017751.0",
         "2.09524",
         "buy"
        ],
        [
         "6",
         "MGY",
         "1",
         "2000.0",
         "2.11111",
         "buy"
        ],
        [
         "14",
         "DE",
         "1",
         "28994.0",
         "2.12",
         "buy"
        ],
        [
         "13",
         "GLOB",
         "1",
         "8064.0",
         "2.13636",
         "buy"
        ],
        [
         "8",
         "SOLS",
         "4",
         "916900.0",
         "2.16667",
         "buy"
        ],
        [
         "17",
         "TEX",
         "3",
         "24183.0",
         "2.18182",
         "buy"
        ],
        [
         "18",
         "AKAM",
         "93",
         "5086503.0",
         "2.20833",
         "buy"
        ],
        [
         "15",
         "TXT",
         "17",
         "1259880.0",
         "2.3125",
         "buy"
        ],
        [
         "21",
         "DEO",
         "2",
         "12803.0",
         "2.375",
         "buy"
        ],
        [
         "7",
         "MAS",
         "10",
         "3517712.0",
         "2.47826",
         "buy"
        ]
       ],
       "shape": {
        "columns": 5,
        "rows": 22
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Ticker</th>\n",
       "      <th>Insider_Buys_Count</th>\n",
       "      <th>Net_Shares_Bought</th>\n",
       "      <th>Analyst_Score</th>\n",
       "      <th>Analyst_Verdict</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>SVM</td>\n",
       "      <td>3</td>\n",
       "      <td>8335.0</td>\n",
       "      <td>1.33333</td>\n",
       "      <td>strong_buy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>DAR</td>\n",
       "      <td>11</td>\n",
       "      <td>703246.0</td>\n",
       "      <td>1.38462</td>\n",
       "      <td>strong_buy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>NUE</td>\n",
       "      <td>92</td>\n",
       "      <td>5442652.0</td>\n",
       "      <td>1.46667</td>\n",
       "      <td>strong_buy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>OPCH</td>\n",
       "      <td>8</td>\n",
       "      <td>18954.0</td>\n",
       "      <td>1.50000</td>\n",
       "      <td>strong_buy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>CVE</td>\n",
       "      <td>73</td>\n",
       "      <td>53965480.0</td>\n",
       "      <td>1.52941</td>\n",
       "      <td>buy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>PDD</td>\n",
       "      <td>5</td>\n",
       "      <td>16257.0</td>\n",
       "      <td>1.75610</td>\n",
       "      <td>buy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>ALC</td>\n",
       "      <td>3</td>\n",
       "      <td>147507.0</td>\n",
       "      <td>1.78571</td>\n",
       "      <td>buy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>PGNY</td>\n",
       "      <td>3</td>\n",
       "      <td>68670.0</td>\n",
       "      <td>1.81818</td>\n",
       "      <td>buy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>PAAS</td>\n",
       "      <td>15</td>\n",
       "      <td>1368070.0</td>\n",
       "      <td>2.00000</td>\n",
       "      <td>buy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>VLTO</td>\n",
       "      <td>6</td>\n",
       "      <td>14327.0</td>\n",
       "      <td>2.05263</td>\n",
       "      <td>buy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>BRKR</td>\n",
       "      <td>4</td>\n",
       "      <td>41837.0</td>\n",
       "      <td>2.06667</td>\n",
       "      <td>buy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>HON</td>\n",
       "      <td>3</td>\n",
       "      <td>413316.0</td>\n",
       "      <td>2.07407</td>\n",
       "      <td>buy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>SU</td>\n",
       "      <td>63</td>\n",
       "      <td>12017751.0</td>\n",
       "      <td>2.09524</td>\n",
       "      <td>buy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>MGY</td>\n",
       "      <td>1</td>\n",
       "      <td>2000.0</td>\n",
       "      <td>2.11111</td>\n",
       "      <td>buy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>DE</td>\n",
       "      <td>1</td>\n",
       "      <td>28994.0</td>\n",
       "      <td>2.12000</td>\n",
       "      <td>buy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>GLOB</td>\n",
       "      <td>1</td>\n",
       "      <td>8064.0</td>\n",
       "      <td>2.13636</td>\n",
       "      <td>buy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>SOLS</td>\n",
       "      <td>4</td>\n",
       "      <td>916900.0</td>\n",
       "      <td>2.16667</td>\n",
       "      <td>buy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>TEX</td>\n",
       "      <td>3</td>\n",
       "      <td>24183.0</td>\n",
       "      <td>2.18182</td>\n",
       "      <td>buy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>AKAM</td>\n",
       "      <td>93</td>\n",
       "      <td>5086503.0</td>\n",
       "      <td>2.20833</td>\n",
       "      <td>buy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>TXT</td>\n",
       "      <td>17</td>\n",
       "      <td>1259880.0</td>\n",
       "      <td>2.31250</td>\n",
       "      <td>buy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>DEO</td>\n",
       "      <td>2</td>\n",
       "      <td>12803.0</td>\n",
       "      <td>2.37500</td>\n",
       "      <td>buy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>MAS</td>\n",
       "      <td>10</td>\n",
       "      <td>3517712.0</td>\n",
       "      <td>2.47826</td>\n",
       "      <td>buy</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Ticker  Insider_Buys_Count  Net_Shares_Bought  Analyst_Score Analyst_Verdict\n",
       "4     SVM                   3             8335.0        1.33333      strong_buy\n",
       "22    DAR                  11           703246.0        1.38462      strong_buy\n",
       "5     NUE                  92          5442652.0        1.46667      strong_buy\n",
       "9    OPCH                   8            18954.0        1.50000      strong_buy\n",
       "19    CVE                  73         53965480.0        1.52941             buy\n",
       "12    PDD                   5            16257.0        1.75610             buy\n",
       "10    ALC                   3           147507.0        1.78571             buy\n",
       "0    PGNY                   3            68670.0        1.81818             buy\n",
       "1    PAAS                  15          1368070.0        2.00000             buy\n",
       "2    VLTO                   6            14327.0        2.05263             buy\n",
       "16   BRKR                   4            41837.0        2.06667             buy\n",
       "11    HON                   3           413316.0        2.07407             buy\n",
       "20     SU                  63         12017751.0        2.09524             buy\n",
       "6     MGY                   1             2000.0        2.11111             buy\n",
       "14     DE                   1            28994.0        2.12000             buy\n",
       "13   GLOB                   1             8064.0        2.13636             buy\n",
       "8    SOLS                   4           916900.0        2.16667             buy\n",
       "17    TEX                   3            24183.0        2.18182             buy\n",
       "18   AKAM                  93          5086503.0        2.20833             buy\n",
       "15    TXT                  17          1259880.0        2.31250             buy\n",
       "21    DEO                   2            12803.0        2.37500             buy\n",
       "7     MAS                  10          3517712.0        2.47826             buy"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "# ==========================================\n",
    "# 2. ANALYST FILTER FUNCTION FOR INSIDER PICKS (NEW)\n",
    "# ==========================================\n",
    "def filter_for_analyst_ratings(df_insiders, max_score=2.5):\n",
    "    \"\"\"\n",
    "    Fetches analyst data for the insider winners and filters for 'Buy' or better.\n",
    "    Scale: 1.0 = Strong Buy, 5.0 = Sell.\n",
    "    Cutoff: 2.5 ensures we get 'Buy' and 'Strong Buy'.\n",
    "    \"\"\"\n",
    "    if df_insiders.empty:\n",
    "        return df_insiders\n",
    "        \n",
    "    tickers = df_insiders['Ticker'].tolist()\n",
    "    \n",
    "    \n",
    "    try:\n",
    "        yq = Ticker(tickers, asynchronous=True)\n",
    "        # 'financial_data' contains the specific recommendation scores\n",
    "        fin_data = yq.financial_data\n",
    "        \n",
    "        analyst_data = []\n",
    "        for t in tickers:\n",
    "            # Check if we got valid data for this ticker\n",
    "            if isinstance(fin_data, dict) and t in fin_data:\n",
    "                data = fin_data[t]\n",
    "                # Ensure it's a dictionary and has the key we need\n",
    "                if isinstance(data, dict) and 'recommendationMean' in data:\n",
    "                    score = data.get('recommendationMean')\n",
    "                    \n",
    "                    # Only keep valid scores (sometimes they are None)\n",
    "                    if score is not None:\n",
    "                        analyst_data.append({\n",
    "                            'Ticker': t,\n",
    "                            'Analyst_Score': score,\n",
    "                            'Analyst_Verdict': data.get('recommendationKey', 'N/A')\n",
    "                        })\n",
    "        \n",
    "        df_analyst = pd.DataFrame(analyst_data)\n",
    "        \n",
    "        if df_analyst.empty:\n",
    "            print(\"‚ö†Ô∏è No Analyst ratings found for these tickers.\")\n",
    "            return df_insiders # Return original if no data found\n",
    "            \n",
    "        # Merge with the Insider DataFrame\n",
    "        merged = pd.merge(df_insiders, df_analyst, on='Ticker', how='inner')\n",
    "        \n",
    "        # FILTER: Keep only scores <= max_score (Lower is better)\n",
    "        final_df = merged[merged['Analyst_Score'] <= max_score].copy()\n",
    "        \n",
    "        print(f\"‚úÖ Analyst Filter: {len(merged)} -> {len(final_df)} stocks (Min Rating: Buy).\")\n",
    "        return final_df.sort_values(by='Analyst_Score', ascending=True)\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Error in Analyst Filter: {e}\")\n",
    "        return df_insiders\n",
    "\n",
    "# ==========================================\n",
    "# 3. EXECUTION PIPELINE\n",
    "# ==========================================\n",
    "\n",
    "# A. Setup Tickers\n",
    "if 'fortress_df' in locals() and not fortress_df.empty:\n",
    "    target_tickers = fortress_df['Ticker'].tolist()\n",
    "else:\n",
    "    # Backup list just in case\n",
    "    target_tickers = [\n",
    "        'PET.TO', 'MFI.TO', 'TXG.TO', 'SAP.TO', 'PAAS.TO', 'NEO.TO', 'WPM.TO', \n",
    "        'FNV.TO', 'LUG.TO', 'DPM.TO', 'ASM.TO', 'PNG.V', 'DSG.TO', 'KNT.TO', \n",
    "        'GGD.TO', 'GRGD.TO', 'WDO.TO', 'OGC.TO', 'DNG.TO', 'CLS.TO'\n",
    "    ]\n",
    "\n",
    "# B. Run Insider Filter\n",
    "insider_winners = filter_for_insider_buying(target_tickers)\n",
    "\n",
    "# C. Run Analyst Filter (NEW STEP)\n",
    "# We overwrite 'Fortress_insiders' so it works with your Data Wrangler flow\n",
    "if not insider_winners.empty:\n",
    "    Fortress_insiders_Analyst_buy = filter_for_analyst_ratings(insider_winners, max_score=2.5)\n",
    "else:\n",
    "    Fortress_insiders_Analyst_buy = pd.DataFrame()\n",
    "\n",
    "# D. Display Result\n",
    "if not Fortress_insiders_Analyst_buy.empty:\n",
    "    print(f\"\\nüöÄ Final List: {len(Fortress_insiders_Analyst_buy)} stocks (Fortress + Insider Buying + Analyst Buy Rating)\")\n",
    "    display(Fortress_insiders_Analyst_buy)\n",
    "else:\n",
    "    print(\"No stocks passed all filters.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ceaa9fcb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Processing 11 stocks ---\n",
      "1. Fetching Analyst Ratings from Finviz...\n",
      "2. Fetching Price & Volatility from yfinance...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\James\\AppData\\Local\\Temp\\ipykernel_30396\\2779024273.py:46: FutureWarning: YF.download() has changed argument auto_adjust default to True\n",
      "  data = yf.download(ticker_list, period=\"1y\", interval=\"1d\", group_by='ticker', progress=False, threads=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Watchlist ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "Ticker",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "Price",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "Change_%",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "52W_MA",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "Drop_from_High_%",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "Recom",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "Target_Price",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "Rel_Volume",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "Volatility_%",
         "rawType": "float64",
         "type": "float"
        }
       ],
       "ref": "c76a0b86-51cb-4f33-ad27-fe047503b1c4",
       "rows": [
        [
         "6",
         "GRND",
         "13.41",
         "-0.59",
         "17.66",
         "-46.64",
         "1.40",
         "21.75",
         "0.52",
         "3.18"
        ],
        [
         "0",
         "ADMA",
         "19.11",
         "-0.88",
         "17.9",
         "-25.56",
         "1.00",
         "30.00",
         "0.39",
         "3.26"
        ],
        [
         "9",
         "SEI",
         "44.58",
         "-0.16",
         "32.53",
         "-21.85",
         "1.17",
         "65.45",
         "0.38",
         "5.9"
        ],
        [
         "7",
         "MIR",
         "23.77",
         "0.08",
         "19.92",
         "-21.49",
         "1.12",
         "30.62",
         "0.45",
         "3.49"
        ],
        [
         "10",
         "UBER",
         "81.5",
         "0.3",
         "84.53",
         "-20.09",
         "1.47",
         "112.40",
         "0.56",
         "2.41"
        ],
        [
         "5",
         "FLEX",
         "62.56",
         "-1.22",
         "48.3",
         "-13.38",
         "1.50",
         "76.00",
         "0.3",
         "2.9"
        ],
        [
         "2",
         "ARCC",
         "20.17",
         "-0.15",
         "20.48",
         "-9.91",
         "1.27",
         "22.64",
         "1.47",
         "1.38"
        ],
        [
         "8",
         "ONB",
         "22.79",
         "-0.83",
         "21.4",
         "-4.55",
         "1.85",
         "25.92",
         "1.09",
         "2.14"
        ],
        [
         "1",
         "APG",
         "39.2",
         "-0.94",
         "31.4",
         "-3.4",
         "1.45",
         "43.40",
         "0.34",
         "1.92"
        ],
        [
         "4",
         "DD",
         "40.89",
         "-0.9",
         "31.9",
         "-2.29",
         "1.48",
         "47.19",
         "0.59",
         "2.23"
        ],
        [
         "3",
         "BANC",
         "19.63",
         "-0.36",
         "15.37",
         "-2.19",
         "1.27",
         "22.14",
         "0.53",
         "2.18"
        ]
       ],
       "shape": {
        "columns": 9,
        "rows": 11
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Ticker</th>\n",
       "      <th>Price</th>\n",
       "      <th>Change_%</th>\n",
       "      <th>52W_MA</th>\n",
       "      <th>Drop_from_High_%</th>\n",
       "      <th>Recom</th>\n",
       "      <th>Target_Price</th>\n",
       "      <th>Rel_Volume</th>\n",
       "      <th>Volatility_%</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>GRND</td>\n",
       "      <td>13.41</td>\n",
       "      <td>-0.59</td>\n",
       "      <td>17.66</td>\n",
       "      <td>-46.64</td>\n",
       "      <td>1.40</td>\n",
       "      <td>21.75</td>\n",
       "      <td>0.52</td>\n",
       "      <td>3.18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ADMA</td>\n",
       "      <td>19.11</td>\n",
       "      <td>-0.88</td>\n",
       "      <td>17.90</td>\n",
       "      <td>-25.56</td>\n",
       "      <td>1.00</td>\n",
       "      <td>30.00</td>\n",
       "      <td>0.39</td>\n",
       "      <td>3.26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>SEI</td>\n",
       "      <td>44.58</td>\n",
       "      <td>-0.16</td>\n",
       "      <td>32.53</td>\n",
       "      <td>-21.85</td>\n",
       "      <td>1.17</td>\n",
       "      <td>65.45</td>\n",
       "      <td>0.38</td>\n",
       "      <td>5.90</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>MIR</td>\n",
       "      <td>23.77</td>\n",
       "      <td>0.08</td>\n",
       "      <td>19.92</td>\n",
       "      <td>-21.49</td>\n",
       "      <td>1.12</td>\n",
       "      <td>30.62</td>\n",
       "      <td>0.45</td>\n",
       "      <td>3.49</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>UBER</td>\n",
       "      <td>81.50</td>\n",
       "      <td>0.30</td>\n",
       "      <td>84.53</td>\n",
       "      <td>-20.09</td>\n",
       "      <td>1.47</td>\n",
       "      <td>112.40</td>\n",
       "      <td>0.56</td>\n",
       "      <td>2.41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>FLEX</td>\n",
       "      <td>62.56</td>\n",
       "      <td>-1.22</td>\n",
       "      <td>48.30</td>\n",
       "      <td>-13.38</td>\n",
       "      <td>1.50</td>\n",
       "      <td>76.00</td>\n",
       "      <td>0.30</td>\n",
       "      <td>2.90</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ARCC</td>\n",
       "      <td>20.17</td>\n",
       "      <td>-0.15</td>\n",
       "      <td>20.48</td>\n",
       "      <td>-9.91</td>\n",
       "      <td>1.27</td>\n",
       "      <td>22.64</td>\n",
       "      <td>1.47</td>\n",
       "      <td>1.38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>ONB</td>\n",
       "      <td>22.79</td>\n",
       "      <td>-0.83</td>\n",
       "      <td>21.40</td>\n",
       "      <td>-4.55</td>\n",
       "      <td>1.85</td>\n",
       "      <td>25.92</td>\n",
       "      <td>1.09</td>\n",
       "      <td>2.14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>APG</td>\n",
       "      <td>39.20</td>\n",
       "      <td>-0.94</td>\n",
       "      <td>31.40</td>\n",
       "      <td>-3.40</td>\n",
       "      <td>1.45</td>\n",
       "      <td>43.40</td>\n",
       "      <td>0.34</td>\n",
       "      <td>1.92</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>DD</td>\n",
       "      <td>40.89</td>\n",
       "      <td>-0.90</td>\n",
       "      <td>31.90</td>\n",
       "      <td>-2.29</td>\n",
       "      <td>1.48</td>\n",
       "      <td>47.19</td>\n",
       "      <td>0.59</td>\n",
       "      <td>2.23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>BANC</td>\n",
       "      <td>19.63</td>\n",
       "      <td>-0.36</td>\n",
       "      <td>15.37</td>\n",
       "      <td>-2.19</td>\n",
       "      <td>1.27</td>\n",
       "      <td>22.14</td>\n",
       "      <td>0.53</td>\n",
       "      <td>2.18</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Ticker  Price  Change_%  52W_MA  Drop_from_High_% Recom Target_Price  Rel_Volume  Volatility_%\n",
       "6    GRND  13.41     -0.59   17.66            -46.64  1.40        21.75        0.52          3.18\n",
       "0    ADMA  19.11     -0.88   17.90            -25.56  1.00        30.00        0.39          3.26\n",
       "9     SEI  44.58     -0.16   32.53            -21.85  1.17        65.45        0.38          5.90\n",
       "7     MIR  23.77      0.08   19.92            -21.49  1.12        30.62        0.45          3.49\n",
       "10   UBER  81.50      0.30   84.53            -20.09  1.47       112.40        0.56          2.41\n",
       "5    FLEX  62.56     -1.22   48.30            -13.38  1.50        76.00        0.30          2.90\n",
       "2    ARCC  20.17     -0.15   20.48             -9.91  1.27        22.64        1.47          1.38\n",
       "8     ONB  22.79     -0.83   21.40             -4.55  1.85        25.92        1.09          2.14\n",
       "1     APG  39.20     -0.94   31.40             -3.40  1.45        43.40        0.34          1.92\n",
       "4      DD  40.89     -0.90   31.90             -2.29  1.48        47.19        0.59          2.23\n",
       "3    BANC  19.63     -0.36   15.37             -2.19  1.27        22.14        0.53          2.18"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# ==========================================\n",
    "# Watchlist Combiner (Finviz + YFinance)\n",
    "# ==========================================\n",
    "\n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "import yfinance as yf\n",
    "from finvizfinance.quote import finvizfinance\n",
    "import time\n",
    "import numpy as np\n",
    "\n",
    "# --- 1. INPUT YOUR MANUAL LIST HERE ---\n",
    "MY_TICKERS = ['GRND','ARCC','BANC','ONB','UBER','ADMA','MIR','APG','SEI','FLEX','DD',] \n",
    "\n",
    "def get_combined_watchlist(ticker_list):\n",
    "    print(f\"--- Processing {len(ticker_list)} stocks ---\")\n",
    "    \n",
    "    # --- PART A: Get Analyst Ratings from Finviz ---\n",
    "    print(\"1. Fetching Analyst Ratings from Finviz...\")\n",
    "    finviz_data = []\n",
    "    \n",
    "    for ticker in ticker_list:\n",
    "        try:\n",
    "            stock = finvizfinance(ticker)\n",
    "            info = stock.ticker_fundament()\n",
    "            \n",
    "            finviz_data.append({\n",
    "                'Ticker': ticker,\n",
    "                'Recom': info.get('Recom', np.nan),\n",
    "                'Target_Price': info.get('Target Price', np.nan)\n",
    "            })\n",
    "            time.sleep(0.5) \n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"   Skipping Finviz for {ticker}: {e}\")\n",
    "            finviz_data.append({'Ticker': ticker, 'Recom': np.nan, 'Target_Price': np.nan})\n",
    "\n",
    "    df_finviz = pd.DataFrame(finviz_data)\n",
    "    \n",
    "    # --- PART B: Get Real-Time Stats from yfinance ---\n",
    "    print(\"2. Fetching Price & Volatility from yfinance...\")\n",
    "    \n",
    "    try:\n",
    "        # Download data (1 Year is perfect for 52-Week MA)\n",
    "        data = yf.download(ticker_list, period=\"1y\", interval=\"1d\", group_by='ticker', progress=False, threads=True)\n",
    "        yf_stats = []\n",
    "        \n",
    "        for ticker in ticker_list:\n",
    "            try:\n",
    "                # --- FIXED: Robust Data Extraction ---\n",
    "                if isinstance(data.columns, pd.MultiIndex):\n",
    "                    if ticker in data.columns.levels[0]:\n",
    "                        df = data[ticker].copy()\n",
    "                    else:\n",
    "                        print(f\"   Warning: {ticker} not found in yfinance download.\")\n",
    "                        continue\n",
    "                else:\n",
    "                    df = data.copy()\n",
    "\n",
    "                # Cleanup\n",
    "                df = df.dropna(subset=['Close'])\n",
    "                if len(df) < 20: \n",
    "                    print(f\"   Warning: Not enough data for {ticker}\")\n",
    "                    continue\n",
    "\n",
    "                # --- MATH CALCULATIONS ---\n",
    "                current_price = df['Close'].iloc[-1]\n",
    "                prev_close = df['Close'].iloc[-2]\n",
    "                \n",
    "                high_52 = df['High'].max()\n",
    "                drop_from_high = ((current_price - high_52) / high_52) * 100\n",
    "                \n",
    "                change_pct = ((current_price - prev_close) / prev_close) * 100\n",
    "                \n",
    "                # Volatility (30-day Std Dev)\n",
    "                volatility = df['Close'].pct_change().std() * 100\n",
    "                \n",
    "                # Relative Volume\n",
    "                curr_vol = df['Volume'].iloc[-1]\n",
    "                avg_vol = df['Volume'].tail(30).mean()\n",
    "                rel_vol = curr_vol / avg_vol if avg_vol > 0 else 0\n",
    "\n",
    "                # --- NEW: 52-Week Moving Average ---\n",
    "                # Since we fetched exactly 1 year ('1y'), the mean of the whole column is the 52W MA\n",
    "                ma_52w = df['Close'].mean()\n",
    "\n",
    "                # Distance from MA (Optional but helpful metric)\n",
    "                # dist_ma = ((current_price - ma_52w) / ma_52w) * 100 \n",
    "\n",
    "                yf_stats.append({\n",
    "                    'Ticker': ticker,\n",
    "                    'Price': round(current_price, 2),\n",
    "                    'Change_%': round(change_pct, 2),\n",
    "                    '52W_MA': round(ma_52w, 2),          # <--- Added Here\n",
    "                    'Drop_from_High_%': round(drop_from_high, 2),\n",
    "                    'Volatility_%': round(volatility, 2),\n",
    "                    'Rel_Volume': round(rel_vol, 2)\n",
    "                })\n",
    "                \n",
    "            except Exception as e:\n",
    "                print(f\"   Error calculating stats for {ticker}: {e}\")\n",
    "                continue\n",
    "                \n",
    "        df_yf = pd.DataFrame(yf_stats)\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"yfinance Critical Error: {e}\")\n",
    "        return pd.DataFrame()\n",
    "\n",
    "    # --- PART C: Merge ---\n",
    "    if not df_finviz.empty:\n",
    "        if not df_yf.empty:\n",
    "            master_df = pd.merge(df_finviz, df_yf, on='Ticker', how='outer')\n",
    "        else:\n",
    "            master_df = df_finviz\n",
    "            \n",
    "        # Added '52W_MA' to this list so it displays in the final table\n",
    "        cols = ['Ticker', 'Price', 'Change_%', '52W_MA', 'Drop_from_High_%', 'Recom', 'Target_Price', 'Rel_Volume', 'Volatility_%']\n",
    "        \n",
    "        final_cols = [c for c in cols if c in master_df.columns]\n",
    "        return master_df[final_cols]\n",
    "    else:\n",
    "        return pd.DataFrame()\n",
    "\n",
    "# --- RUN IT ---\n",
    "watchlist_df = get_combined_watchlist(MY_TICKERS)\n",
    "\n",
    "if not watchlist_df.empty:\n",
    "    if 'Drop_from_High_%' in watchlist_df.columns:\n",
    "        watchlist_df['Drop_from_High_%'] = pd.to_numeric(watchlist_df['Drop_from_High_%'], errors='coerce')\n",
    "        print(\"\\n--- Final Watchlist ---\")\n",
    "        display(watchlist_df.sort_values(by='Drop_from_High_%', ascending=True))\n",
    "    else:\n",
    "        display(watchlist_df)\n",
    "else:\n",
    "    print(\"No data found.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "01880793",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import pandas as pd\n",
    "import google as genai\n",
    "import enum\n",
    "from typing_extensions import TypedDict\n",
    "import json\n",
    "import plotly.express as px\n",
    "import sys\n",
    "#!\"{sys.executable}\" -m pip install google.genai\n",
    "#!\"{sys.executable}\" -m pip install plotly.express"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b06187d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "tickers_gemini = ['NVDA'] \n",
    "import os\n",
    "from google import genai\n",
    "from google.genai import types\n",
    "from IPython.display import display, Markdown"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "333020a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ API Key loaded securely.\n",
      "\n",
      "üß† Gemini 3 is thinking (High Reasoning Mode)... analyzing $['NVDA']...\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "## üß† Gemini 3 Sentiment Report: ['NVDA']\n",
       "**Reasoning Depth:** High  \n",
       "**Sentiment Score:** 7.8 / 10  \n",
       "**Verdict:** Buy on Weakness (Opportunity)\n",
       "\n",
       "---\n",
       "\n",
       "### 1. The Bull Thesis (Why it goes up)\n",
       "*   **The \"Inference\" Pivot**: The $20 billion Groq licensing deal is a massive strategic move. It signals NVIDIA's shift from being a \"training\" powerhouse to dominating \"low-latency inference,\" effectively killing the thesis that competitors like Groq could disrupt its moat.\n",
       "*   **Blackwell Demand**: Management confirmed \"insatiable\" demand for Blackwell architecture, which is effectively sold out through mid-2026.\n",
       "*   **China Re-entry**: The US authorization of H200 chip exports to China (even with the 25% tax) reopens a multi-billion dollar revenue stream previously considered \"lost\" due to geopolitical friction.\n",
       "*   **Analyst Upward Pressure**: Recent weeks have seen targets shift from the $240 range to a consensus $275, with \"whisper\" targets pushing toward $300-$350 by 2026.\n",
       "\n",
       "### 2. The Bear Thesis (Why it goes down)\n",
       "*   **The \"Insider Exit\" Signal**: Corporate insiders, including CEO Jensen Huang, sold over $1.7 billion in shares in 2025. While often dismissed as \"diversification,\" the sheer volume and the fact that there are *zero* insider buys in the last 12 months creates a psychological ceiling.\n",
       "*   **Capital Bloat**: Strategic bets like the $5 billion Intel stake and the $20 billion Groq deal are massive deployments of cash. Bears argue this \"aggressive spending\" hints at a desperate attempt to defend a moat that is starting to leak.\n",
       "*   **Priced for Perfection**: With Q4 revenue guidance at a staggering $65B (+/- 2%), even a \"minor beat\" is no longer enough to move the needle. The market demands a \"beat and raise\" of epic proportions.\n",
       "\n",
       "---\n",
       "\n",
       "### 3. Deep Dive Analysis\n",
       "\n",
       "#### **News Analysis**\n",
       "Headline sentiment is a battle between **Euphoria** (product breakthroughs) and **Fear** (regulatory scrutiny). The news cycle is currently dominated by the \"Groq deal\" and \"China exports,\" which act as significant positive catalysts. However, the narrative is punctuated by news of \"heavy insider dumping\" and potential DOJ/Antitrust inquiries. Historically, NVIDIA‚Äôs stock has \"shaken off\" regulatory news in favor of pure performance, but the $1.7B insider selling is a persistent drag on sentiment.\n",
       "\n",
       "#### **Smart Money**\n",
       "*   **Institutional Flows**: Large-cap managers (BlackRock, JPMorgan, UBS) are still accumulating or holding, viewing NVDA as a \"utility\" of the AI era.\n",
       "*   **Insider Sentiment**: **Extremely Bearish**. 511 insider sales vs. 0 buys in the last 6 months. This suggests that the people running the company believe the stock is near its peak valuation for the current cycle.\n",
       "\n",
       "#### **Financial Statement Analysis**\n",
       "*   **Historic Performance (Last 3 Years)**: \n",
       "    *   **2023**: Revenue of $26.97B (Stagnant post-crypto crash).\n",
       "    *   **2024**: Revenue of $60.92B (+125% YoY).\n",
       "    *   **2025**: Revenue of $130.50B (+114% YoY). \n",
       "*   **Efficiency**: Net margins have exploded from ~15% in early 2023 to a consistent **53.4%** in late 2025.\n",
       "*   **Projected Performance**: TTM revenue as of Oct 2025 sits at **$187.14B**. Analysts expect FY2026 to push toward $200B+ as Blackwell becomes the primary driver. The return on equity (ROE) is currently a \"best-in-class\" 99%.\n",
       "\n",
       "---\n",
       "\n",
       "### 4. Conclusion\n",
       "**Verdict: Opportunity, but avoid \"Chasing the Rip.\"**\n",
       "The current price action (~$188-$190) shows a slight disconnect; the news is overwhelmingly positive regarding the \"Groq Moat\" and China exports, yet the price has faced resistance. This is likely a result of **year-end profit-taking** and **insider selling pressure** rather than a fundamental decay. \n",
       "\n",
       "The \"Whisper\" expectations for the upcoming Q4 (Feb 2026 report) are set at $1.52 EPS‚Äîsignificantly higher than the official consensus. If the stock retreats to the $165-$175 range (near its 50-day moving average), it represents a high-probability entry point. The long-term trajectory toward $275+ remains intact, provided Blackwell production yields remain stable."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "\n",
    "# ==========================================\n",
    "# SECURE CONFIGURATION\n",
    "# ==========================================\n",
    "\n",
    "# 1. Define the path to your key file\n",
    "# If the file is in the same folder as this notebook, just use the filename.\n",
    "KEY_FILE_PATH = \"C:\\\\Users\\\\James\\\\OneDrive - McMaster University\\\\Gemini API Key\\\\gemini_key.txt\"\n",
    "\n",
    "def load_api_key(filepath):\n",
    "    \"\"\"\n",
    "    Reads the API key from a local file to avoid hardcoding it.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        with open(filepath, \"r\") as f:\n",
    "            # .strip() removes any accidental newlines or spaces\n",
    "            return f.read().strip()\n",
    "    except FileNotFoundError:\n",
    "        print(f\"‚ùå Error: Could not find the file '{filepath}'\")\n",
    "        print(\"Please create a text file with your API key in it.\")\n",
    "        return None\n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Error reading key file: {e}\")\n",
    "        return None\n",
    "\n",
    "# 2. Load the key and set the environment variable\n",
    "api_key = load_api_key(KEY_FILE_PATH)\n",
    "\n",
    "if api_key:\n",
    "    os.environ[\"GEMINI_API_KEY\"] = api_key\n",
    "    print(\"‚úÖ API Key loaded securely.\")\n",
    "else:\n",
    "    print(\"‚ö†Ô∏è CRITICAL: API Key not loaded. The script will fail.\")\n",
    "\n",
    "# ==========================================\n",
    "# SENTIMENT ANALYSIS FUNCTION\n",
    "# ==========================================\n",
    "def analyze_sentiment_gemini_3(tickers_gemini, company_name=None):\n",
    "    \"\"\"\n",
    "    Uses Gemini 3 Flash (Preview) with 'High' Thinking Level and Google Search \n",
    "    using the NEW google-genai SDK.\n",
    "    \"\"\"\n",
    "    if not os.environ.get(\"GEMINI_API_KEY\"):\n",
    "        print(\"‚ùå Stop: No API Key found.\")\n",
    "        return\n",
    "\n",
    "    print(f\"\\nüß† Gemini 3 is thinking (High Reasoning Mode)... analyzing ${tickers_gemini}...\")\n",
    "\n",
    "    # Initialize Client\n",
    "    client = genai.Client(api_key=os.environ[\"GEMINI_API_KEY\"])\n",
    "\n",
    "    config = types.GenerateContentConfig(\n",
    "        thinking_config=types.ThinkingConfig(\n",
    "            include_thoughts=False, \n",
    "            thinking_level=\"HIGH\"\n",
    "        ),\n",
    "        tools=[types.Tool(\n",
    "            google_search=types.GoogleSearch() \n",
    "        )],\n",
    "        response_modalities=[\"TEXT\"]\n",
    "    )\n",
    "\n",
    "    prompt = f\"\"\"\n",
    "    You are a Senior Equity Research Analyst using the Gemini 3 Reasoning Engine. \n",
    "    Perform a deep \"Market Sentiment Analysis\" on {tickers_gemini} ({company_name if company_name else 'the company'}).\n",
    "    \n",
    "    Step 1: SEARCH. Use Google Search to find the latest (last 30 days) news, analyst notes, and SEC filings.\n",
    "    Step 2: REASON. Analyze the search results to determine the true market psychology. Look for contradictions between price action and news.\n",
    "    \n",
    "    Investigate these 4 Pillars:\n",
    "    1. **News Virality**: Are headlines fear-mongering or euphoric? (Look for scandals, lawsuits, or product breakthroughs).\n",
    "    2. **Analyst Shifts**: Are price targets moving UP or DOWN in the last week?\n",
    "    3. **Institutional Flows**: Any reports of hedge funds or insiders buying/selling?\n",
    "    4. **The \"Whisper\" Number**: What are traders saying on forums vs. official guidance?\n",
    "\n",
    "    **OUTPUT FORMAT:**\n",
    "    Produce a professional Markdown report:\n",
    "    \n",
    "    ## üß† Gemini 3 Sentiment Report: {tickers_gemini}\n",
    "    **Reasoning Depth:** High\n",
    "    **Sentiment Score:** [1-10]\n",
    "    **Verdict:** [Buy / Hold / Sell / Speculative]\n",
    "    \n",
    "    ### 1. The Bull Thesis (Why it goes up)\n",
    "    * ...\n",
    "    \n",
    "    ### 2. The Bear Thesis (Why it goes down)\n",
    "    * ...\n",
    "    \n",
    "    ### 3. Deep Dive Analysis\n",
    "    * **News Analysis**: ...\n",
    "    * **Smart Money**: ...\n",
    "    * **Financial Statement Analysis**: (Historic performance over last 3 years + expected performance)\n",
    "    \n",
    "    ### 4. Conclusion\n",
    "    [Summary of whether the current price is a trap or an opportunity]\n",
    "    \"\"\"\n",
    "\n",
    "    try:\n",
    "        response = client.models.generate_content(\n",
    "            model='gemini-3-flash-preview', # Or 'gemini-3-flash-preview'\n",
    "            contents=prompt,\n",
    "            config=config\n",
    "        )\n",
    "        display(Markdown(response.text))\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Error: {e}\")\n",
    "\n",
    "# ==========================================\n",
    "# EXECUTION\n",
    "# ==========================================\n",
    "# Only run this if the key loaded successfully\n",
    "if os.environ.get(\"GEMINI_API_KEY\"):\n",
    "    analyze_sentiment_gemini_3(tickers_gemini, tickers_gemini)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
