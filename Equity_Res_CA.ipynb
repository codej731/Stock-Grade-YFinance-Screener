{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "67ec8184",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import requests\n",
    "from yahooquery import Ticker  # Step 2 (Speed)\n",
    "import yfinance as yf          # Step 3 (Reliability)\n",
    "import io\n",
    "import json\n",
    "import os\n",
    "import time\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "831a506f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "\n",
    "# ==========================================\n",
    "# CONFIGURATION\n",
    "# ==========================================\n",
    "# 1. FOLDER SETUP (The Fix for GitHub Portability)\n",
    "DATA_FOLDER = \"YfinanceDataDump\"  # Relative path (creates folder in project root)\n",
    "\n",
    "# Create the folder if it doesn't exist\n",
    "if not os.path.exists(DATA_FOLDER):\n",
    "    try:\n",
    "        os.makedirs(DATA_FOLDER)\n",
    "        print(f\"Created data folder: {DATA_FOLDER}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Warning: Could not create folder '{DATA_FOLDER}'. Saving to current directory. Error: {e}\")\n",
    "        DATA_FOLDER = \".\"\n",
    "\n",
    "# 2. FILE PATHS (Everything saves inside the folder now)\n",
    "CACHE_FILE = os.path.join(DATA_FOLDER, \"financial_cache.json\")\n",
    "FORTRESS_CSV = os.path.join(DATA_FOLDER, \"fortress_stocks.csv\")\n",
    "STRONG_CSV = os.path.join(DATA_FOLDER, \"strong_stocks.csv\")\n",
    "RISKY_CSV = os.path.join(DATA_FOLDER, \"risky_stocks.csv\")\n",
    "ANALYST_CSV = os.path.join(DATA_FOLDER, \"Analyst_Fortress_Picks.csv\")\n",
    "BUFFETT_CSV = os.path.join(DATA_FOLDER, \"Buffett_Value_Picks.csv\")\n",
    "\n",
    "# 3. UNIVERSE FILTERS\n",
    "MIN_PRICE = 2.00               \n",
    "MIN_VOLUME = 100_000          # 100K shares/day       \n",
    "MIN_CAP = 50_000_000        # $50M\n",
    "MIN_CURRENT_RATIO = 1.2\n",
    "MAX_PE_RATIO = 100.0         \n",
    "\n",
    "# 4. SAFETY THRESHOLDS \n",
    "MIN_INTEREST_COVERAGE = 1.5\n",
    "MIN_ROIC = 0.05              # 5%\n",
    "FORTRESS_MARGIN_THRESHOLD = 0.05  # 5%\n",
    "\n",
    "EXCLUDED_SECTORS = ['Financial Services', 'Real Estate']\n",
    "CACHE_EXPIRY_DAYS = 30 \n",
    "\n",
    "# ==========================================\n",
    "# HELPER FUNCTIONS\n",
    "# ==========================================\n",
    "def load_cache():\n",
    "    if os.path.exists(CACHE_FILE):\n",
    "        try:\n",
    "            with open(CACHE_FILE, 'r') as f:\n",
    "                return json.load(f)\n",
    "        except:\n",
    "            return {}\n",
    "    return {}\n",
    "\n",
    "def save_cache(cache_data):\n",
    "    try:\n",
    "        with open(CACHE_FILE, 'w') as f:\n",
    "            json.dump(cache_data, f)\n",
    "    except Exception as e:\n",
    "        print(f\"Warning: Could not save cache: {e}\")\n",
    "\n",
    "def calculate_altman_z_yfinance(bs, fin, market_cap):\n",
    "    \"\"\"\n",
    "    Calculates Z-Score using yfinance DataFrames.\n",
    "    Formula: 1.2A + 1.4B + 3.3C + 0.6D + 1.0E\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Helper to safely get value from Series\n",
    "        def get_val(df, keys):\n",
    "            for k in keys:\n",
    "                if k in df.index:\n",
    "                    return df.loc[k].iloc[0]\n",
    "            return 0\n",
    "\n",
    "        # Map yfinance row names\n",
    "        total_assets = get_val(bs, ['Total Assets'])\n",
    "        total_liab = get_val(bs, ['Total Liabilities Net Minority Interest', 'Total Liabilities'])\n",
    "        current_assets = get_val(bs, ['Current Assets', 'Total Current Assets'])\n",
    "        current_liab = get_val(bs, ['Current Liabilities', 'Total Current Liabilities'])\n",
    "        retained_earnings = get_val(bs, ['Retained Earnings'])\n",
    "        \n",
    "        ebit = get_val(fin, ['EBIT', 'Operating Income'])\n",
    "        total_revenue = get_val(fin, ['Total Revenue'])\n",
    "        \n",
    "        if total_assets == 0 or total_liab == 0: return 0\n",
    "\n",
    "        # A: Working Capital / Total Assets\n",
    "        A = (current_assets - current_liab) / total_assets\n",
    "        \n",
    "        # B: Retained Earnings / Total Assets\n",
    "        B = retained_earnings / total_assets\n",
    "        \n",
    "        # C: EBIT / Total Assets\n",
    "        C = ebit / total_assets\n",
    "        \n",
    "        # D: Market Value of Equity / Total Liabilities\n",
    "        D = market_cap / total_liab\n",
    "        \n",
    "        # E: Sales / Total Assets\n",
    "        E = total_revenue / total_assets\n",
    "        \n",
    "        return (1.2 * A) + (1.4 * B) + (3.3 * C) + (0.6 * D) + (1.0 * E)\n",
    "    except Exception as e:\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "efa4bf6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==========================================\n",
    "# STEP 1: FETCH CANADIAN UNIVERSE (ROBUST)\n",
    "# ==========================================\n",
    "def get_combined_universe():\n",
    "    print(\"--- STEP 1: Fetching Canadian Universe (TSX & TSX-V) ---\")\n",
    "    tickers = []\n",
    "    \n",
    "    # --- METHOD 1: TMX OFFICIAL MOC LIST ---\n",
    "    url_tmx = \"https://www.tsx.com/files/trading/moc-eligible-stocks.txt\"\n",
    "    headers = {\n",
    "        \"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36\"\n",
    "    }\n",
    "    \n",
    "    try:\n",
    "        print(\"   -> Attempting to fetch official TMX list...\")\n",
    "        response = requests.get(url_tmx, headers=headers, timeout=10)\n",
    "        response.raise_for_status()\n",
    "        \n",
    "        lines = response.content.decode('utf-8').split('\\n')\n",
    "        \n",
    "        for line in lines:\n",
    "            parts = line.strip().split()\n",
    "            if len(parts) < 3: continue\n",
    "            \n",
    "            # PARSING LOGIC: Detect if Exchange is at the Start or End\n",
    "            # Format A: \"TSX    RY    ROYAL BANK...\"\n",
    "            # Format B: \"RY     ROYAL BANK...     TSX\"\n",
    "            \n",
    "            symbol = None\n",
    "            exchange = None\n",
    "            \n",
    "            if parts[0] in ['TSX', 'TSXV']:\n",
    "                exchange = parts[0]\n",
    "                symbol = parts[1]\n",
    "            elif parts[-1] in ['TSX', 'TSXV']:\n",
    "                exchange = parts[-1]\n",
    "                symbol = parts[0]\n",
    "            \n",
    "            if symbol and exchange:\n",
    "                # Clean Symbol (Yahoo uses hyphens, TMX uses dots)\n",
    "                clean_symbol = symbol.replace('.', '-')\n",
    "                \n",
    "                if exchange == \"TSX\":\n",
    "                    tickers.append(f\"{clean_symbol}.TO\")\n",
    "                elif exchange == \"TSXV\":\n",
    "                    tickers.append(f\"{clean_symbol}.V\")\n",
    "                    \n",
    "        tickers = list(set(tickers))\n",
    "        print(f\"   -> Success: Found {len(tickers)} stocks via TMX.\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"   -> TMX Fetch Failed ({e}). Trying Backup...\")\n",
    "\n",
    "    # --- METHOD 2: WIKIPEDIA S&P/TSX COMPOSITE (If Method 1 returns 0 or fails) ---\n",
    "    if len(tickers) == 0:\n",
    "        try:\n",
    "            print(\"   -> Attempting to scrape S&P/TSX Composite from Wikipedia...\")\n",
    "            url_wiki = \"https://en.wikipedia.org/wiki/S%26P/TSX_Composite_Index\"\n",
    "            dfs = pd.read_html(url_wiki)\n",
    "            \n",
    "            # The constituent table is usually the first or second table\n",
    "            for df in dfs:\n",
    "                if 'Symbol' in df.columns:\n",
    "                    # Wikipedia symbols often look like \"RY\" or \"RY.TO\"\n",
    "                    wiki_tickers = df['Symbol'].astype(str).tolist()\n",
    "                    for t in wiki_tickers:\n",
    "                        t = t.replace('.', '-') # Fix BAM.A to BAM-A\n",
    "                        if not t.endswith('.TO'):\n",
    "                            t = t + \".TO\"\n",
    "                        tickers.append(t)\n",
    "                    break\n",
    "            \n",
    "            tickers = list(set(tickers))\n",
    "            print(f\"   -> Success: Found {len(tickers)} stocks via Wikipedia.\")\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"   -> Wikipedia Scraping Failed ({e}).\")\n",
    "\n",
    "    # --- METHOD 3: EMERGENCY FALLBACK LIST ---\n",
    "    if len(tickers) == 0:\n",
    "        print(\"   -> All web fetches failed. Using Emergency Hardcoded List.\")\n",
    "        tickers = [\n",
    "            'SHOP.TO', 'RY.TO', 'TD.TO', 'CNR.TO', 'CP.TO', 'CSU.TO', 'ATD.TO', 'DOL.TO',\n",
    "            'BMO.TO', 'BNS.TO', 'TRP.TO', 'ENB.TO', 'CNQ.TO', 'BCE.TO', 'CM.TO', 'MFC.TO',\n",
    "            'QSR.TO', 'GIB-A.TO', 'SU.TO', 'WCN.TO', 'TECK-B.TO', 'T.TO', 'POW.TO', 'CVE.TO',\n",
    "            'NA.TO', 'FTS.TO', 'EMA.TO', 'AEM.TO', 'WPM.TO', 'MRU.TO', 'OTEX.TO', 'SAP.TO',\n",
    "            'L.TO', 'WN.TO', 'RCI-B.TO', 'CTC-A.TO', 'MG.TO', 'FM.TO', 'K.TO', 'CAE.TO',\n",
    "            'TIH.TO', 'GIL.TO', 'DOO.TO', 'STN.TO', 'EFN.TO', 'KEY.TO', 'PPL.TO', 'IMO.TO'\n",
    "        ]\n",
    "        print(f\"   -> Loaded {len(tickers)} major stocks.\")\n",
    "\n",
    "    return tickers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "65c3da19",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==========================================\n",
    "# STEP 2: LIGHTWEIGHT SIEVE (YahooQuery)\n",
    "# ==========================================\n",
    "def get_initial_survivors(tickers):\n",
    "    print(f\"\\n--- STEP 2: Running 'Lightweight' Filter on {len(tickers)} stocks ---\")\n",
    "    chunk_size = 500 \n",
    "    survivors = []\n",
    "    chunks = [tickers[i:i + chunk_size] for i in range(0, len(tickers), chunk_size)]\n",
    "    \n",
    "    for i, chunk in enumerate(chunks):\n",
    "        if i % 2 == 0: print(f\" -> Processing Batch {i+1}/{len(chunks)}...\")\n",
    "        try:\n",
    "            yq = Ticker(chunk, asynchronous=True)\n",
    "            df_modules = yq.get_modules('summaryProfile summaryDetail financialData price defaultKeyStatistics')\n",
    "            \n",
    "            for symbol, data in df_modules.items():\n",
    "                if isinstance(data, str): continue \n",
    "                try:\n",
    "                    price = data.get('price', {}).get('regularMarketPrice', 0)\n",
    "                    if price is None: price = 0\n",
    "                    \n",
    "                    vol = data.get('summaryDetail', {}).get('averageVolume', 0)\n",
    "                    if vol is None or vol == 0:\n",
    "                         vol = data.get('price', {}).get('averageDailyVolume10Day', 0)\n",
    "                    \n",
    "                    cap = data.get('price', {}).get('marketCap', 0)\n",
    "                    if cap is None: cap = 0\n",
    "                    \n",
    "                    sector = data.get('summaryProfile', {}).get('sector', 'Unknown')\n",
    "                    fin_data = data.get('financialData', {})\n",
    "                    curr_ratio = fin_data.get('currentRatio', 0)\n",
    "                    op_margins = fin_data.get('operatingMargins', 0)\n",
    "                    if curr_ratio is None: curr_ratio = 0\n",
    "                    if op_margins is None: op_margins = 0\n",
    "\n",
    "                    # --- P/E RATIO CHECK ---\n",
    "                    pe = data.get('summaryDetail', {}).get('trailingPE')\n",
    "                    if pe is not None and pe > MAX_PE_RATIO: continue\n",
    "\n",
    "                    # FILTERS\n",
    "                    if price < MIN_PRICE: continue\n",
    "                    if cap < MIN_CAP: continue\n",
    "                    if vol < MIN_VOLUME: continue \n",
    "                    if any(x in sector for x in EXCLUDED_SECTORS): continue\n",
    "                    if curr_ratio < MIN_CURRENT_RATIO: continue\n",
    "                    if op_margins <= 0: continue \n",
    "                    \n",
    "                    survivors.append({\n",
    "                        'Ticker': symbol,\n",
    "                        'Sector': sector,\n",
    "                        'Price': price,\n",
    "                        'Op Margin %': round(op_margins * 100, 2),\n",
    "                        'P/E': round(pe, 2) if pe else 0,\n",
    "                        'Curr Ratio': curr_ratio,\n",
    "                        'Mkt Cap (B)': round(cap / 1_000_000_000, 2)\n",
    "                    })\n",
    "                except: continue\n",
    "        except: continue\n",
    "    return pd.DataFrame(survivors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b09f64f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==========================================\n",
    "# STEP 3: DEEP DIVE (yfinance + Cache)\n",
    "# ==========================================\n",
    "def get_advanced_metrics(survivor_df):\n",
    "    tickers = survivor_df['Ticker'].tolist()\n",
    "    print(f\"\\n--- STEP 3: Fetching Deep Financials for {len(tickers)} Survivors ---\")\n",
    "    \n",
    "    cache = load_cache()\n",
    "    current_time = time.time()\n",
    "    expiry_seconds = CACHE_EXPIRY_DAYS * 86400\n",
    "    \n",
    "    final_data = []\n",
    "    \n",
    "    for i, ticker in enumerate(tickers):\n",
    "        if i % 20 == 0: print(f\" -> Analyzing {i+1}/{len(tickers)}: {ticker}...\")\n",
    "        \n",
    "        # Helper: Logic to assign Tier based on Average Margin & Safety\n",
    "        def determine_tier_history(metrics, is_fortress_margin, is_pos_margin):\n",
    "            # 1. Safety Checks (Must pass these regardless of margins)\n",
    "            if metrics['int_cov'] < MIN_INTEREST_COVERAGE: return \"Risky\"\n",
    "            if metrics['roic'] < MIN_ROIC: return \"Risky\"\n",
    "            \n",
    "            # 2. Historical Margin Checks (Using the 4-Year Average)\n",
    "            if is_fortress_margin: \n",
    "                return \"Fortress\"  # Avg Margin > 5%\n",
    "            elif is_pos_margin:\n",
    "                return \"Strong\"    # Avg Margin > 0%\n",
    "            \n",
    "            return \"Risky\"         # Avg Margin was negative\n",
    "\n",
    "        # 1. CHECK CACHE\n",
    "        cached_data = cache.get(ticker)\n",
    "        # Note: We skip cache logic here to force a refresh on the first run with new logic\n",
    "        # If you want to use cache, ensure 'avg_margin' logic is handled or clear old cache\n",
    "        if cached_data and (current_time - cached_data['timestamp'] < expiry_seconds):\n",
    "             # For now, we allow cache if it has valid data, but re-calculating margins \n",
    "             # usually requires the full dataframe. \n",
    "             # To force the new Average Margin check, we often proceed to fetch new data.\n",
    "             pass \n",
    "\n",
    "        # 2. FETCH NEW DATA\n",
    "        try:\n",
    "            stock = yf.Ticker(ticker)\n",
    "            fin = stock.financials\n",
    "            bs = stock.balance_sheet\n",
    "            \n",
    "            if fin.empty or bs.empty:\n",
    "                cache[ticker] = {'timestamp': current_time, 'z_score': 0, 'roic': -999, 'int_cov': -999}\n",
    "                continue\n",
    "            \n",
    "            # --- A. NEW LOGIC: 4-Year Average Margin Check ---\n",
    "            try:\n",
    "                # Get Operating Income (try 'Operating Income' first, then 'EBIT')\n",
    "                if 'Operating Income' in fin.index:\n",
    "                    op_income_history = fin.loc['Operating Income']\n",
    "                elif 'EBIT' in fin.index:\n",
    "                    op_income_history = fin.loc['EBIT']\n",
    "                else:\n",
    "                    op_income_history = pd.Series([0]) \n",
    "\n",
    "                # Get Revenue\n",
    "                revenue_history = fin.loc['Total Revenue']\n",
    "                \n",
    "                # Calculate Margins for every available year\n",
    "                # This automatically handles 1, 2, 3, or 4 years of data\n",
    "                yearly_margins = (op_income_history / revenue_history).dropna()\n",
    "                \n",
    "                if len(yearly_margins) > 0:\n",
    "                    avg_margin = yearly_margins.mean()\n",
    "                    \n",
    "                    # The Uniform Rule: Is the AVERAGE above the threshold?\n",
    "                    is_fortress_margin = avg_margin > FORTRESS_MARGIN_THRESHOLD\n",
    "                    is_positive_margin = avg_margin > 0\n",
    "                else:\n",
    "                    is_fortress_margin = False\n",
    "                    is_positive_margin = False\n",
    "\n",
    "            except Exception as e:\n",
    "                # Fail safe\n",
    "                is_fortress_margin = False\n",
    "                is_positive_margin = False\n",
    "            # ---------------------------------------------------\n",
    "\n",
    "            # --- B. Standard Calculations (Safety Checks) ---\n",
    "            def get_item(df, keys):\n",
    "                for k in keys:\n",
    "                    if k in df.index: return df.loc[k].iloc[0]\n",
    "                return 0\n",
    "\n",
    "            ebit = get_item(fin, ['EBIT', 'Operating Income', 'Pretax Income'])\n",
    "            int_exp = get_item(fin, ['Interest Expense', 'Interest Expense Non Operating'])\n",
    "            total_assets = get_item(bs, ['Total Assets'])\n",
    "            curr_liab = get_item(bs, ['Current Liabilities', 'Total Current Liabilities'])\n",
    "            \n",
    "            # Interest Coverage\n",
    "            int_exp = abs(int_exp)\n",
    "            if int_exp == 0: int_cov = 100\n",
    "            else: int_cov = ebit / int_exp\n",
    "            \n",
    "            # ROIC\n",
    "            invested_cap = total_assets - curr_liab\n",
    "            if invested_cap <= 0: roic = 0\n",
    "            else: roic = ebit / invested_cap\n",
    "            \n",
    "            # Z-Score\n",
    "            base_row = survivor_df[survivor_df['Ticker'] == ticker].iloc[0]\n",
    "            mkt_cap_raw = base_row['Mkt Cap (B)'] * 1_000_000_000\n",
    "            z = calculate_altman_z_yfinance(bs, fin, mkt_cap_raw)\n",
    "            \n",
    "            # Cache the metrics\n",
    "            metrics = {\n",
    "                'timestamp': current_time,\n",
    "                'z_score': round(z, 2),\n",
    "                'roic': roic,\n",
    "                'int_cov': round(int_cov, 2)\n",
    "            }\n",
    "            cache[ticker] = metrics\n",
    "            \n",
    "            # --- C. Determine Final Tier ---\n",
    "            tier = determine_tier_history(metrics, is_fortress_margin, is_positive_margin)\n",
    "\n",
    "            final_data.append({\n",
    "                'Ticker': ticker,\n",
    "                'Tier': tier,\n",
    "                'Price': base_row['Price'],\n",
    "                'P/E': base_row['P/E'],\n",
    "                'Sector': base_row['Sector'],\n",
    "                'Z-Score': round(z, 2),\n",
    "                'ROIC %': round(roic * 100, 2),\n",
    "                'Op Margin %': base_row['Op Margin %'], # We still show the current TTM margin for reference\n",
    "                'Avg Margin (4Y)': round(avg_margin * 100, 2) if 'avg_margin' in locals() else 0, # NEW COLUMN\n",
    "                'Curr Ratio': base_row['Curr Ratio'],\n",
    "                'Int Cov': round(int_cov, 2),\n",
    "                'Mkt Cap (B)': base_row['Mkt Cap (B)']\n",
    "            })\n",
    "            \n",
    "        except Exception as e:\n",
    "            continue\n",
    "\n",
    "    save_cache(cache)\n",
    "    return pd.DataFrame(final_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a5361c2f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- STEP 1: Fetching Canadian Universe (TSX & TSX-V) ---\n",
      "   -> Attempting to fetch official TMX list...\n",
      "   -> Success: Found 1089 stocks via TMX.\n",
      "\n",
      "--- STEP 2: Running 'Lightweight' Filter on 1089 stocks ---\n",
      " -> Processing Batch 1/3...\n",
      " -> Processing Batch 3/3...\n",
      "\n",
      "‚úÖ Step 2 Complete. 111 stocks passed basic filters.\n",
      "\n",
      "--- STEP 3: Fetching Deep Financials for 111 Survivors ---\n",
      " -> Analyzing 1/111: TECK-B.TO...\n",
      " -> Analyzing 21/111: AGI.TO...\n",
      " -> Analyzing 41/111: PNG.V...\n",
      " -> Analyzing 61/111: TIH.TO...\n",
      " -> Analyzing 81/111: ARIS.TO...\n",
      " -> Analyzing 101/111: AQN.TO...\n",
      "\n",
      "============================================================\n",
      "RESULTS GENERATED\n",
      "============================================================\n",
      "1. FORTRESS (74): Saved to 'YfinanceDataDump\\fortress_stocks.csv'\n",
      "2. STRONG   (5): Saved to 'YfinanceDataDump\\strong_stocks.csv'\n",
      "3. RISKY    (30): Saved to 'YfinanceDataDump\\risky_stocks.csv'\n",
      "\n",
      "--- FORTRESS PREVIEW ---\n",
      "      Ticker      Tier   Price    P/E             Sector  Z-Score  ROIC %  Op Margin %  Avg Margin (4Y)  Curr Ratio  Int Cov  Mkt Cap (B)\n",
      "47    WPM.TO  Fortress  162.77  54.08    Basic Materials   269.85    8.72        66.54            50.89       8.089  2269.82        73.90\n",
      "34    FNV.TO  Fortress  285.09  43.66    Basic Materials    99.78   12.20        70.04            62.22       4.641  7640.00        54.96\n",
      "25    LUG.TO  Fortress  115.69  29.97    Basic Materials    57.08   66.57        62.00            45.55       3.227     3.65        27.93\n",
      "91    DPM.TO  Fortress   42.65  18.23    Basic Materials    44.81   20.76        42.96            36.22       2.774   176.88         9.46\n",
      "48    ASM.TO  Fortress    8.82  46.42    Basic Materials    36.09   11.12        32.56             6.68       2.754    38.26         1.38\n",
      "29    DSG.TO  Fortress  120.62  49.43         Technology    24.90   13.47        30.54            27.88       1.834   191.87        10.37\n",
      "1     KNT.TO  Fortress   22.62  16.04    Basic Materials    23.82   30.81        68.87            35.98       3.285   456.18         5.51\n",
      "55   GRGD.TO  Fortress   83.69  44.28  Consumer Cyclical    14.45   45.97        33.04            16.06       1.713     6.57         9.07\n",
      "5     WDO.TO  Fortress   22.98  12.03    Basic Materials    14.31   29.95        55.55            21.26       4.793    83.52         3.47\n",
      "15    OGC.TO  Fortress   38.88  16.62    Basic Materials    10.77   12.37        36.34            20.19       1.274    12.14         8.88\n",
      "108   DNG.TO  Fortress    5.79  11.35    Basic Materials     9.89   25.90         7.90             9.47       4.633    68.99         0.24\n",
      "75    TXG.TO  Fortress   66.83  14.40    Basic Materials     9.07   19.55        43.61            32.65       1.377   100.00         6.43\n",
      "13    ALS.TO  Fortress   40.80   5.33    Basic Materials     8.71   15.66        41.82            50.25       8.460    11.53         1.89\n",
      "88    AEM.TO  Fortress  235.30  25.19    Basic Materials     8.49   10.21        53.10            29.01       2.120    33.63       118.20\n",
      "19    AGI.TO  Fortress   53.56  30.61    Basic Materials     8.16   10.53        80.68            28.96       1.717    35.88        22.49\n"
     ]
    }
   ],
   "source": [
    "# ==========================================\n",
    "# MAIN EXECUTION\n",
    "# ==========================================\n",
    "if __name__ == \"__main__\":\n",
    "    tickers = get_combined_universe()\n",
    "    \n",
    "    if len(tickers) > 0:\n",
    "        survivors_df = get_initial_survivors(tickers)\n",
    "        \n",
    "        if not survivors_df.empty:\n",
    "            print(f\"\\n‚úÖ Step 2 Complete. {len(survivors_df)} stocks passed basic filters.\")\n",
    "            \n",
    "            final_results = get_advanced_metrics(survivors_df)\n",
    "            \n",
    "            if not final_results.empty:\n",
    "                final_results = final_results.sort_values(by=['Tier', 'Z-Score'], ascending=[True, False])\n",
    "                \n",
    "                # 1. Standard Split\n",
    "                fortress_df = final_results[final_results['Tier'] == 'Fortress'].copy()\n",
    "                strong_df = final_results[final_results['Tier'] == 'Strong'].copy()\n",
    "                risky_df = final_results[final_results['Tier'] == 'Risky'].copy()\n",
    "                \n",
    "                # 3. Save Files (Updated to use Relative Paths from Cell 2)\n",
    "                try:\n",
    "                    fortress_df.to_csv(FORTRESS_CSV, index=False)\n",
    "                    strong_df.to_csv(STRONG_CSV, index=False)\n",
    "                    risky_df.to_csv(RISKY_CSV, index=False)\n",
    "                    \n",
    "                    print(\"\\n\" + \"=\"*60)\n",
    "                    print(\"RESULTS GENERATED\")\n",
    "                    print(\"=\"*60)\n",
    "                    print(f\"1. FORTRESS ({len(fortress_df)}): Saved to '{FORTRESS_CSV}'\")\n",
    "                    print(f\"2. STRONG   ({len(strong_df)}): Saved to '{STRONG_CSV}'\")\n",
    "                    print(f\"3. RISKY    ({len(risky_df)}): Saved to '{RISKY_CSV}'\")\n",
    "                except Exception as e:\n",
    "                    print(f\"\\n‚ö†Ô∏è Error Saving Files: {e}\")\n",
    "                    print(\"Check if the file is open in Excel or if the folder exists.\")\n",
    "                \n",
    "                pd.set_option('display.max_rows', 500)\n",
    "                pd.set_option('display.max_columns', 20)\n",
    "                pd.set_option('display.width', 1000)\n",
    "                \n",
    "                print(\"\\n--- FORTRESS PREVIEW ---\")\n",
    "                print(fortress_df.head(15))\n",
    "            else:\n",
    "                print(\"No stocks passed the deep financial analysis.\")\n",
    "        else:\n",
    "            print(\"No stocks passed the initial lightweight filter.\")\n",
    "    else:\n",
    "        print(\"Could not fetch ticker universe.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "36ee3ec0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- STEP 4: Fetching Analyst Ratings for 74 Stocks (From Memory) ---\n",
      "    (Fetching serially to avoid throttling...)\n",
      " -> Analyst Scan 1/74: WPM.TO...\n",
      " -> Analyst Scan 11/74: DNG.TO...\n",
      " -> Analyst Scan 21/74: K.TO...\n",
      " -> Analyst Scan 31/74: RUS.TO...\n",
      " -> Analyst Scan 41/74: IMO.TO...\n",
      " -> Analyst Scan 51/74: POU.TO...\n",
      " -> Analyst Scan 61/74: WN.TO...\n",
      " -> Analyst Scan 71/74: CTC-A.TO...\n",
      "\n",
      "‚úÖ Analyst Scan Complete!\n",
      "Found 35 stocks with Buy Ratings (Score < 2.0)\n",
      "Saved to 'Analyst_Fortress_Picks.csv'\n",
      "      Ticker   Price  Analyst_Rating  Upside_%  Target_Price      Tier\n",
      "20    VNP.TO   17.87         1.50000     41.81     25.341032  Fortress\n",
      "17    MDI.TO   12.97         1.20000     29.53     16.800000  Fortress\n",
      "26    CVE.TO   23.35         1.52941     27.09     29.676470  Fortress\n",
      "29    PBH.TO  102.06         1.72727     24.61    127.181820  Fortress\n",
      "4     TXG.TO   66.83         1.50000     24.13     82.958330  Fortress\n",
      "11    PSI.TO   12.00         2.00000     20.00     14.400000  Fortress\n",
      "7     AGI.TO   53.56         1.38462     19.80     64.167230  Fortress\n",
      "33    BDI.TO   14.72         1.50000     19.74     17.625000  Fortress\n",
      "28    DOO.TO   97.87         1.83333     19.41    116.867170  Fortress\n",
      "31    KEY.TO   44.06         1.84615     18.72     52.307690  Fortress\n",
      "25    PHX.TO    7.75         1.66667     18.28      9.166670  Fortress\n",
      "2    GRGD.TO   83.69         1.58333     17.60     98.416670  Fortress\n",
      "3     OGC.TO   38.88         1.54545     16.74     45.386960  Fortress\n",
      "0     WPM.TO  162.77         1.43750     16.40    189.470290  Fortress\n",
      "27    CIA.TO    5.56         1.68750     16.31      6.466670  Fortress\n",
      "12    GIL.TO   85.90         1.53846     14.83     98.641730  Fortress\n",
      "30    EFX.TO   21.47         1.55556     14.78     24.642860  Fortress\n",
      "6     AEM.TO  235.30         1.75000     14.12    268.519930  Fortress\n",
      "15    RUS.TO   43.92         2.00000     13.52     49.857140  Fortress\n",
      "21  CCL-B.TO   86.95         1.60000     11.90     97.300000  Fortress\n"
     ]
    }
   ],
   "source": [
    "# 1. Define the function (if you haven't already in a previous cell)\n",
    "def get_analyst_fortress_from_var(df_input):\n",
    "    working_df = df_input.copy()\n",
    "    tickers = working_df['Ticker'].tolist()\n",
    "    \n",
    "    print(f\"\\n--- STEP 4: Fetching Analyst Ratings for {len(tickers)} Stocks (From Memory) ---\")\n",
    "    print(\"    (Fetching serially to avoid throttling...)\")\n",
    "    \n",
    "    analyst_data = []\n",
    "    \n",
    "    for i, ticker in enumerate(tickers):\n",
    "        if i % 10 == 0: print(f\" -> Analyst Scan {i+1}/{len(tickers)}: {ticker}...\")\n",
    "        \n",
    "        try:\n",
    "            stock = yf.Ticker(ticker)\n",
    "            info = stock.info\n",
    "            \n",
    "            rec_mean = info.get('recommendationMean')\n",
    "            target_price = info.get('targetMeanPrice')\n",
    "            current_price = info.get('currentPrice')\n",
    "            \n",
    "            # Filter: Must be better than 2.0 (Lower is better)\n",
    "            if rec_mean is None or rec_mean > 2.0: continue\n",
    "            \n",
    "            upside = 0\n",
    "            if target_price and current_price:\n",
    "                upside = round(((target_price - current_price) / current_price) * 100, 2)\n",
    "            \n",
    "            # Merge with existing data\n",
    "            base_row = working_df[working_df['Ticker'] == ticker].iloc[0].to_dict()\n",
    "            base_row['Analyst_Rating'] = rec_mean\n",
    "            base_row['Target_Price'] = target_price\n",
    "            base_row['Upside_%'] = upside\n",
    "            \n",
    "            analyst_data.append(base_row)\n",
    "            time.sleep(0.2) # Polite delay\n",
    "            \n",
    "        except Exception:\n",
    "            continue\n",
    "            \n",
    "    return pd.DataFrame(analyst_data)\n",
    "\n",
    "# ==========================================\n",
    "# 2. EXECUTE IT (Run this part!)\n",
    "# ==========================================\n",
    "\n",
    "# Check if fortress_df exists from the previous step\n",
    "if 'fortress_df' in locals() and not fortress_df.empty:\n",
    "    \n",
    "    # Run the function\n",
    "    Analyst_Fortress_DF = get_analyst_fortress_from_var(fortress_df)\n",
    "    \n",
    "    if not Analyst_Fortress_DF.empty:\n",
    "        # Sort by best Analyst Rating (Lower is better) or Upside\n",
    "        Analyst_Fortress_DF = Analyst_Fortress_DF.sort_values(by='Upside_%', ascending=False)\n",
    "        \n",
    "        # Display Results\n",
    "        print(\"\\n‚úÖ Analyst Scan Complete!\")\n",
    "        print(f\"Found {len(Analyst_Fortress_DF)} stocks with Buy Ratings (Score < 2.0)\")\n",
    "        \n",
    "        # Save to CSV\n",
    "        Analyst_Fortress_DF.to_csv(ANALYST_CSV, index=False)\n",
    "        print(\"Saved to 'Analyst_Fortress_Picks.csv'\")\n",
    "        \n",
    "        # Show top picks\n",
    "        cols = ['Ticker', 'Price', 'Analyst_Rating', 'Upside_%', 'Target_Price', 'Tier']\n",
    "        print(Analyst_Fortress_DF[cols].head(20))\n",
    "    else:\n",
    "        print(\"No stocks passed the Analyst filter.\")\n",
    "else:\n",
    "    print(\"‚ùå 'fortress_df' not found or empty. Please run the Main Filter (Step 1-3) first.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ca466fcd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- STEP 5: Warren Buffett 'Below NAV' Scan ---\n",
      "    Scanning 109 candidates for Deep Value...\n",
      "    Criteria: P/B < 1.0 (Below Book) | ROE > 0% (Profitable) | Debt/Eq < 100%\n",
      "\n",
      "============================================================\n",
      "BUFFETT SCAN COMPLETE\n",
      "============================================================\n",
      "Found 2 Deep Value Stocks (Trading < Book Value)\n",
      "Saved to: 'Buffett_Value_Picks.csv'\n",
      "\n",
      "--- DEEP VALUE PICKS ---\n",
      "     Ticker  Price  P/B Ratio  ROE %  Debt/Eq %             Sector      Tier\n",
      "1   MATR.TO   7.93       0.63   3.66      80.14             Energy     Risky\n",
      "0  TCL-A.TO  22.70       0.99   8.94      42.46  Consumer Cyclical  Fortress\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from yahooquery import Ticker\n",
    "\n",
    "# ==========================================\n",
    "# BUFFETT \"BELOW NAV\" SCAN\n",
    "# ==========================================\n",
    "def get_buffett_value_picks(df_input):\n",
    "    print(f\"\\n--- STEP 5: Warren Buffett 'Below NAV' Scan ---\")\n",
    "    print(f\"    Scanning {len(df_input)} candidates for Deep Value...\")\n",
    "    print(\"    Criteria: P/B < 1.0 (Below Book) | ROE > 0% (Profitable) | Debt/Eq < 100%\")\n",
    "\n",
    "    tickers = df_input['Ticker'].tolist()\n",
    "    buffett_candidates = []\n",
    "\n",
    "    # Use YahooQuery for speed (Key Stats are summary data, no throttling risk here)\n",
    "    chunk_size = 250\n",
    "    chunks = [tickers[i:i + chunk_size] for i in range(0, len(tickers), chunk_size)]\n",
    "\n",
    "    for chunk in chunks:\n",
    "        try:\n",
    "            yq = Ticker(chunk, asynchronous=True)\n",
    "            # We need defaultKeyStatistics (P/B) and financialData (ROE, Debt)\n",
    "            data = yq.get_modules(\"defaultKeyStatistics financialData\")\n",
    "\n",
    "            for symbol in chunk:\n",
    "                if isinstance(data, dict) and symbol in data:\n",
    "                    try:\n",
    "                        stats = data[symbol].get('defaultKeyStatistics', {})\n",
    "                        fin = data[symbol].get('financialData', {})\n",
    "\n",
    "                        # 1. Price to Book < 1.0 (The Core Rule)\n",
    "                        pb = stats.get('priceToBook')\n",
    "                        # Skip if None, > 1.0, or negative (insolvent)\n",
    "                        if pb is None or pb >= 1.0 or pb <= 0: continue\n",
    "\n",
    "                        # 2. Positive ROE (No Zombies)\n",
    "                        roe = fin.get('returnOnEquity', 0)\n",
    "                        if roe is None or roe <= 0: continue\n",
    "\n",
    "                        # 3. Reasonable Debt (Safety)\n",
    "                        # Buffett hates high leverage on weak companies\n",
    "                        de = fin.get('debtToEquity', 0)\n",
    "                        if de is None or de > 100: continue \n",
    "\n",
    "                        # Get base data from input_df\n",
    "                        base_row = df_input[df_input['Ticker'] == symbol].iloc[0].to_dict()\n",
    "\n",
    "                        # Add new Value Metrics\n",
    "                        base_row['P/B Ratio'] = round(pb, 2)\n",
    "                        base_row['ROE %'] = round(roe * 100, 2)\n",
    "                        base_row['Debt/Eq %'] = round(de, 2)\n",
    "\n",
    "                        buffett_candidates.append(base_row)\n",
    "\n",
    "                    except: continue\n",
    "        except: continue\n",
    "\n",
    "    return pd.DataFrame(buffett_candidates)\n",
    "\n",
    "# ==========================================\n",
    "# EXECUTION BLOCK\n",
    "# ==========================================\n",
    "# Ensure we have the 'final_results' from the Main Filter\n",
    "if 'final_results' in locals() and not final_results.empty:\n",
    "    \n",
    "    Buffett_Value_DF = get_buffett_value_picks(final_results)\n",
    "    \n",
    "    if not Buffett_Value_DF.empty:\n",
    "        # Sort by P/B Ratio (Cheapest first)\n",
    "        Buffett_Value_DF = Buffett_Value_DF.sort_values(by='P/B Ratio', ascending=True)\n",
    "        \n",
    "        # Save results\n",
    "        Buffett_Value_DF.to_csv(BUFFETT_CSV, index=False)\n",
    "        \n",
    "        print(\"\\n\" + \"=\"*60)\n",
    "        print(\"BUFFETT SCAN COMPLETE\")\n",
    "        print(\"=\"*60)\n",
    "        print(f\"Found {len(Buffett_Value_DF)} Deep Value Stocks (Trading < Book Value)\")\n",
    "        print(\"Saved to: 'Buffett_Value_Picks.csv'\")\n",
    "        \n",
    "        # Display\n",
    "        pd.set_option('display.max_rows', 500)\n",
    "        cols = ['Ticker', 'Price', 'P/B Ratio', 'ROE %', 'Debt/Eq %', 'Sector', 'Tier']\n",
    "        print(\"\\n--- DEEP VALUE PICKS ---\")\n",
    "        print(Buffett_Value_DF[cols].head(20))\n",
    "        \n",
    "    else:\n",
    "        print(\"\\n‚ùå No stocks passed the Buffett Value filter (All stocks are trading > Book Value).\")\n",
    "else:\n",
    "    print(\"‚ùå 'final_results' variable not found. Please run the Main Filter first.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a22c790c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üïµÔ∏è Scanning 74 stocks for Insider Buying...\n",
      "‚úÖ Created 'Fortress_insiders' with 46 rows.\n"
     ]
    },
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "Ticker",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "Insider_Buys_Count",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "Net_Shares_Bought",
         "rawType": "float64",
         "type": "float"
        }
       ],
       "ref": "17ce1c3a-62fe-4b9b-9333-de20aa46c460",
       "rows": [
        [
         "0",
         "DPM.TO",
         "86",
         "9142771.0"
        ],
        [
         "1",
         "KNT.TO",
         "1",
         "8333.0"
        ],
        [
         "2",
         "GRGD.TO",
         "32",
         "648000.0"
        ],
        [
         "3",
         "WDO.TO",
         "7",
         "677900.0"
        ],
        [
         "4",
         "DNG.TO",
         "136",
         "159600.0"
        ],
        [
         "5",
         "TXG.TO",
         "18",
         "554667.0"
        ],
        [
         "6",
         "ALS.TO",
         "9",
         "54100.0"
        ],
        [
         "7",
         "ATZ.TO",
         "62",
         "471200.0"
        ],
        [
         "8",
         "PAAS.TO",
         "15",
         "1368070.0"
        ],
        [
         "9",
         "APM.TO",
         "40",
         "2101921.0"
        ],
        [
         "10",
         "HWX.TO",
         "18",
         "1095589.0"
        ],
        [
         "11",
         "TIH.TO",
         "6",
         "132600.0"
        ],
        [
         "12",
         "PSI.TO",
         "84",
         "1101000.0"
        ],
        [
         "13",
         "GIL.TO",
         "110",
         "1575676.0"
        ],
        [
         "14",
         "RCH.TO",
         "117",
         "879375.0"
        ],
        [
         "15",
         "TCW.TO",
         "128",
         "10370216.0"
        ],
        [
         "16",
         "BDGI.TO",
         "73",
         "503800.0"
        ],
        [
         "17",
         "CG.TO",
         "92",
         "5442652.0"
        ],
        [
         "18",
         "RUS.TO",
         "141",
         "2576200.0"
        ],
        [
         "19",
         "FVI.TO",
         "4",
         "916900.0"
        ],
        [
         "20",
         "CEU.TO",
         "22",
         "31620438.0"
        ],
        [
         "21",
         "NWC.TO",
         "34",
         "197899.0"
        ],
        [
         "22",
         "ENGH.TO",
         "66",
         "1039126.0"
        ],
        [
         "23",
         "IMO.TO",
         "150",
         "19889952.0"
        ],
        [
         "24",
         "MRU.TO",
         "69",
         "4423300.0"
        ],
        [
         "25",
         "STN.TO",
         "20",
         "5431.0"
        ],
        [
         "26",
         "CCL-B.TO",
         "4",
         "627580.0"
        ],
        [
         "27",
         "LUN.TO",
         "53",
         "13358800.0"
        ],
        [
         "28",
         "FTT.TO",
         "1",
         "348.0"
        ],
        [
         "29",
         "L.TO",
         "130",
         "12804874.0"
        ],
        [
         "30",
         "POU.TO",
         "2",
         "5439300.0"
        ],
        [
         "31",
         "CMG.TO",
         "7",
         "317400.0"
        ],
        [
         "32",
         "ELD.TO",
         "93",
         "5086503.0"
        ],
        [
         "33",
         "FAR.TO",
         "139",
         "633500.0"
        ],
        [
         "34",
         "PET.TO",
         "11",
         "1100029.0"
        ],
        [
         "35",
         "CVE.TO",
         "73",
         "53965480.0"
        ],
        [
         "36",
         "TCL-A.TO",
         "8",
         "310432.0"
        ],
        [
         "37",
         "SU.TO",
         "63",
         "12017751.0"
        ],
        [
         "38",
         "WN.TO",
         "137",
         "4586698.0"
        ],
        [
         "39",
         "RSI.TO",
         "10",
         "6782.0"
        ],
        [
         "40",
         "PBH.TO",
         "7",
         "32771.0"
        ],
        [
         "41",
         "EFX.TO",
         "12",
         "4189200.0"
        ],
        [
         "42",
         "MTL.TO",
         "123",
         "756740.0"
        ],
        [
         "43",
         "CTC-A.TO",
         "9",
         "1057.0"
        ],
        [
         "44",
         "EIF.TO",
         "6",
         "3538.0"
        ],
        [
         "45",
         "ACO-X.TO",
         "34",
         "26560.0"
        ]
       ],
       "shape": {
        "columns": 3,
        "rows": 46
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Ticker</th>\n",
       "      <th>Insider_Buys_Count</th>\n",
       "      <th>Net_Shares_Bought</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>DPM.TO</td>\n",
       "      <td>86</td>\n",
       "      <td>9142771.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>KNT.TO</td>\n",
       "      <td>1</td>\n",
       "      <td>8333.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>GRGD.TO</td>\n",
       "      <td>32</td>\n",
       "      <td>648000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>WDO.TO</td>\n",
       "      <td>7</td>\n",
       "      <td>677900.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>DNG.TO</td>\n",
       "      <td>136</td>\n",
       "      <td>159600.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>TXG.TO</td>\n",
       "      <td>18</td>\n",
       "      <td>554667.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>ALS.TO</td>\n",
       "      <td>9</td>\n",
       "      <td>54100.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>ATZ.TO</td>\n",
       "      <td>62</td>\n",
       "      <td>471200.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>PAAS.TO</td>\n",
       "      <td>15</td>\n",
       "      <td>1368070.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>APM.TO</td>\n",
       "      <td>40</td>\n",
       "      <td>2101921.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>HWX.TO</td>\n",
       "      <td>18</td>\n",
       "      <td>1095589.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>TIH.TO</td>\n",
       "      <td>6</td>\n",
       "      <td>132600.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>PSI.TO</td>\n",
       "      <td>84</td>\n",
       "      <td>1101000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>GIL.TO</td>\n",
       "      <td>110</td>\n",
       "      <td>1575676.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>RCH.TO</td>\n",
       "      <td>117</td>\n",
       "      <td>879375.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>TCW.TO</td>\n",
       "      <td>128</td>\n",
       "      <td>10370216.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>BDGI.TO</td>\n",
       "      <td>73</td>\n",
       "      <td>503800.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>CG.TO</td>\n",
       "      <td>92</td>\n",
       "      <td>5442652.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>RUS.TO</td>\n",
       "      <td>141</td>\n",
       "      <td>2576200.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>FVI.TO</td>\n",
       "      <td>4</td>\n",
       "      <td>916900.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>CEU.TO</td>\n",
       "      <td>22</td>\n",
       "      <td>31620438.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>NWC.TO</td>\n",
       "      <td>34</td>\n",
       "      <td>197899.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>ENGH.TO</td>\n",
       "      <td>66</td>\n",
       "      <td>1039126.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>IMO.TO</td>\n",
       "      <td>150</td>\n",
       "      <td>19889952.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>MRU.TO</td>\n",
       "      <td>69</td>\n",
       "      <td>4423300.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>STN.TO</td>\n",
       "      <td>20</td>\n",
       "      <td>5431.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>CCL-B.TO</td>\n",
       "      <td>4</td>\n",
       "      <td>627580.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>LUN.TO</td>\n",
       "      <td>53</td>\n",
       "      <td>13358800.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>FTT.TO</td>\n",
       "      <td>1</td>\n",
       "      <td>348.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>L.TO</td>\n",
       "      <td>130</td>\n",
       "      <td>12804874.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>POU.TO</td>\n",
       "      <td>2</td>\n",
       "      <td>5439300.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>CMG.TO</td>\n",
       "      <td>7</td>\n",
       "      <td>317400.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>ELD.TO</td>\n",
       "      <td>93</td>\n",
       "      <td>5086503.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>FAR.TO</td>\n",
       "      <td>139</td>\n",
       "      <td>633500.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>PET.TO</td>\n",
       "      <td>11</td>\n",
       "      <td>1100029.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>CVE.TO</td>\n",
       "      <td>73</td>\n",
       "      <td>53965480.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>TCL-A.TO</td>\n",
       "      <td>8</td>\n",
       "      <td>310432.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>SU.TO</td>\n",
       "      <td>63</td>\n",
       "      <td>12017751.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>WN.TO</td>\n",
       "      <td>137</td>\n",
       "      <td>4586698.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>RSI.TO</td>\n",
       "      <td>10</td>\n",
       "      <td>6782.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>PBH.TO</td>\n",
       "      <td>7</td>\n",
       "      <td>32771.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>EFX.TO</td>\n",
       "      <td>12</td>\n",
       "      <td>4189200.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>MTL.TO</td>\n",
       "      <td>123</td>\n",
       "      <td>756740.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>CTC-A.TO</td>\n",
       "      <td>9</td>\n",
       "      <td>1057.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>EIF.TO</td>\n",
       "      <td>6</td>\n",
       "      <td>3538.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>ACO-X.TO</td>\n",
       "      <td>34</td>\n",
       "      <td>26560.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Ticker  Insider_Buys_Count  Net_Shares_Bought\n",
       "0     DPM.TO                  86          9142771.0\n",
       "1     KNT.TO                   1             8333.0\n",
       "2    GRGD.TO                  32           648000.0\n",
       "3     WDO.TO                   7           677900.0\n",
       "4     DNG.TO                 136           159600.0\n",
       "5     TXG.TO                  18           554667.0\n",
       "6     ALS.TO                   9            54100.0\n",
       "7     ATZ.TO                  62           471200.0\n",
       "8    PAAS.TO                  15          1368070.0\n",
       "9     APM.TO                  40          2101921.0\n",
       "10    HWX.TO                  18          1095589.0\n",
       "11    TIH.TO                   6           132600.0\n",
       "12    PSI.TO                  84          1101000.0\n",
       "13    GIL.TO                 110          1575676.0\n",
       "14    RCH.TO                 117           879375.0\n",
       "15    TCW.TO                 128         10370216.0\n",
       "16   BDGI.TO                  73           503800.0\n",
       "17     CG.TO                  92          5442652.0\n",
       "18    RUS.TO                 141          2576200.0\n",
       "19    FVI.TO                   4           916900.0\n",
       "20    CEU.TO                  22         31620438.0\n",
       "21    NWC.TO                  34           197899.0\n",
       "22   ENGH.TO                  66          1039126.0\n",
       "23    IMO.TO                 150         19889952.0\n",
       "24    MRU.TO                  69          4423300.0\n",
       "25    STN.TO                  20             5431.0\n",
       "26  CCL-B.TO                   4           627580.0\n",
       "27    LUN.TO                  53         13358800.0\n",
       "28    FTT.TO                   1              348.0\n",
       "29      L.TO                 130         12804874.0\n",
       "30    POU.TO                   2          5439300.0\n",
       "31    CMG.TO                   7           317400.0\n",
       "32    ELD.TO                  93          5086503.0\n",
       "33    FAR.TO                 139           633500.0\n",
       "34    PET.TO                  11          1100029.0\n",
       "35    CVE.TO                  73         53965480.0\n",
       "36  TCL-A.TO                   8           310432.0\n",
       "37     SU.TO                  63         12017751.0\n",
       "38     WN.TO                 137          4586698.0\n",
       "39    RSI.TO                  10             6782.0\n",
       "40    PBH.TO                   7            32771.0\n",
       "41    EFX.TO                  12          4189200.0\n",
       "42    MTL.TO                 123           756740.0\n",
       "43  CTC-A.TO                   9             1057.0\n",
       "44    EIF.TO                   6             3538.0\n",
       "45  ACO-X.TO                  34            26560.0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from yahooquery import Ticker\n",
    "from IPython.display import display, Markdown\n",
    "\n",
    "# ==========================================\n",
    "# INSIDER FILTER FUNCTION\n",
    "# ==========================================\n",
    "def filter_for_insider_buying(tickers):\n",
    "    print(f\"üïµÔ∏è Scanning {len(tickers)} stocks for Insider Buying...\")\n",
    "    insider_picks = []\n",
    "    \n",
    "    # Chunk to prevent timeouts\n",
    "    chunk_size = 20\n",
    "    chunks = [tickers[i:i + chunk_size] for i in range(0, len(tickers), chunk_size)]\n",
    "    \n",
    "    for chunk in chunks:\n",
    "        try:\n",
    "            yq = Ticker(chunk, asynchronous=True)\n",
    "            df_insiders = yq.insider_transactions\n",
    "            \n",
    "            if isinstance(df_insiders, dict) or not hasattr(df_insiders, 'reset_index'): \n",
    "                continue\n",
    "            \n",
    "            df_insiders = df_insiders.reset_index()\n",
    "\n",
    "            for symbol in chunk:\n",
    "                if symbol not in df_insiders['symbol'].values:\n",
    "                    continue\n",
    "                \n",
    "                stock_tx = df_insiders[df_insiders['symbol'] == symbol].copy()\n",
    "                \n",
    "                # Filter for Purchases\n",
    "                buys = stock_tx[stock_tx['transactionText'].astype(str).str.contains(\"Purchase\", case=False, na=False)]\n",
    "                sells = stock_tx[stock_tx['transactionText'].astype(str).str.contains(\"Sale\", case=False, na=False)]\n",
    "                \n",
    "                # Logic: Net Positive Buying\n",
    "                buy_vol = buys['shares'].sum() if not buys.empty else 0\n",
    "                sell_vol = sells['shares'].sum() if not sells.empty else 0\n",
    "                \n",
    "                if buy_vol > sell_vol:\n",
    "                    insider_picks.append({\n",
    "                        'Ticker': symbol,\n",
    "                        'Insider_Buys_Count': len(buys),\n",
    "                        'Net_Shares_Bought': buy_vol - sell_vol\n",
    "                    })\n",
    "                        \n",
    "        except Exception:\n",
    "            continue\n",
    "\n",
    "    return pd.DataFrame(insider_picks)\n",
    "\n",
    "# ==========================================\n",
    "# 2. CREATE 'Fortress_insiders' DATAFRAME\n",
    "# ==========================================\n",
    "\n",
    "# Use fortress_df if it exists, otherwise use the top 20 backup list\n",
    "if 'fortress_df' in locals() and not fortress_df.empty:\n",
    "    target_tickers = fortress_df['Ticker'].tolist()\n",
    "else:\n",
    "    # Backup list from your logs so this runs even if you restarted the kernel\n",
    "    target_tickers = [\n",
    "        'PET.TO', 'MFI.TO', 'TXG.TO', 'SAP.TO', 'PAAS.TO', 'NEO.TO', 'WPM.TO', \n",
    "        'FNV.TO', 'LUG.TO', 'DPM.TO', 'ASM.TO', 'PNG.V', 'DSG.TO', 'KNT.TO', \n",
    "        'GGD.TO', 'GRGD.TO', 'WDO.TO', 'OGC.TO', 'DNG.TO', 'CLS.TO'\n",
    "    ]\n",
    "\n",
    "# Run the filter and assign to the variable you requested\n",
    "Fortress_insiders = filter_for_insider_buying(target_tickers)\n",
    "\n",
    "# Display so Data Wrangler picks it up\n",
    "print(f\"‚úÖ Created 'Fortress_insiders' with {len(Fortress_insiders)} rows.\")\n",
    "display(Fortress_insiders)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a8281dfc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Processing 12 stocks ---\n",
      "1. Fetching Analyst Ratings from Finviz...\n",
      "   Skipping Finviz for TCL-A.TO: HTTP error for URL https://finviz.com/quote.ashx?t=TCL-A.TO: 404 Client Error: Not Found for url: https://finviz.com/quote.ashx?t=TCL-A.TO\n",
      "   Skipping Finviz for MATR.TO: HTTP error for URL https://finviz.com/quote.ashx?t=MATR.TO: 404 Client Error: Not Found for url: https://finviz.com/quote.ashx?t=MATR.TO\n",
      "2. Fetching Price & Volatility from yfinance...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\James\\AppData\\Local\\Temp\\ipykernel_34168\\579518594.py:46: FutureWarning: YF.download() has changed argument auto_adjust default to True\n",
      "  data = yf.download(ticker_list, period=\"1y\", interval=\"1d\", group_by='ticker', progress=False, threads=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Watchlist ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "Ticker",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "Price",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "Change_%",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "52W_MA",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "Drop_from_High_%",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "Recom",
         "rawType": "object",
         "type": "unknown"
        },
        {
         "name": "Target_Price",
         "rawType": "object",
         "type": "unknown"
        },
        {
         "name": "Rel_Volume",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "Volatility_%",
         "rawType": "float64",
         "type": "float"
        }
       ],
       "ref": "74244355-71e2-4916-bf75-5e3a73300d7e",
       "rows": [
        [
         "6",
         "GRND",
         "13.41",
         "0.0",
         "17.64",
         "-46.64",
         "1.40",
         "21.75",
         "0.8",
         "3.18"
        ],
        [
         "7",
         "MATR.TO",
         "7.93",
         "-1.73",
         "10.66",
         "-38.95",
         null,
         null,
         "1.08",
         "3.08"
        ],
        [
         "0",
         "ADMA",
         "18.36",
         "-3.92",
         "17.91",
         "-28.48",
         "1.00",
         "30.00",
         "0.72",
         "3.27"
        ],
        [
         "8",
         "MIR",
         "23.7",
         "-0.29",
         "19.94",
         "-21.72",
         "1.12",
         "30.62",
         "0.43",
         "3.49"
        ],
        [
         "10",
         "SEI",
         "46.1",
         "3.41",
         "32.6",
         "-19.18",
         "1.17",
         "65.45",
         "0.89",
         "5.9"
        ],
        [
         "5",
         "FLEX",
         "61.67",
         "-1.42",
         "48.39",
         "-14.61",
         "1.50",
         "76.00",
         "0.25",
         "2.9"
        ],
        [
         "11",
         "TCL-A.TO",
         "22.7",
         "-0.87",
         "18.95",
         "-11.5",
         null,
         null,
         "0.74",
         "1.85"
        ],
        [
         "2",
         "ARCC",
         "20.29",
         "0.59",
         "20.48",
         "-9.37",
         "1.27",
         "22.64",
         "1.33",
         "1.38"
        ],
        [
         "9",
         "ONB",
         "22.61",
         "-0.79",
         "21.41",
         "-5.31",
         "1.85",
         "25.92",
         "0.72",
         "2.15"
        ],
        [
         "1",
         "APG",
         "38.86",
         "-0.87",
         "31.46",
         "-4.24",
         "1.45",
         "43.40",
         "0.48",
         "1.93"
        ],
        [
         "3",
         "BANC",
         "19.44",
         "-0.97",
         "15.39",
         "-3.14",
         "1.27",
         "22.41",
         "0.79",
         "2.18"
        ],
        [
         "4",
         "DD",
         "40.68",
         "-0.51",
         "31.94",
         "-2.8",
         "1.48",
         "47.19",
         "0.61",
         "2.23"
        ]
       ],
       "shape": {
        "columns": 9,
        "rows": 12
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Ticker</th>\n",
       "      <th>Price</th>\n",
       "      <th>Change_%</th>\n",
       "      <th>52W_MA</th>\n",
       "      <th>Drop_from_High_%</th>\n",
       "      <th>Recom</th>\n",
       "      <th>Target_Price</th>\n",
       "      <th>Rel_Volume</th>\n",
       "      <th>Volatility_%</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>GRND</td>\n",
       "      <td>13.41</td>\n",
       "      <td>0.00</td>\n",
       "      <td>17.64</td>\n",
       "      <td>-46.64</td>\n",
       "      <td>1.40</td>\n",
       "      <td>21.75</td>\n",
       "      <td>0.80</td>\n",
       "      <td>3.18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>MATR.TO</td>\n",
       "      <td>7.93</td>\n",
       "      <td>-1.73</td>\n",
       "      <td>10.66</td>\n",
       "      <td>-38.95</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.08</td>\n",
       "      <td>3.08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ADMA</td>\n",
       "      <td>18.36</td>\n",
       "      <td>-3.92</td>\n",
       "      <td>17.91</td>\n",
       "      <td>-28.48</td>\n",
       "      <td>1.00</td>\n",
       "      <td>30.00</td>\n",
       "      <td>0.72</td>\n",
       "      <td>3.27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>MIR</td>\n",
       "      <td>23.70</td>\n",
       "      <td>-0.29</td>\n",
       "      <td>19.94</td>\n",
       "      <td>-21.72</td>\n",
       "      <td>1.12</td>\n",
       "      <td>30.62</td>\n",
       "      <td>0.43</td>\n",
       "      <td>3.49</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>SEI</td>\n",
       "      <td>46.10</td>\n",
       "      <td>3.41</td>\n",
       "      <td>32.60</td>\n",
       "      <td>-19.18</td>\n",
       "      <td>1.17</td>\n",
       "      <td>65.45</td>\n",
       "      <td>0.89</td>\n",
       "      <td>5.90</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>FLEX</td>\n",
       "      <td>61.67</td>\n",
       "      <td>-1.42</td>\n",
       "      <td>48.39</td>\n",
       "      <td>-14.61</td>\n",
       "      <td>1.50</td>\n",
       "      <td>76.00</td>\n",
       "      <td>0.25</td>\n",
       "      <td>2.90</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>TCL-A.TO</td>\n",
       "      <td>22.70</td>\n",
       "      <td>-0.87</td>\n",
       "      <td>18.95</td>\n",
       "      <td>-11.50</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.74</td>\n",
       "      <td>1.85</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ARCC</td>\n",
       "      <td>20.29</td>\n",
       "      <td>0.59</td>\n",
       "      <td>20.48</td>\n",
       "      <td>-9.37</td>\n",
       "      <td>1.27</td>\n",
       "      <td>22.64</td>\n",
       "      <td>1.33</td>\n",
       "      <td>1.38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>ONB</td>\n",
       "      <td>22.61</td>\n",
       "      <td>-0.79</td>\n",
       "      <td>21.41</td>\n",
       "      <td>-5.31</td>\n",
       "      <td>1.85</td>\n",
       "      <td>25.92</td>\n",
       "      <td>0.72</td>\n",
       "      <td>2.15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>APG</td>\n",
       "      <td>38.86</td>\n",
       "      <td>-0.87</td>\n",
       "      <td>31.46</td>\n",
       "      <td>-4.24</td>\n",
       "      <td>1.45</td>\n",
       "      <td>43.40</td>\n",
       "      <td>0.48</td>\n",
       "      <td>1.93</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>BANC</td>\n",
       "      <td>19.44</td>\n",
       "      <td>-0.97</td>\n",
       "      <td>15.39</td>\n",
       "      <td>-3.14</td>\n",
       "      <td>1.27</td>\n",
       "      <td>22.41</td>\n",
       "      <td>0.79</td>\n",
       "      <td>2.18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>DD</td>\n",
       "      <td>40.68</td>\n",
       "      <td>-0.51</td>\n",
       "      <td>31.94</td>\n",
       "      <td>-2.80</td>\n",
       "      <td>1.48</td>\n",
       "      <td>47.19</td>\n",
       "      <td>0.61</td>\n",
       "      <td>2.23</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Ticker  Price  Change_%  52W_MA  Drop_from_High_% Recom Target_Price  Rel_Volume  Volatility_%\n",
       "6       GRND  13.41      0.00   17.64            -46.64  1.40        21.75        0.80          3.18\n",
       "7    MATR.TO   7.93     -1.73   10.66            -38.95   NaN          NaN        1.08          3.08\n",
       "0       ADMA  18.36     -3.92   17.91            -28.48  1.00        30.00        0.72          3.27\n",
       "8        MIR  23.70     -0.29   19.94            -21.72  1.12        30.62        0.43          3.49\n",
       "10       SEI  46.10      3.41   32.60            -19.18  1.17        65.45        0.89          5.90\n",
       "5       FLEX  61.67     -1.42   48.39            -14.61  1.50        76.00        0.25          2.90\n",
       "11  TCL-A.TO  22.70     -0.87   18.95            -11.50   NaN          NaN        0.74          1.85\n",
       "2       ARCC  20.29      0.59   20.48             -9.37  1.27        22.64        1.33          1.38\n",
       "9        ONB  22.61     -0.79   21.41             -5.31  1.85        25.92        0.72          2.15\n",
       "1        APG  38.86     -0.87   31.46             -4.24  1.45        43.40        0.48          1.93\n",
       "3       BANC  19.44     -0.97   15.39             -3.14  1.27        22.41        0.79          2.18\n",
       "4         DD  40.68     -0.51   31.94             -2.80  1.48        47.19        0.61          2.23"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# ==========================================\n",
    "# Watchlist Combiner (Finviz + YFinance)\n",
    "# ==========================================\n",
    "\n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "import yfinance as yf\n",
    "from finvizfinance.quote import finvizfinance\n",
    "import time\n",
    "import numpy as np\n",
    "\n",
    "# --- 1. INPUT YOUR MANUAL LIST HERE ---\n",
    "MY_TICKERS = ['GRND','ARCC','BANC','ONB','TCL-A.TO','ADMA','MIR','APG','SEI','FLEX','DD','MATR.TO'] \n",
    "\n",
    "def get_combined_watchlist(ticker_list):\n",
    "    print(f\"--- Processing {len(ticker_list)} stocks ---\")\n",
    "    \n",
    "    # --- PART A: Get Analyst Ratings from Finviz ---\n",
    "    print(\"1. Fetching Analyst Ratings from Finviz...\")\n",
    "    finviz_data = []\n",
    "    \n",
    "    for ticker in ticker_list:\n",
    "        try:\n",
    "            stock = finvizfinance(ticker)\n",
    "            info = stock.ticker_fundament()\n",
    "            \n",
    "            finviz_data.append({\n",
    "                'Ticker': ticker,\n",
    "                'Recom': info.get('Recom', np.nan),\n",
    "                'Target_Price': info.get('Target Price', np.nan)\n",
    "            })\n",
    "            time.sleep(0.5) \n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"   Skipping Finviz for {ticker}: {e}\")\n",
    "            finviz_data.append({'Ticker': ticker, 'Recom': np.nan, 'Target_Price': np.nan})\n",
    "\n",
    "    df_finviz = pd.DataFrame(finviz_data)\n",
    "    \n",
    "    # --- PART B: Get Real-Time Stats from yfinance ---\n",
    "    print(\"2. Fetching Price & Volatility from yfinance...\")\n",
    "    \n",
    "    try:\n",
    "        # Download data (1 Year is perfect for 52-Week MA)\n",
    "        data = yf.download(ticker_list, period=\"1y\", interval=\"1d\", group_by='ticker', progress=False, threads=True)\n",
    "        yf_stats = []\n",
    "        \n",
    "        for ticker in ticker_list:\n",
    "            try:\n",
    "                # --- FIXED: Robust Data Extraction ---\n",
    "                if isinstance(data.columns, pd.MultiIndex):\n",
    "                    if ticker in data.columns.levels[0]:\n",
    "                        df = data[ticker].copy()\n",
    "                    else:\n",
    "                        print(f\"   Warning: {ticker} not found in yfinance download.\")\n",
    "                        continue\n",
    "                else:\n",
    "                    df = data.copy()\n",
    "\n",
    "                # Cleanup\n",
    "                df = df.dropna(subset=['Close'])\n",
    "                if len(df) < 20: \n",
    "                    print(f\"   Warning: Not enough data for {ticker}\")\n",
    "                    continue\n",
    "\n",
    "                # --- MATH CALCULATIONS ---\n",
    "                current_price = df['Close'].iloc[-1]\n",
    "                prev_close = df['Close'].iloc[-2]\n",
    "                \n",
    "                high_52 = df['High'].max()\n",
    "                drop_from_high = ((current_price - high_52) / high_52) * 100\n",
    "                \n",
    "                change_pct = ((current_price - prev_close) / prev_close) * 100\n",
    "                \n",
    "                # Volatility (30-day Std Dev)\n",
    "                volatility = df['Close'].pct_change().std() * 100\n",
    "                \n",
    "                # Relative Volume\n",
    "                curr_vol = df['Volume'].iloc[-1]\n",
    "                avg_vol = df['Volume'].tail(30).mean()\n",
    "                rel_vol = curr_vol / avg_vol if avg_vol > 0 else 0\n",
    "\n",
    "                # --- NEW: 52-Week Moving Average ---\n",
    "                # Since we fetched exactly 1 year ('1y'), the mean of the whole column is the 52W MA\n",
    "                ma_52w = df['Close'].mean()\n",
    "\n",
    "                # Distance from MA (Optional but helpful metric)\n",
    "                # dist_ma = ((current_price - ma_52w) / ma_52w) * 100 \n",
    "\n",
    "                yf_stats.append({\n",
    "                    'Ticker': ticker,\n",
    "                    'Price': round(current_price, 2),\n",
    "                    'Change_%': round(change_pct, 2),\n",
    "                    '52W_MA': round(ma_52w, 2),          # <--- Added Here\n",
    "                    'Drop_from_High_%': round(drop_from_high, 2),\n",
    "                    'Volatility_%': round(volatility, 2),\n",
    "                    'Rel_Volume': round(rel_vol, 2)\n",
    "                })\n",
    "                \n",
    "            except Exception as e:\n",
    "                print(f\"   Error calculating stats for {ticker}: {e}\")\n",
    "                continue\n",
    "                \n",
    "        df_yf = pd.DataFrame(yf_stats)\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"yfinance Critical Error: {e}\")\n",
    "        return pd.DataFrame()\n",
    "\n",
    "    # --- PART C: Merge ---\n",
    "    if not df_finviz.empty:\n",
    "        if not df_yf.empty:\n",
    "            master_df = pd.merge(df_finviz, df_yf, on='Ticker', how='outer')\n",
    "        else:\n",
    "            master_df = df_finviz\n",
    "            \n",
    "        # Added '52W_MA' to this list so it displays in the final table\n",
    "        cols = ['Ticker', 'Price', 'Change_%', '52W_MA', 'Drop_from_High_%', 'Recom', 'Target_Price', 'Rel_Volume', 'Volatility_%']\n",
    "        \n",
    "        final_cols = [c for c in cols if c in master_df.columns]\n",
    "        return master_df[final_cols]\n",
    "    else:\n",
    "        return pd.DataFrame()\n",
    "\n",
    "# --- RUN IT ---\n",
    "watchlist_df = get_combined_watchlist(MY_TICKERS)\n",
    "\n",
    "if not watchlist_df.empty:\n",
    "    if 'Drop_from_High_%' in watchlist_df.columns:\n",
    "        watchlist_df['Drop_from_High_%'] = pd.to_numeric(watchlist_df['Drop_from_High_%'], errors='coerce')\n",
    "        print(\"\\n--- Final Watchlist ---\")\n",
    "        display(watchlist_df.sort_values(by='Drop_from_High_%', ascending=True))\n",
    "    else:\n",
    "        display(watchlist_df)\n",
    "else:\n",
    "    print(\"No data found.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "03a4571f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import pandas as pd\n",
    "import google as genai\n",
    "import enum\n",
    "from typing_extensions import TypedDict\n",
    "import json\n",
    "import plotly.express as px\n",
    "import sys\n",
    "#!\"{sys.executable}\" -m pip install google.genai\n",
    "#!\"{sys.executable}\" -m pip install plotly.express"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ba6e20c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "tickers_gemini = ['MATR.TO'] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f2eea302",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ API Key loaded securely.\n",
      "\n",
      "üß† Gemini 3 is thinking (High Reasoning Mode)... analyzing $['MATR.TO']...\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "## üß† Gemini 3 Sentiment Report: ['MATR.TO'] (Mattr Corp.)\n",
       "**Reasoning Depth:** High  \n",
       "**Sentiment Score:** 4/10 (Neutral-Bearish Short Term / Bullish Divergence Long Term)  \n",
       "**Verdict:** Speculative / Contrarian Buy\n",
       "\n",
       "---\n",
       "\n",
       "### 1. The Bull Thesis (Why it goes up)\n",
       "*   **Massive Insider Conviction**: Despite a 21% share price collapse following Q3 earnings, high-ranking insiders (CEO Michael Reeves and multiple Directors) executed \"informative buys\" in late November/December 2025. This suggests leadership views the sell-off as a massive overreaction to temporary headwinds.\n",
       "*   **Deep Valuation Discount**: The stock is currently trading at roughly ~C$8.00, which is over 75% below some intrinsic fair value estimates (approx. C$35.00 according to multi-stage DCF models).\n",
       "*   **Infrastructure Secular Tailwinds**: Long-term demand for its \"Connection Technologies\" segment (which surged 105% YoY) remains robust due to global electrification and data center expansion.\n",
       "*   **Operational Transition Completion**: Management has physically completed its \"Manufacturing Excellence & Optimization\" (MEO) projects, which should lead to improved margins once the initial cash outflows subside in 2026.\n",
       "\n",
       "### 2. The Bear Thesis (Why it goes down)\n",
       "*   **Leverage Concerns**: Net Debt to Adjusted EBITDA has climbed to **3.86x**, moving significantly away from the management target of <2.0x. This high leverage makes the stock sensitive to interest rates and economic slowdowns.\n",
       "*   **\"Dead Money\" Guidance**: Management paused the share repurchase program and M&A activity until at least 2027. This removes a major price floor and suggests a period of \"treading water\" while they focus on deleveraging.\n",
       "*   **Seasonal and Geopolitical Friction**: Cautious Q4 2025 guidance was blamed on a Canadian industrial slowdown, commodity price volatility, and potential tariff impacts. \n",
       "*   **Tax-Loss Harvesting Pressure**: As of late December 2025, the stock is a prime candidate for tax-loss selling, creating a technical \"falling knife\" environment with low liquidity.\n",
       "\n",
       "---\n",
       "\n",
       "### 3. Deep Dive Analysis\n",
       "\n",
       "#### **News Analysis**\n",
       "The sentiment in the last 30 days is **highly polarized**. Official headlines focus on the \"earnings plunge\" and \"cautious outlook,\" creating a narrative of fear. However, the underlying data shows that the revenue miss was actually a \"beat\" (+22% revenue surprise), but the market punished the company for an EPS miss (-122% surprise) and the grim guidance. The \"fear-mongering\" is largely driven by the debt levels and the lack of immediate catalysts for 2026.\n",
       "\n",
       "#### **Smart Money**\n",
       "*   **Institutional Flows**: Institutional ownership fell by ~6.6% recently. While 35 institutions still hold positions, there is a clear \"rotation out\" by funds seeking immediate growth.\n",
       "*   **Insiders**: This is where the \"Whisper\" contradiction lives. While analysts are downgrading to \"Hold\" (Stifel, TD Cowen), the people running the company are buying. Insiders bought roughly C$1.3M worth of shares in the last 3 months, specifically after the post-earnings crash.\n",
       "\n",
       "#### **Financial Statement Analysis**\n",
       "*   **Historic (3-Year) Performance**: Mattr has been in a \"transformation phase,\" shedding legacy oil & gas assets to focus on materials technology. Revenue has been volatile but showed a massive 39% YoY surge in Q3 2025.\n",
       "*   **Expected Performance**: Earnings are forecast to grow at ~33.7% per year as the company transitions into a higher-margin \"Connection\" and \"Composite\" technologies firm. However, the current \"debt wall\" (3.86x leverage) is the primary hurdle for the next 12‚Äì18 months.\n",
       "\n",
       "---\n",
       "\n",
       "### 4. Conclusion\n",
       "The current price of **MATR.TO** is a **Classic Value Trap in the short term, but a High-Conviction Opportunity for the patient investor.** \n",
       "\n",
       "The market is currently obsessing over the \"Pause until 2027\" guidance and the debt ratio, leading to a capitulation phase accelerated by year-end tax-loss harvesting. However, the extreme divergence between **insider buying** and **price action** is a \"tell.\" If the company can successfully navigate its debt reduction without further dilution, the current C$8.00 level represents a generational floor. \n",
       "\n",
       "**Verdict:** Avoid if you have a 3-month horizon; **Speculative Buy** if you have a 24-month horizon."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import os\n",
    "from google import genai\n",
    "from google.genai import types\n",
    "from IPython.display import display, Markdown\n",
    "\n",
    "# ==========================================\n",
    "# SECURE CONFIGURATION\n",
    "# ==========================================\n",
    "\n",
    "# 1. Define the path to your key file\n",
    "# If the file is in the same folder as this notebook, just use the filename.\n",
    "KEY_FILE_PATH = \"C:\\\\Users\\\\James\\\\OneDrive - McMaster University\\\\Gemini API Key\\\\gemini_key.txt\"\n",
    "\n",
    "def load_api_key(filepath):\n",
    "    \"\"\"\n",
    "    Reads the API key from a local file to avoid hardcoding it.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        with open(filepath, \"r\") as f:\n",
    "            # .strip() removes any accidental newlines or spaces\n",
    "            return f.read().strip()\n",
    "    except FileNotFoundError:\n",
    "        print(f\"‚ùå Error: Could not find the file '{filepath}'\")\n",
    "        print(\"Please create a text file with your API key in it.\")\n",
    "        return None\n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Error reading key file: {e}\")\n",
    "        return None\n",
    "\n",
    "# 2. Load the key and set the environment variable\n",
    "api_key = load_api_key(KEY_FILE_PATH)\n",
    "\n",
    "if api_key:\n",
    "    os.environ[\"GEMINI_API_KEY\"] = api_key\n",
    "    print(\"‚úÖ API Key loaded securely.\")\n",
    "else:\n",
    "    print(\"‚ö†Ô∏è CRITICAL: API Key not loaded. The script will fail.\")\n",
    "\n",
    "# ==========================================\n",
    "# SENTIMENT ANALYSIS FUNCTION\n",
    "# ==========================================\n",
    "def analyze_sentiment_gemini_3(tickers_gemini, company_name=None):\n",
    "    \"\"\"\n",
    "    Uses Gemini 3 Flash (Preview) with 'High' Thinking Level and Google Search \n",
    "    using the NEW google-genai SDK.\n",
    "    \"\"\"\n",
    "    if not os.environ.get(\"GEMINI_API_KEY\"):\n",
    "        print(\"‚ùå Stop: No API Key found.\")\n",
    "        return\n",
    "\n",
    "    print(f\"\\nüß† Gemini 3 is thinking (High Reasoning Mode)... analyzing ${tickers_gemini}...\")\n",
    "\n",
    "    # Initialize Client\n",
    "    client = genai.Client(api_key=os.environ[\"GEMINI_API_KEY\"])\n",
    "\n",
    "    config = types.GenerateContentConfig(\n",
    "        thinking_config=types.ThinkingConfig(\n",
    "            include_thoughts=False, \n",
    "            thinking_level=\"HIGH\"\n",
    "        ),\n",
    "        tools=[types.Tool(\n",
    "            google_search=types.GoogleSearch() \n",
    "        )],\n",
    "        response_modalities=[\"TEXT\"]\n",
    "    )\n",
    "\n",
    "    prompt = f\"\"\"\n",
    "    You are a Senior Equity Research Analyst using the Gemini 3 Reasoning Engine. \n",
    "    Perform a deep \"Market Sentiment Analysis\" on {tickers_gemini} ({company_name if company_name else 'the company'}).\n",
    "    \n",
    "    Step 1: SEARCH. Use Google Search to find the latest (last 30 days) news, analyst notes, and SEC filings.\n",
    "    Step 2: REASON. Analyze the search results to determine the true market psychology. Look for contradictions between price action and news.\n",
    "    \n",
    "    Investigate these 4 Pillars:\n",
    "    1. **News Virality**: Are headlines fear-mongering or euphoric? (Look for scandals, lawsuits, or product breakthroughs).\n",
    "    2. **Analyst Shifts**: Are price targets moving UP or DOWN in the last week?\n",
    "    3. **Institutional Flows**: Any reports of hedge funds or insiders buying/selling?\n",
    "    4. **The \"Whisper\" Number**: What are traders saying on forums vs. official guidance?\n",
    "\n",
    "    **OUTPUT FORMAT:**\n",
    "    Produce a professional Markdown report:\n",
    "    \n",
    "    ## üß† Gemini 3 Sentiment Report: {tickers_gemini}\n",
    "    **Reasoning Depth:** High\n",
    "    **Sentiment Score:** [1-10]\n",
    "    **Verdict:** [Buy / Hold / Sell / Speculative]\n",
    "    \n",
    "    ### 1. The Bull Thesis (Why it goes up)\n",
    "    * ...\n",
    "    \n",
    "    ### 2. The Bear Thesis (Why it goes down)\n",
    "    * ...\n",
    "    \n",
    "    ### 3. Deep Dive Analysis\n",
    "    * **News Analysis**: ...\n",
    "    * **Smart Money**: ...\n",
    "    * **Financial Statement Analysis**: (Historic performance over last 3 years + expected performance)\n",
    "    \n",
    "    ### 4. Conclusion\n",
    "    [Summary of whether the current price is a trap or an opportunity]\n",
    "    \"\"\"\n",
    "\n",
    "    try:\n",
    "        response = client.models.generate_content(\n",
    "            model='gemini-3-flash-preview', # Or 'gemini-3-flash-preview'\n",
    "            contents=prompt,\n",
    "            config=config\n",
    "        )\n",
    "        display(Markdown(response.text))\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Error: {e}\")\n",
    "\n",
    "# ==========================================\n",
    "# EXECUTION\n",
    "# ==========================================\n",
    "# Only run this if the key loaded successfully\n",
    "if os.environ.get(\"GEMINI_API_KEY\"):\n",
    "    analyze_sentiment_gemini_3(tickers_gemini, tickers_gemini)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
