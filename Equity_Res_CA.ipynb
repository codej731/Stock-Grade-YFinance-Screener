{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "67ec8184",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import requests\n",
    "from yahooquery import Ticker  # Step 2 (Speed)\n",
    "import yfinance as yf          # Step 3 (Reliability)\n",
    "import io\n",
    "import json\n",
    "import os\n",
    "import time\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "831a506f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "\n",
    "# ==========================================\n",
    "# CONFIGURATION\n",
    "# ==========================================\n",
    "# 1. FOLDER SETUP (The Fix for GitHub Portability)\n",
    "DATA_FOLDER = \"YfinanceDataDump\"  # Relative path (creates folder in project root)\n",
    "\n",
    "# Create the folder if it doesn't exist\n",
    "if not os.path.exists(DATA_FOLDER):\n",
    "    try:\n",
    "        os.makedirs(DATA_FOLDER)\n",
    "        print(f\"Created data folder: {DATA_FOLDER}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Warning: Could not create folder '{DATA_FOLDER}'. Saving to current directory. Error: {e}\")\n",
    "        DATA_FOLDER = \".\"\n",
    "\n",
    "# 2. FILE PATHS (Everything saves inside the folder now)\n",
    "CACHE_FILE = os.path.join(DATA_FOLDER, \"financial_cache.json\")\n",
    "FORTRESS_CSV = os.path.join(DATA_FOLDER, \"fortress_stocks.csv\")\n",
    "STRONG_CSV = os.path.join(DATA_FOLDER, \"strong_stocks.csv\")\n",
    "RISKY_CSV = os.path.join(DATA_FOLDER, \"risky_stocks.csv\")\n",
    "ANALYST_CSV = os.path.join(DATA_FOLDER, \"Analyst_Fortress_Picks.csv\")\n",
    "BUFFETT_CSV = os.path.join(DATA_FOLDER, \"Buffett_Value_Picks.csv\")\n",
    "\n",
    "# 3. UNIVERSE FILTERS\n",
    "MIN_PRICE = 2.00               \n",
    "MIN_VOLUME = 100_000          # 100K shares/day       \n",
    "MIN_CAP = 50_000_000        # $50M\n",
    "MIN_CURRENT_RATIO = 1.2\n",
    "MAX_PE_RATIO = 100.0         \n",
    "\n",
    "# 4. SAFETY THRESHOLDS \n",
    "MIN_INTEREST_COVERAGE = 1.5\n",
    "MIN_ROIC = 0.05              # 5%\n",
    "FORTRESS_MARGIN_THRESHOLD = 0.05  # 5%\n",
    "\n",
    "EXCLUDED_SECTORS = ['Financial Services', 'Real Estate']\n",
    "CACHE_EXPIRY_DAYS = 30 \n",
    "\n",
    "# ==========================================\n",
    "# HELPER FUNCTIONS\n",
    "# ==========================================\n",
    "def load_cache():\n",
    "    if os.path.exists(CACHE_FILE):\n",
    "        try:\n",
    "            with open(CACHE_FILE, 'r') as f:\n",
    "                return json.load(f)\n",
    "        except:\n",
    "            return {}\n",
    "    return {}\n",
    "\n",
    "def save_cache(cache_data):\n",
    "    try:\n",
    "        with open(CACHE_FILE, 'w') as f:\n",
    "            json.dump(cache_data, f)\n",
    "    except Exception as e:\n",
    "        print(f\"Warning: Could not save cache: {e}\")\n",
    "\n",
    "def calculate_altman_z_yfinance(bs, fin, market_cap):\n",
    "    \"\"\"\n",
    "    Calculates Z-Score using yfinance DataFrames.\n",
    "    Formula: 1.2A + 1.4B + 3.3C + 0.6D + 1.0E\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Helper to safely get value from Series\n",
    "        def get_val(df, keys):\n",
    "            for k in keys:\n",
    "                if k in df.index:\n",
    "                    return df.loc[k].iloc[0]\n",
    "            return 0\n",
    "\n",
    "        # Map yfinance row names\n",
    "        total_assets = get_val(bs, ['Total Assets'])\n",
    "        total_liab = get_val(bs, ['Total Liabilities Net Minority Interest', 'Total Liabilities'])\n",
    "        current_assets = get_val(bs, ['Current Assets', 'Total Current Assets'])\n",
    "        current_liab = get_val(bs, ['Current Liabilities', 'Total Current Liabilities'])\n",
    "        retained_earnings = get_val(bs, ['Retained Earnings'])\n",
    "        \n",
    "        ebit = get_val(fin, ['EBIT', 'Operating Income'])\n",
    "        total_revenue = get_val(fin, ['Total Revenue'])\n",
    "        \n",
    "        if total_assets == 0 or total_liab == 0: return 0\n",
    "\n",
    "        # A: Working Capital / Total Assets\n",
    "        A = (current_assets - current_liab) / total_assets\n",
    "        \n",
    "        # B: Retained Earnings / Total Assets\n",
    "        B = retained_earnings / total_assets\n",
    "        \n",
    "        # C: EBIT / Total Assets\n",
    "        C = ebit / total_assets\n",
    "        \n",
    "        # D: Market Value of Equity / Total Liabilities\n",
    "        D = market_cap / total_liab\n",
    "        \n",
    "        # E: Sales / Total Assets\n",
    "        E = total_revenue / total_assets\n",
    "        \n",
    "        return (1.2 * A) + (1.4 * B) + (3.3 * C) + (0.6 * D) + (1.0 * E)\n",
    "    except Exception as e:\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "efa4bf6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==========================================\n",
    "# STEP 1: FETCH CANADIAN UNIVERSE (ROBUST)\n",
    "# ==========================================\n",
    "def get_combined_universe():\n",
    "    print(\"--- STEP 1: Fetching Canadian Universe (TSX & TSX-V) ---\")\n",
    "    tickers = []\n",
    "    \n",
    "    # --- METHOD 1: TMX OFFICIAL MOC LIST ---\n",
    "    url_tmx = \"https://www.tsx.com/files/trading/moc-eligible-stocks.txt\"\n",
    "    headers = {\n",
    "        \"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36\"\n",
    "    }\n",
    "    \n",
    "    try:\n",
    "        print(\"   -> Attempting to fetch official TMX list...\")\n",
    "        response = requests.get(url_tmx, headers=headers, timeout=10)\n",
    "        response.raise_for_status()\n",
    "        \n",
    "        lines = response.content.decode('utf-8').split('\\n')\n",
    "        \n",
    "        for line in lines:\n",
    "            parts = line.strip().split()\n",
    "            if len(parts) < 3: continue\n",
    "            \n",
    "            # PARSING LOGIC: Detect if Exchange is at the Start or End\n",
    "            # Format A: \"TSX    RY    ROYAL BANK...\"\n",
    "            # Format B: \"RY     ROYAL BANK...     TSX\"\n",
    "            \n",
    "            symbol = None\n",
    "            exchange = None\n",
    "            \n",
    "            if parts[0] in ['TSX', 'TSXV']:\n",
    "                exchange = parts[0]\n",
    "                symbol = parts[1]\n",
    "            elif parts[-1] in ['TSX', 'TSXV']:\n",
    "                exchange = parts[-1]\n",
    "                symbol = parts[0]\n",
    "            \n",
    "            if symbol and exchange:\n",
    "                # Clean Symbol (Yahoo uses hyphens, TMX uses dots)\n",
    "                clean_symbol = symbol.replace('.', '-')\n",
    "                \n",
    "                if exchange == \"TSX\":\n",
    "                    tickers.append(f\"{clean_symbol}.TO\")\n",
    "                elif exchange == \"TSXV\":\n",
    "                    tickers.append(f\"{clean_symbol}.V\")\n",
    "                    \n",
    "        tickers = list(set(tickers))\n",
    "        print(f\"   -> Success: Found {len(tickers)} stocks via TMX.\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"   -> TMX Fetch Failed ({e}). Trying Backup...\")\n",
    "\n",
    "    # --- METHOD 2: WIKIPEDIA S&P/TSX COMPOSITE (If Method 1 returns 0 or fails) ---\n",
    "    if len(tickers) == 0:\n",
    "        try:\n",
    "            print(\"   -> Attempting to scrape S&P/TSX Composite from Wikipedia...\")\n",
    "            url_wiki = \"https://en.wikipedia.org/wiki/S%26P/TSX_Composite_Index\"\n",
    "            dfs = pd.read_html(url_wiki)\n",
    "            \n",
    "            # The constituent table is usually the first or second table\n",
    "            for df in dfs:\n",
    "                if 'Symbol' in df.columns:\n",
    "                    # Wikipedia symbols often look like \"RY\" or \"RY.TO\"\n",
    "                    wiki_tickers = df['Symbol'].astype(str).tolist()\n",
    "                    for t in wiki_tickers:\n",
    "                        t = t.replace('.', '-') # Fix BAM.A to BAM-A\n",
    "                        if not t.endswith('.TO'):\n",
    "                            t = t + \".TO\"\n",
    "                        tickers.append(t)\n",
    "                    break\n",
    "            \n",
    "            tickers = list(set(tickers))\n",
    "            print(f\"   -> Success: Found {len(tickers)} stocks via Wikipedia.\")\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"   -> Wikipedia Scraping Failed ({e}).\")\n",
    "\n",
    "    # --- METHOD 3: EMERGENCY FALLBACK LIST ---\n",
    "    if len(tickers) == 0:\n",
    "        print(\"   -> All web fetches failed. Using Emergency Hardcoded List.\")\n",
    "        tickers = [\n",
    "            'SHOP.TO', 'RY.TO', 'TD.TO', 'CNR.TO', 'CP.TO', 'CSU.TO', 'ATD.TO', 'DOL.TO',\n",
    "            'BMO.TO', 'BNS.TO', 'TRP.TO', 'ENB.TO', 'CNQ.TO', 'BCE.TO', 'CM.TO', 'MFC.TO',\n",
    "            'QSR.TO', 'GIB-A.TO', 'SU.TO', 'WCN.TO', 'TECK-B.TO', 'T.TO', 'POW.TO', 'CVE.TO',\n",
    "            'NA.TO', 'FTS.TO', 'EMA.TO', 'AEM.TO', 'WPM.TO', 'MRU.TO', 'OTEX.TO', 'SAP.TO',\n",
    "            'L.TO', 'WN.TO', 'RCI-B.TO', 'CTC-A.TO', 'MG.TO', 'FM.TO', 'K.TO', 'CAE.TO',\n",
    "            'TIH.TO', 'GIL.TO', 'DOO.TO', 'STN.TO', 'EFN.TO', 'KEY.TO', 'PPL.TO', 'IMO.TO'\n",
    "        ]\n",
    "        print(f\"   -> Loaded {len(tickers)} major stocks.\")\n",
    "\n",
    "    return tickers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "65c3da19",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==========================================\n",
    "# STEP 2: LIGHTWEIGHT SIEVE (YahooQuery)\n",
    "# ==========================================\n",
    "def get_initial_survivors(tickers):\n",
    "    print(f\"\\n--- STEP 2: Running 'Lightweight' Filter on {len(tickers)} stocks ---\")\n",
    "    chunk_size = 500 \n",
    "    survivors = []\n",
    "    chunks = [tickers[i:i + chunk_size] for i in range(0, len(tickers), chunk_size)]\n",
    "    \n",
    "    for i, chunk in enumerate(chunks):\n",
    "        if i % 2 == 0: print(f\" -> Processing Batch {i+1}/{len(chunks)}...\")\n",
    "        try:\n",
    "            yq = Ticker(chunk, asynchronous=True)\n",
    "            df_modules = yq.get_modules('summaryProfile summaryDetail financialData price defaultKeyStatistics')\n",
    "            \n",
    "            for symbol, data in df_modules.items():\n",
    "                if isinstance(data, str): continue \n",
    "                try:\n",
    "                    price = data.get('price', {}).get('regularMarketPrice', 0)\n",
    "                    if price is None: price = 0\n",
    "                    \n",
    "                    vol = data.get('summaryDetail', {}).get('averageVolume', 0)\n",
    "                    if vol is None or vol == 0:\n",
    "                         vol = data.get('price', {}).get('averageDailyVolume10Day', 0)\n",
    "                    \n",
    "                    cap = data.get('price', {}).get('marketCap', 0)\n",
    "                    if cap is None: cap = 0\n",
    "                    \n",
    "                    sector = data.get('summaryProfile', {}).get('sector', 'Unknown')\n",
    "                    fin_data = data.get('financialData', {})\n",
    "                    curr_ratio = fin_data.get('currentRatio', 0)\n",
    "                    op_margins = fin_data.get('operatingMargins', 0)\n",
    "                    if curr_ratio is None: curr_ratio = 0\n",
    "                    if op_margins is None: op_margins = 0\n",
    "\n",
    "                    # --- P/E RATIO CHECK ---\n",
    "                    pe = data.get('summaryDetail', {}).get('trailingPE')\n",
    "                    if pe is not None and pe > MAX_PE_RATIO: continue\n",
    "\n",
    "                    # FILTERS\n",
    "                    if price < MIN_PRICE: continue\n",
    "                    if cap < MIN_CAP: continue\n",
    "                    if vol < MIN_VOLUME: continue \n",
    "                    if any(x in sector for x in EXCLUDED_SECTORS): continue\n",
    "                    if curr_ratio < MIN_CURRENT_RATIO: continue\n",
    "                    if op_margins <= 0: continue \n",
    "                    \n",
    "                    survivors.append({\n",
    "                        'Ticker': symbol,\n",
    "                        'Sector': sector,\n",
    "                        'Price': price,\n",
    "                        'Op Margin %': round(op_margins * 100, 2),\n",
    "                        'P/E': round(pe, 2) if pe else 0,\n",
    "                        'Curr Ratio': curr_ratio,\n",
    "                        'Mkt Cap (B)': round(cap / 1_000_000_000, 2)\n",
    "                    })\n",
    "                except: continue\n",
    "        except: continue\n",
    "    return pd.DataFrame(survivors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b09f64f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# ==========================================\n",
    "# STEP 3: DEEP DIVE (yfinance + Cache)\n",
    "# ==========================================\n",
    "def get_advanced_metrics(survivor_df):\n",
    "    tickers = survivor_df['Ticker'].tolist()\n",
    "    print(f\"\\n--- STEP 3: Fetching Deep Financials for {len(tickers)} Survivors ---\")\n",
    "    \n",
    "    cache = load_cache()\n",
    "    current_time = time.time()\n",
    "    expiry_seconds = CACHE_EXPIRY_DAYS * 86400\n",
    "    \n",
    "    final_data = []\n",
    "    \n",
    "    for i, ticker in enumerate(tickers):\n",
    "        if i % 20 == 0: print(f\" -> Analyzing {i+1}/{len(tickers)}: {ticker}...\")\n",
    "        \n",
    "        def determine_tier(metrics, base_row):\n",
    "            if metrics['int_cov'] < MIN_INTEREST_COVERAGE: return \"Risky\"\n",
    "            if metrics['roic'] < MIN_ROIC: return \"Risky\"\n",
    "            \n",
    "            op_margin_pct = base_row['Op Margin %'] / 100\n",
    "            if op_margin_pct >= FORTRESS_MARGIN_THRESHOLD: return \"Fortress\"\n",
    "            return \"Strong\"\n",
    "\n",
    "        # 1. CHECK CACHE\n",
    "        cached_data = cache.get(ticker)\n",
    "        if cached_data and (current_time - cached_data['timestamp'] < expiry_seconds):\n",
    "            if cached_data.get('roic') == -999: continue \n",
    "            \n",
    "            base_row = survivor_df[survivor_df['Ticker'] == ticker].iloc[0]\n",
    "            tier = determine_tier(cached_data, base_row)\n",
    "            \n",
    "            final_data.append({\n",
    "                'Ticker': ticker,\n",
    "                'Tier': tier,\n",
    "                'Price': base_row['Price'],\n",
    "                'P/E': base_row['P/E'],\n",
    "                'Sector': base_row['Sector'],\n",
    "                'Z-Score': cached_data['z_score'],\n",
    "                'ROIC %': round(cached_data['roic'] * 100, 2),\n",
    "                'Op Margin %': base_row['Op Margin %'],\n",
    "                'Curr Ratio': base_row['Curr Ratio'],\n",
    "                'Int Cov': cached_data['int_cov'],\n",
    "                'Mkt Cap (B)': base_row['Mkt Cap (B)']\n",
    "            })\n",
    "            continue\n",
    "\n",
    "        # 2. FETCH NEW DATA\n",
    "        try:\n",
    "            stock = yf.Ticker(ticker)\n",
    "            fin = stock.financials\n",
    "            bs = stock.balance_sheet\n",
    "            \n",
    "            if fin.empty or bs.empty:\n",
    "                cache[ticker] = {'timestamp': current_time, 'z_score': 0, 'roic': -999, 'int_cov': -999}\n",
    "                continue\n",
    "            \n",
    "            def get_item(df, keys):\n",
    "                for k in keys:\n",
    "                    if k in df.index: return df.loc[k].iloc[0]\n",
    "                return 0\n",
    "\n",
    "            ebit = get_item(fin, ['EBIT', 'Operating Income', 'Pretax Income'])\n",
    "            int_exp = get_item(fin, ['Interest Expense', 'Interest Expense Non Operating'])\n",
    "            total_assets = get_item(bs, ['Total Assets'])\n",
    "            curr_liab = get_item(bs, ['Current Liabilities', 'Total Current Liabilities'])\n",
    "            \n",
    "            int_exp = abs(int_exp)\n",
    "            if int_exp == 0: int_cov = 100\n",
    "            else: int_cov = ebit / int_exp\n",
    "            \n",
    "            invested_cap = total_assets - curr_liab\n",
    "            if invested_cap <= 0: roic = 0\n",
    "            else: roic = ebit / invested_cap\n",
    "            \n",
    "            base_row = survivor_df[survivor_df['Ticker'] == ticker].iloc[0]\n",
    "            mkt_cap_raw = base_row['Mkt Cap (B)'] * 1_000_000_000\n",
    "            z = calculate_altman_z_yfinance(bs, fin, mkt_cap_raw)\n",
    "            \n",
    "            metrics = {\n",
    "                'timestamp': current_time,\n",
    "                'z_score': round(z, 2),\n",
    "                'roic': roic,\n",
    "                'int_cov': round(int_cov, 2)\n",
    "            }\n",
    "            cache[ticker] = metrics\n",
    "            \n",
    "            tier = determine_tier(metrics, base_row)\n",
    "\n",
    "            final_data.append({\n",
    "                'Ticker': ticker,\n",
    "                'Tier': tier,\n",
    "                'Price': base_row['Price'],\n",
    "                'P/E': base_row['P/E'],\n",
    "                'Sector': base_row['Sector'],\n",
    "                'Z-Score': round(z, 2),\n",
    "                'ROIC %': round(roic * 100, 2),\n",
    "                'Op Margin %': base_row['Op Margin %'],\n",
    "                'Curr Ratio': base_row['Curr Ratio'],\n",
    "                'Int Cov': round(int_cov, 2),\n",
    "                'Mkt Cap (B)': base_row['Mkt Cap (B)']\n",
    "            })\n",
    "            \n",
    "        except Exception as e:\n",
    "            continue\n",
    "\n",
    "    save_cache(cache)\n",
    "    return pd.DataFrame(final_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a5361c2f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- STEP 1: Fetching Canadian Universe (TSX & TSX-V) ---\n",
      "   -> Attempting to fetch official TMX list...\n",
      "   -> Success: Found 1089 stocks via TMX.\n",
      "\n",
      "--- STEP 2: Running 'Lightweight' Filter on 1089 stocks ---\n",
      " -> Processing Batch 1/3...\n",
      " -> Processing Batch 3/3...\n",
      "\n",
      "✅ Step 2 Complete. 111 stocks passed basic filters.\n",
      "\n",
      "--- STEP 3: Fetching Deep Financials for 111 Survivors ---\n",
      " -> Analyzing 1/111: PET.TO...\n",
      " -> Analyzing 21/111: MFI.TO...\n",
      " -> Analyzing 41/111: TXG.TO...\n",
      " -> Analyzing 61/111: SAP.TO...\n",
      " -> Analyzing 81/111: PAAS.TO...\n",
      " -> Analyzing 101/111: NEO.TO...\n",
      "\n",
      "============================================================\n",
      "RESULTS GENERATED\n",
      "============================================================\n",
      "1. FORTRESS (78): Saved to 'YfinanceDataDump\\fortress_stocks.csv'\n",
      "2. STRONG   (7): Saved to 'YfinanceDataDump\\strong_stocks.csv'\n",
      "3. RISKY    (24): Saved to 'YfinanceDataDump\\risky_stocks.csv'\n",
      "\n",
      "--- FORTRESS PREVIEW ---\n",
      "      Ticker      Tier   Price    P/E             Sector  Z-Score  ROIC %  Op Margin %  Curr Ratio  Int Cov  Mkt Cap (B)\n",
      "54    WPM.TO  Fortress  160.76  53.41    Basic Materials   266.55    8.72        66.54       8.089  2269.82        72.99\n",
      "57    FNV.TO  Fortress  284.65  43.66    Basic Materials    99.62   12.20        70.04       4.641  7640.00        54.87\n",
      "6     LUG.TO  Fortress  114.46  29.58    Basic Materials    56.50   66.57        62.00       3.227     3.65        27.63\n",
      "105   DPM.TO  Fortress   42.18  18.03    Basic Materials    44.36   20.76        42.96       2.774   176.88         9.36\n",
      "15    ASM.TO  Fortress    8.99  47.32    Basic Materials    36.86   11.12        32.56       2.754    38.26         1.41\n",
      "33     PNG.V  Fortress    6.33  90.43         Technology    29.97    8.88        15.75       7.305    36.38         1.94\n",
      "100   DSG.TO  Fortress  121.79  49.91         Technology    25.13   13.47        30.54       1.834   191.87        10.47\n",
      "85    KNT.TO  Fortress   22.63  16.05    Basic Materials    23.82   30.81        68.87       3.285   456.18         5.51\n",
      "59    GGD.TO  Fortress    2.84  40.57    Basic Materials    20.50    6.48        29.13       7.626    45.24         1.23\n",
      "71   GRGD.TO  Fortress   83.93  44.41  Consumer Cyclical    14.47   45.97        33.04       1.713     6.57         9.09\n",
      "47    WDO.TO  Fortress   22.99  12.04    Basic Materials    14.31   29.95        55.55       4.793    83.52         3.47\n",
      "23    OGC.TO  Fortress   37.98  16.23    Basic Materials    10.55   12.37        36.34       1.274    12.14         8.68\n",
      "25    DNG.TO  Fortress    5.68  11.14    Basic Materials     9.89   25.90         7.90       4.633    68.99         0.24\n",
      "69    CLS.TO  Fortress  415.37  49.33         Technology     9.14   19.69        10.32       1.468    11.21        47.78\n",
      "38    TXG.TO  Fortress   65.77  14.14    Basic Materials     8.94   19.55        43.61       1.377   100.00         6.32\n"
     ]
    }
   ],
   "source": [
    "# ==========================================\n",
    "# MAIN EXECUTION\n",
    "# ==========================================\n",
    "if __name__ == \"__main__\":\n",
    "    tickers = get_combined_universe()\n",
    "    \n",
    "    if len(tickers) > 0:\n",
    "        survivors_df = get_initial_survivors(tickers)\n",
    "        \n",
    "        if not survivors_df.empty:\n",
    "            print(f\"\\n✅ Step 2 Complete. {len(survivors_df)} stocks passed basic filters.\")\n",
    "            \n",
    "            final_results = get_advanced_metrics(survivors_df)\n",
    "            \n",
    "            if not final_results.empty:\n",
    "                final_results = final_results.sort_values(by=['Tier', 'Z-Score'], ascending=[True, False])\n",
    "                \n",
    "                # 1. Standard Split\n",
    "                fortress_df = final_results[final_results['Tier'] == 'Fortress'].copy()\n",
    "                strong_df = final_results[final_results['Tier'] == 'Strong'].copy()\n",
    "                risky_df = final_results[final_results['Tier'] == 'Risky'].copy()\n",
    "                \n",
    "                # 3. Save Files (Updated to use Relative Paths from Cell 2)\n",
    "                try:\n",
    "                    fortress_df.to_csv(FORTRESS_CSV, index=False)\n",
    "                    strong_df.to_csv(STRONG_CSV, index=False)\n",
    "                    risky_df.to_csv(RISKY_CSV, index=False)\n",
    "                    \n",
    "                    print(\"\\n\" + \"=\"*60)\n",
    "                    print(\"RESULTS GENERATED\")\n",
    "                    print(\"=\"*60)\n",
    "                    print(f\"1. FORTRESS ({len(fortress_df)}): Saved to '{FORTRESS_CSV}'\")\n",
    "                    print(f\"2. STRONG   ({len(strong_df)}): Saved to '{STRONG_CSV}'\")\n",
    "                    print(f\"3. RISKY    ({len(risky_df)}): Saved to '{RISKY_CSV}'\")\n",
    "                except Exception as e:\n",
    "                    print(f\"\\n⚠️ Error Saving Files: {e}\")\n",
    "                    print(\"Check if the file is open in Excel or if the folder exists.\")\n",
    "                \n",
    "                pd.set_option('display.max_rows', 500)\n",
    "                pd.set_option('display.max_columns', 20)\n",
    "                pd.set_option('display.width', 1000)\n",
    "                \n",
    "                print(\"\\n--- FORTRESS PREVIEW ---\")\n",
    "                print(fortress_df.head(15))\n",
    "            else:\n",
    "                print(\"No stocks passed the deep financial analysis.\")\n",
    "        else:\n",
    "            print(\"No stocks passed the initial lightweight filter.\")\n",
    "    else:\n",
    "        print(\"Could not fetch ticker universe.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "36ee3ec0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- STEP 4: Fetching Analyst Ratings for 78 Stocks (From Memory) ---\n",
      "    (Fetching serially to avoid throttling...)\n",
      " -> Analyst Scan 1/78: WPM.TO...\n",
      " -> Analyst Scan 11/78: WDO.TO...\n",
      " -> Analyst Scan 21/78: ATZ.TO...\n",
      " -> Analyst Scan 31/78: SVM.TO...\n",
      " -> Analyst Scan 41/78: VNP.TO...\n",
      " -> Analyst Scan 51/78: LUN.TO...\n",
      " -> Analyst Scan 61/78: PET.TO...\n",
      " -> Analyst Scan 71/78: KEY.TO...\n",
      "\n",
      "✅ Analyst Scan Complete!\n",
      "Found 45 stocks with Buy Ratings (Score < 2.0)\n",
      "Saved to 'Analyst_Fortress_Picks.csv'\n",
      "     Ticker   Price  Analyst_Rating  Upside_%  Target_Price      Tier\n",
      "13   HSTR.V    2.65         1.33333     95.47      5.180000  Fortress\n",
      "32   VLE.TO    8.28         1.16667     56.83     12.985710  Fortress\n",
      "5    GGD.TO    2.84         1.00000     46.71      4.166670  Fortress\n",
      "27   VNP.TO   18.09         1.50000     39.93     25.312738  Fortress\n",
      "9    CLS.TO  415.37         1.47059     30.58    542.378230  Fortress\n",
      "24   MDI.TO   13.00         1.20000     29.23     16.800000  Fortress\n",
      "37   CVE.TO   23.12         1.52941     28.36     29.676470  Fortress\n",
      "29   STN.TO  131.63         1.72727     28.25    168.818180  Fortress\n",
      "35  ARIS.TO   22.13         1.40000     26.32     27.954145  Fortress\n",
      "10   TXG.TO   65.77         1.50000     26.13     82.958330  Fortress\n",
      "7    WDO.TO   22.99         2.00000     20.34     27.666670  Fortress\n",
      "14   AGI.TO   53.27         1.38462     20.30     64.082010  Fortress\n",
      "20   PSI.TO   11.97         2.00000     20.30     14.400000  Fortress\n",
      "1    FNV.TO  284.65         1.93750     19.89    341.271500  Fortress\n",
      "8    OGC.TO   37.98         1.54545     19.35     45.328000  Fortress\n",
      "43   BDI.TO   14.83         1.50000     18.85     17.625000  Fortress\n",
      "41   KEY.TO   44.12         1.84615     18.56     52.307690  Fortress\n",
      "38   CIA.TO    5.46         1.68750     18.44      6.466670  Fortress\n",
      "39   DOO.TO   98.92         1.83333     18.14    116.867170  Fortress\n",
      "0    WPM.TO  160.76         1.43750     17.72    189.246290  Fortress\n"
     ]
    }
   ],
   "source": [
    "# 1. Define the function (if you haven't already in a previous cell)\n",
    "def get_analyst_fortress_from_var(df_input):\n",
    "    working_df = df_input.copy()\n",
    "    tickers = working_df['Ticker'].tolist()\n",
    "    \n",
    "    print(f\"\\n--- STEP 4: Fetching Analyst Ratings for {len(tickers)} Stocks (From Memory) ---\")\n",
    "    print(\"    (Fetching serially to avoid throttling...)\")\n",
    "    \n",
    "    analyst_data = []\n",
    "    \n",
    "    for i, ticker in enumerate(tickers):\n",
    "        if i % 10 == 0: print(f\" -> Analyst Scan {i+1}/{len(tickers)}: {ticker}...\")\n",
    "        \n",
    "        try:\n",
    "            stock = yf.Ticker(ticker)\n",
    "            info = stock.info\n",
    "            \n",
    "            rec_mean = info.get('recommendationMean')\n",
    "            target_price = info.get('targetMeanPrice')\n",
    "            current_price = info.get('currentPrice')\n",
    "            \n",
    "            # Filter: Must be better than 2.0 (Lower is better)\n",
    "            if rec_mean is None or rec_mean > 2.0: continue\n",
    "            \n",
    "            upside = 0\n",
    "            if target_price and current_price:\n",
    "                upside = round(((target_price - current_price) / current_price) * 100, 2)\n",
    "            \n",
    "            # Merge with existing data\n",
    "            base_row = working_df[working_df['Ticker'] == ticker].iloc[0].to_dict()\n",
    "            base_row['Analyst_Rating'] = rec_mean\n",
    "            base_row['Target_Price'] = target_price\n",
    "            base_row['Upside_%'] = upside\n",
    "            \n",
    "            analyst_data.append(base_row)\n",
    "            time.sleep(0.2) # Polite delay\n",
    "            \n",
    "        except Exception:\n",
    "            continue\n",
    "            \n",
    "    return pd.DataFrame(analyst_data)\n",
    "\n",
    "# ==========================================\n",
    "# 2. EXECUTE IT (Run this part!)\n",
    "# ==========================================\n",
    "\n",
    "# Check if fortress_df exists from the previous step\n",
    "if 'fortress_df' in locals() and not fortress_df.empty:\n",
    "    \n",
    "    # Run the function\n",
    "    Analyst_Fortress_DF = get_analyst_fortress_from_var(fortress_df)\n",
    "    \n",
    "    if not Analyst_Fortress_DF.empty:\n",
    "        # Sort by best Analyst Rating (Lower is better) or Upside\n",
    "        Analyst_Fortress_DF = Analyst_Fortress_DF.sort_values(by='Upside_%', ascending=False)\n",
    "        \n",
    "        # Display Results\n",
    "        print(\"\\n✅ Analyst Scan Complete!\")\n",
    "        print(f\"Found {len(Analyst_Fortress_DF)} stocks with Buy Ratings (Score < 2.0)\")\n",
    "        \n",
    "        # Save to CSV\n",
    "        Analyst_Fortress_DF.to_csv(ANALYST_CSV, index=False)\n",
    "        print(\"Saved to 'Analyst_Fortress_Picks.csv'\")\n",
    "        \n",
    "        # Show top picks\n",
    "        cols = ['Ticker', 'Price', 'Analyst_Rating', 'Upside_%', 'Target_Price', 'Tier']\n",
    "        print(Analyst_Fortress_DF[cols].head(20))\n",
    "    else:\n",
    "        print(\"No stocks passed the Analyst filter.\")\n",
    "else:\n",
    "    print(\"❌ 'fortress_df' not found or empty. Please run the Main Filter (Step 1-3) first.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ca466fcd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- STEP 5: Warren Buffett 'Below NAV' Scan ---\n",
      "    Scanning 109 candidates for Deep Value...\n",
      "    Criteria: P/B < 1.0 (Below Book) | ROE > 0% (Profitable) | Debt/Eq < 100%\n",
      "\n",
      "============================================================\n",
      "BUFFETT SCAN COMPLETE\n",
      "============================================================\n",
      "Found 1 Deep Value Stocks (Trading < Book Value)\n",
      "Saved to: 'Buffett_Value_Picks.csv'\n",
      "\n",
      "--- DEEP VALUE PICKS ---\n",
      "    Ticker  Price  P/B Ratio  ROE %  Debt/Eq %  Sector   Tier\n",
      "0  MATR.TO   8.07       0.64   3.66      80.14  Energy  Risky\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from yahooquery import Ticker\n",
    "\n",
    "# ==========================================\n",
    "# BUFFETT \"BELOW NAV\" SCAN\n",
    "# ==========================================\n",
    "def get_buffett_value_picks(df_input):\n",
    "    print(f\"\\n--- STEP 5: Warren Buffett 'Below NAV' Scan ---\")\n",
    "    print(f\"    Scanning {len(df_input)} candidates for Deep Value...\")\n",
    "    print(\"    Criteria: P/B < 1.0 (Below Book) | ROE > 0% (Profitable) | Debt/Eq < 100%\")\n",
    "\n",
    "    tickers = df_input['Ticker'].tolist()\n",
    "    buffett_candidates = []\n",
    "\n",
    "    # Use YahooQuery for speed (Key Stats are summary data, no throttling risk here)\n",
    "    chunk_size = 250\n",
    "    chunks = [tickers[i:i + chunk_size] for i in range(0, len(tickers), chunk_size)]\n",
    "\n",
    "    for chunk in chunks:\n",
    "        try:\n",
    "            yq = Ticker(chunk, asynchronous=True)\n",
    "            # We need defaultKeyStatistics (P/B) and financialData (ROE, Debt)\n",
    "            data = yq.get_modules(\"defaultKeyStatistics financialData\")\n",
    "\n",
    "            for symbol in chunk:\n",
    "                if isinstance(data, dict) and symbol in data:\n",
    "                    try:\n",
    "                        stats = data[symbol].get('defaultKeyStatistics', {})\n",
    "                        fin = data[symbol].get('financialData', {})\n",
    "\n",
    "                        # 1. Price to Book < 1.0 (The Core Rule)\n",
    "                        pb = stats.get('priceToBook')\n",
    "                        # Skip if None, > 1.0, or negative (insolvent)\n",
    "                        if pb is None or pb >= 1.0 or pb <= 0: continue\n",
    "\n",
    "                        # 2. Positive ROE (No Zombies)\n",
    "                        roe = fin.get('returnOnEquity', 0)\n",
    "                        if roe is None or roe <= 0: continue\n",
    "\n",
    "                        # 3. Reasonable Debt (Safety)\n",
    "                        # Buffett hates high leverage on weak companies\n",
    "                        de = fin.get('debtToEquity', 0)\n",
    "                        if de is None or de > 100: continue \n",
    "\n",
    "                        # Get base data from input_df\n",
    "                        base_row = df_input[df_input['Ticker'] == symbol].iloc[0].to_dict()\n",
    "\n",
    "                        # Add new Value Metrics\n",
    "                        base_row['P/B Ratio'] = round(pb, 2)\n",
    "                        base_row['ROE %'] = round(roe * 100, 2)\n",
    "                        base_row['Debt/Eq %'] = round(de, 2)\n",
    "\n",
    "                        buffett_candidates.append(base_row)\n",
    "\n",
    "                    except: continue\n",
    "        except: continue\n",
    "\n",
    "    return pd.DataFrame(buffett_candidates)\n",
    "\n",
    "# ==========================================\n",
    "# EXECUTION BLOCK\n",
    "# ==========================================\n",
    "# Ensure we have the 'final_results' from the Main Filter\n",
    "if 'final_results' in locals() and not final_results.empty:\n",
    "    \n",
    "    Buffett_Value_DF = get_buffett_value_picks(final_results)\n",
    "    \n",
    "    if not Buffett_Value_DF.empty:\n",
    "        # Sort by P/B Ratio (Cheapest first)\n",
    "        Buffett_Value_DF = Buffett_Value_DF.sort_values(by='P/B Ratio', ascending=True)\n",
    "        \n",
    "        # Save results\n",
    "        Buffett_Value_DF.to_csv(BUFFETT_CSV, index=False)\n",
    "        \n",
    "        print(\"\\n\" + \"=\"*60)\n",
    "        print(\"BUFFETT SCAN COMPLETE\")\n",
    "        print(\"=\"*60)\n",
    "        print(f\"Found {len(Buffett_Value_DF)} Deep Value Stocks (Trading < Book Value)\")\n",
    "        print(\"Saved to: 'Buffett_Value_Picks.csv'\")\n",
    "        \n",
    "        # Display\n",
    "        pd.set_option('display.max_rows', 500)\n",
    "        cols = ['Ticker', 'Price', 'P/B Ratio', 'ROE %', 'Debt/Eq %', 'Sector', 'Tier']\n",
    "        print(\"\\n--- DEEP VALUE PICKS ---\")\n",
    "        print(Buffett_Value_DF[cols].head(20))\n",
    "        \n",
    "    else:\n",
    "        print(\"\\n❌ No stocks passed the Buffett Value filter (All stocks are trading > Book Value).\")\n",
    "else:\n",
    "    print(\"❌ 'final_results' variable not found. Please run the Main Filter first.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
